I0411 21:11:06.888576 21842 caffe.cpp:217] Using GPUs 2, 3
I0411 21:11:06.998839 21842 caffe.cpp:222] GPU 2: Tesla M40
I0411 21:11:06.999600 21842 caffe.cpp:222] GPU 3: Tesla M40
I0411 21:11:07.390450 21842 solver.cpp:63] Initializing solver from parameters: 
train_net: "models/VGGNet/text/text_polygon_precise_fix_order_384x384/train.prototxt"
test_net: "models/VGGNet/text/text_polygon_precise_fix_order_384x384/test.prototxt"
test_iter: 500
test_interval: 5000
base_lr: 0.0001
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384"
solver_mode: GPU
device_id: 2
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 100
stepvalue: 40000
stepvalue: 100000
stepvalue: 210000
iter_size: 1
type: "Adam"
eval_type: "detection"
ap_version: "11point"
I0411 21:11:07.390702 21842 solver.cpp:96] Creating training net from train_net file: models/VGGNet/text/text_polygon_precise_fix_order_384x384/train.prototxt
I0411 21:11:07.394112 21842 net.cpp:58] Initializing net from parameters: 
name: "VGG_text_text_polygon_precise_fix_order_384x384_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 384
      width: 384
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "./data/train_lmdb/"
    batch_size: 16
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_object_coverage: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_object_coverage: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_object_coverage: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/text/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 90
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 90
    max_size: 150
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 150
    max_size: 210
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 210
    max_size: 270
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 270
    max_size: 330
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 0.2
    num_classes: 2
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: false
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
    use_polygon: true
  }
}
I0411 21:11:07.394682 21842 layer_factory.hpp:77] Creating layer data
I0411 21:11:07.395584 21842 net.cpp:100] Creating Layer data
I0411 21:11:07.395609 21842 net.cpp:408] data -> data
I0411 21:11:07.395671 21842 net.cpp:408] data -> label
I0411 21:11:07.396826 21847 db_lmdb.cpp:35] Opened lmdb ./data/train_lmdb/
I0411 21:11:07.424605 21842 annotated_data_layer.cpp:62] output data size: 16,3,384,384
I0411 21:11:07.478770 21842 net.cpp:150] Setting up data
I0411 21:11:07.478818 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.478826 21842 net.cpp:157] Top shape: 1 1 22 16 (352)
I0411 21:11:07.478832 21842 net.cpp:165] Memory required for data: 28312960
I0411 21:11:07.478842 21842 layer_factory.hpp:77] Creating layer data_data_0_split
I0411 21:11:07.478866 21842 net.cpp:100] Creating Layer data_data_0_split
I0411 21:11:07.478874 21842 net.cpp:434] data_data_0_split <- data
I0411 21:11:07.478891 21842 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0411 21:11:07.478910 21842 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0411 21:11:07.478919 21842 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0411 21:11:07.478929 21842 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0411 21:11:07.478935 21842 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0411 21:11:07.478942 21842 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0411 21:11:07.478952 21842 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0411 21:11:07.479058 21842 net.cpp:150] Setting up data_data_0_split
I0411 21:11:07.479068 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.479075 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.479080 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.479086 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.479090 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.479096 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.479101 21842 net.cpp:157] Top shape: 16 3 384 384 (7077888)
I0411 21:11:07.479106 21842 net.cpp:165] Memory required for data: 226493824
I0411 21:11:07.479110 21842 layer_factory.hpp:77] Creating layer conv1_1
I0411 21:11:07.479132 21842 net.cpp:100] Creating Layer conv1_1
I0411 21:11:07.479138 21842 net.cpp:434] conv1_1 <- data_data_0_split_0
I0411 21:11:07.479148 21842 net.cpp:408] conv1_1 -> conv1_1
I0411 21:11:07.845203 21842 net.cpp:150] Setting up conv1_1
I0411 21:11:07.845247 21842 net.cpp:157] Top shape: 16 64 384 384 (150994944)
I0411 21:11:07.845254 21842 net.cpp:165] Memory required for data: 830473600
I0411 21:11:07.845286 21842 layer_factory.hpp:77] Creating layer relu1_1
I0411 21:11:07.845338 21842 net.cpp:100] Creating Layer relu1_1
I0411 21:11:07.845367 21842 net.cpp:434] relu1_1 <- conv1_1
I0411 21:11:07.845397 21842 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0411 21:11:07.845861 21842 net.cpp:150] Setting up relu1_1
I0411 21:11:07.845880 21842 net.cpp:157] Top shape: 16 64 384 384 (150994944)
I0411 21:11:07.845909 21842 net.cpp:165] Memory required for data: 1434453376
I0411 21:11:07.845932 21842 layer_factory.hpp:77] Creating layer conv1_2
I0411 21:11:07.845970 21842 net.cpp:100] Creating Layer conv1_2
I0411 21:11:07.845993 21842 net.cpp:434] conv1_2 <- conv1_1
I0411 21:11:07.846019 21842 net.cpp:408] conv1_2 -> conv1_2
I0411 21:11:07.849479 21842 net.cpp:150] Setting up conv1_2
I0411 21:11:07.849530 21842 net.cpp:157] Top shape: 16 64 384 384 (150994944)
I0411 21:11:07.849571 21842 net.cpp:165] Memory required for data: 2038433152
I0411 21:11:07.849637 21842 layer_factory.hpp:77] Creating layer relu1_2
I0411 21:11:07.849648 21842 net.cpp:100] Creating Layer relu1_2
I0411 21:11:07.849653 21842 net.cpp:434] relu1_2 <- conv1_2
I0411 21:11:07.849661 21842 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0411 21:11:07.849889 21842 net.cpp:150] Setting up relu1_2
I0411 21:11:07.849930 21842 net.cpp:157] Top shape: 16 64 384 384 (150994944)
I0411 21:11:07.849952 21842 net.cpp:165] Memory required for data: 2642412928
I0411 21:11:07.849973 21842 layer_factory.hpp:77] Creating layer pool1
I0411 21:11:07.850001 21842 net.cpp:100] Creating Layer pool1
I0411 21:11:07.850023 21842 net.cpp:434] pool1 <- conv1_2
I0411 21:11:07.850046 21842 net.cpp:408] pool1 -> pool1
I0411 21:11:07.850137 21842 net.cpp:150] Setting up pool1
I0411 21:11:07.850169 21842 net.cpp:157] Top shape: 16 64 192 192 (37748736)
I0411 21:11:07.850190 21842 net.cpp:165] Memory required for data: 2793407872
I0411 21:11:07.850224 21842 layer_factory.hpp:77] Creating layer conv2_1
I0411 21:11:07.850255 21842 net.cpp:100] Creating Layer conv2_1
I0411 21:11:07.850277 21842 net.cpp:434] conv2_1 <- pool1
I0411 21:11:07.850303 21842 net.cpp:408] conv2_1 -> conv2_1
I0411 21:11:07.852600 21842 net.cpp:150] Setting up conv2_1
I0411 21:11:07.852643 21842 net.cpp:157] Top shape: 16 128 192 192 (75497472)
I0411 21:11:07.852666 21842 net.cpp:165] Memory required for data: 3095397760
I0411 21:11:07.852696 21842 layer_factory.hpp:77] Creating layer relu2_1
I0411 21:11:07.852725 21842 net.cpp:100] Creating Layer relu2_1
I0411 21:11:07.852746 21842 net.cpp:434] relu2_1 <- conv2_1
I0411 21:11:07.852771 21842 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0411 21:11:07.853020 21842 net.cpp:150] Setting up relu2_1
I0411 21:11:07.853056 21842 net.cpp:157] Top shape: 16 128 192 192 (75497472)
I0411 21:11:07.853080 21842 net.cpp:165] Memory required for data: 3397387648
I0411 21:11:07.853099 21842 layer_factory.hpp:77] Creating layer conv2_2
I0411 21:11:07.853132 21842 net.cpp:100] Creating Layer conv2_2
I0411 21:11:07.853154 21842 net.cpp:434] conv2_2 <- conv2_1
I0411 21:11:07.853179 21842 net.cpp:408] conv2_2 -> conv2_2
I0411 21:11:07.857036 21842 net.cpp:150] Setting up conv2_2
I0411 21:11:07.857079 21842 net.cpp:157] Top shape: 16 128 192 192 (75497472)
I0411 21:11:07.857089 21842 net.cpp:165] Memory required for data: 3699377536
I0411 21:11:07.857102 21842 layer_factory.hpp:77] Creating layer relu2_2
I0411 21:11:07.857129 21842 net.cpp:100] Creating Layer relu2_2
I0411 21:11:07.857151 21842 net.cpp:434] relu2_2 <- conv2_2
I0411 21:11:07.857177 21842 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0411 21:11:07.857632 21842 net.cpp:150] Setting up relu2_2
I0411 21:11:07.857669 21842 net.cpp:157] Top shape: 16 128 192 192 (75497472)
I0411 21:11:07.857691 21842 net.cpp:165] Memory required for data: 4001367424
I0411 21:11:07.857699 21842 layer_factory.hpp:77] Creating layer pool2
I0411 21:11:07.857709 21842 net.cpp:100] Creating Layer pool2
I0411 21:11:07.857714 21842 net.cpp:434] pool2 <- conv2_2
I0411 21:11:07.857722 21842 net.cpp:408] pool2 -> pool2
I0411 21:11:07.857784 21842 net.cpp:150] Setting up pool2
I0411 21:11:07.857815 21842 net.cpp:157] Top shape: 16 128 96 96 (18874368)
I0411 21:11:07.857834 21842 net.cpp:165] Memory required for data: 4076864896
I0411 21:11:07.857854 21842 layer_factory.hpp:77] Creating layer conv3_1
I0411 21:11:07.857883 21842 net.cpp:100] Creating Layer conv3_1
I0411 21:11:07.857903 21842 net.cpp:434] conv3_1 <- pool2
I0411 21:11:07.857923 21842 net.cpp:408] conv3_1 -> conv3_1
I0411 21:11:07.864114 21842 net.cpp:150] Setting up conv3_1
I0411 21:11:07.864166 21842 net.cpp:157] Top shape: 16 256 96 96 (37748736)
I0411 21:11:07.864200 21842 net.cpp:165] Memory required for data: 4227859840
I0411 21:11:07.864231 21842 layer_factory.hpp:77] Creating layer relu3_1
I0411 21:11:07.864261 21842 net.cpp:100] Creating Layer relu3_1
I0411 21:11:07.864284 21842 net.cpp:434] relu3_1 <- conv3_1
I0411 21:11:07.864295 21842 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0411 21:11:07.864560 21842 net.cpp:150] Setting up relu3_1
I0411 21:11:07.864598 21842 net.cpp:157] Top shape: 16 256 96 96 (37748736)
I0411 21:11:07.864624 21842 net.cpp:165] Memory required for data: 4378854784
I0411 21:11:07.864645 21842 layer_factory.hpp:77] Creating layer conv3_2
I0411 21:11:07.864673 21842 net.cpp:100] Creating Layer conv3_2
I0411 21:11:07.864697 21842 net.cpp:434] conv3_2 <- conv3_1
I0411 21:11:07.864723 21842 net.cpp:408] conv3_2 -> conv3_2
I0411 21:11:07.873330 21842 net.cpp:150] Setting up conv3_2
I0411 21:11:07.873351 21842 net.cpp:157] Top shape: 16 256 96 96 (37748736)
I0411 21:11:07.873358 21842 net.cpp:165] Memory required for data: 4529849728
I0411 21:11:07.873365 21842 layer_factory.hpp:77] Creating layer relu3_2
I0411 21:11:07.873374 21842 net.cpp:100] Creating Layer relu3_2
I0411 21:11:07.873379 21842 net.cpp:434] relu3_2 <- conv3_2
I0411 21:11:07.873390 21842 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0411 21:11:07.873646 21842 net.cpp:150] Setting up relu3_2
I0411 21:11:07.873680 21842 net.cpp:157] Top shape: 16 256 96 96 (37748736)
I0411 21:11:07.873702 21842 net.cpp:165] Memory required for data: 4680844672
I0411 21:11:07.873723 21842 layer_factory.hpp:77] Creating layer conv3_3
I0411 21:11:07.873756 21842 net.cpp:100] Creating Layer conv3_3
I0411 21:11:07.873778 21842 net.cpp:434] conv3_3 <- conv3_2
I0411 21:11:07.873805 21842 net.cpp:408] conv3_3 -> conv3_3
I0411 21:11:07.882369 21842 net.cpp:150] Setting up conv3_3
I0411 21:11:07.882426 21842 net.cpp:157] Top shape: 16 256 96 96 (37748736)
I0411 21:11:07.882433 21842 net.cpp:165] Memory required for data: 4831839616
I0411 21:11:07.882441 21842 layer_factory.hpp:77] Creating layer relu3_3
I0411 21:11:07.882452 21842 net.cpp:100] Creating Layer relu3_3
I0411 21:11:07.882457 21842 net.cpp:434] relu3_3 <- conv3_3
I0411 21:11:07.882469 21842 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0411 21:11:07.882932 21842 net.cpp:150] Setting up relu3_3
I0411 21:11:07.882973 21842 net.cpp:157] Top shape: 16 256 96 96 (37748736)
I0411 21:11:07.882995 21842 net.cpp:165] Memory required for data: 4982834560
I0411 21:11:07.883015 21842 layer_factory.hpp:77] Creating layer pool3
I0411 21:11:07.883039 21842 net.cpp:100] Creating Layer pool3
I0411 21:11:07.883064 21842 net.cpp:434] pool3 <- conv3_3
I0411 21:11:07.883087 21842 net.cpp:408] pool3 -> pool3
I0411 21:11:07.883150 21842 net.cpp:150] Setting up pool3
I0411 21:11:07.883183 21842 net.cpp:157] Top shape: 16 256 48 48 (9437184)
I0411 21:11:07.883204 21842 net.cpp:165] Memory required for data: 5020583296
I0411 21:11:07.883224 21842 layer_factory.hpp:77] Creating layer conv4_1
I0411 21:11:07.883255 21842 net.cpp:100] Creating Layer conv4_1
I0411 21:11:07.883282 21842 net.cpp:434] conv4_1 <- pool3
I0411 21:11:07.883294 21842 net.cpp:408] conv4_1 -> conv4_1
I0411 21:11:07.898809 21842 net.cpp:150] Setting up conv4_1
I0411 21:11:07.898826 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.898831 21842 net.cpp:165] Memory required for data: 5096080768
I0411 21:11:07.898841 21842 layer_factory.hpp:77] Creating layer relu4_1
I0411 21:11:07.898854 21842 net.cpp:100] Creating Layer relu4_1
I0411 21:11:07.898861 21842 net.cpp:434] relu4_1 <- conv4_1
I0411 21:11:07.898874 21842 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0411 21:11:07.899124 21842 net.cpp:150] Setting up relu4_1
I0411 21:11:07.899165 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.899194 21842 net.cpp:165] Memory required for data: 5171578240
I0411 21:11:07.899214 21842 layer_factory.hpp:77] Creating layer conv4_2
I0411 21:11:07.899242 21842 net.cpp:100] Creating Layer conv4_2
I0411 21:11:07.899250 21842 net.cpp:434] conv4_2 <- conv4_1
I0411 21:11:07.899258 21842 net.cpp:408] conv4_2 -> conv4_2
I0411 21:11:07.928308 21842 net.cpp:150] Setting up conv4_2
I0411 21:11:07.928371 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.928395 21842 net.cpp:165] Memory required for data: 5247075712
I0411 21:11:07.928416 21842 layer_factory.hpp:77] Creating layer relu4_2
I0411 21:11:07.928449 21842 net.cpp:100] Creating Layer relu4_2
I0411 21:11:07.928458 21842 net.cpp:434] relu4_2 <- conv4_2
I0411 21:11:07.928488 21842 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0411 21:11:07.928747 21842 net.cpp:150] Setting up relu4_2
I0411 21:11:07.928783 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.928809 21842 net.cpp:165] Memory required for data: 5322573184
I0411 21:11:07.928817 21842 layer_factory.hpp:77] Creating layer conv4_3
I0411 21:11:07.928829 21842 net.cpp:100] Creating Layer conv4_3
I0411 21:11:07.928836 21842 net.cpp:434] conv4_3 <- conv4_2
I0411 21:11:07.928845 21842 net.cpp:408] conv4_3 -> conv4_3
I0411 21:11:07.972934 21842 net.cpp:150] Setting up conv4_3
I0411 21:11:07.973023 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.973033 21842 net.cpp:165] Memory required for data: 5398070656
I0411 21:11:07.973059 21842 layer_factory.hpp:77] Creating layer relu4_3
I0411 21:11:07.973137 21842 net.cpp:100] Creating Layer relu4_3
I0411 21:11:07.973162 21842 net.cpp:434] relu4_3 <- conv4_3
I0411 21:11:07.973191 21842 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0411 21:11:07.973837 21842 net.cpp:150] Setting up relu4_3
I0411 21:11:07.973865 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.973872 21842 net.cpp:165] Memory required for data: 5473568128
I0411 21:11:07.973879 21842 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0411 21:11:07.973906 21842 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0411 21:11:07.973918 21842 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0411 21:11:07.973933 21842 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0411 21:11:07.973950 21842 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0411 21:11:07.974045 21842 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0411 21:11:07.974059 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.974071 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:07.974078 21842 net.cpp:165] Memory required for data: 5624563072
I0411 21:11:07.974089 21842 layer_factory.hpp:77] Creating layer pool4
I0411 21:11:07.974102 21842 net.cpp:100] Creating Layer pool4
I0411 21:11:07.974112 21842 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0411 21:11:07.974135 21842 net.cpp:408] pool4 -> pool4
I0411 21:11:07.974231 21842 net.cpp:150] Setting up pool4
I0411 21:11:07.974246 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:07.974253 21842 net.cpp:165] Memory required for data: 5643437440
I0411 21:11:07.974259 21842 layer_factory.hpp:77] Creating layer conv5_1
I0411 21:11:07.974287 21842 net.cpp:100] Creating Layer conv5_1
I0411 21:11:07.974295 21842 net.cpp:434] conv5_1 <- pool4
I0411 21:11:07.974308 21842 net.cpp:408] conv5_1 -> conv5_1
I0411 21:11:08.019033 21842 net.cpp:150] Setting up conv5_1
I0411 21:11:08.019078 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:08.019085 21842 net.cpp:165] Memory required for data: 5662311808
I0411 21:11:08.019099 21842 layer_factory.hpp:77] Creating layer relu5_1
I0411 21:11:08.019119 21842 net.cpp:100] Creating Layer relu5_1
I0411 21:11:08.019127 21842 net.cpp:434] relu5_1 <- conv5_1
I0411 21:11:08.019143 21842 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0411 21:11:08.019428 21842 net.cpp:150] Setting up relu5_1
I0411 21:11:08.019443 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:08.019450 21842 net.cpp:165] Memory required for data: 5681186176
I0411 21:11:08.019457 21842 layer_factory.hpp:77] Creating layer conv5_2
I0411 21:11:08.019479 21842 net.cpp:100] Creating Layer conv5_2
I0411 21:11:08.019485 21842 net.cpp:434] conv5_2 <- conv5_1
I0411 21:11:08.019497 21842 net.cpp:408] conv5_2 -> conv5_2
I0411 21:11:08.034024 21848 blocking_queue.cpp:50] Waiting for data
I0411 21:11:08.055959 21842 net.cpp:150] Setting up conv5_2
I0411 21:11:08.055986 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:08.055992 21842 net.cpp:165] Memory required for data: 5700060544
I0411 21:11:08.056004 21842 layer_factory.hpp:77] Creating layer relu5_2
I0411 21:11:08.056046 21842 net.cpp:100] Creating Layer relu5_2
I0411 21:11:08.056054 21842 net.cpp:434] relu5_2 <- conv5_2
I0411 21:11:08.056064 21842 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0411 21:11:08.056306 21842 net.cpp:150] Setting up relu5_2
I0411 21:11:08.056320 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:08.056324 21842 net.cpp:165] Memory required for data: 5718934912
I0411 21:11:08.056329 21842 layer_factory.hpp:77] Creating layer conv5_3
I0411 21:11:08.056346 21842 net.cpp:100] Creating Layer conv5_3
I0411 21:11:08.056354 21842 net.cpp:434] conv5_3 <- conv5_2
I0411 21:11:08.056365 21842 net.cpp:408] conv5_3 -> conv5_3
I0411 21:11:08.088261 21842 net.cpp:150] Setting up conv5_3
I0411 21:11:08.088291 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:08.088297 21842 net.cpp:165] Memory required for data: 5737809280
I0411 21:11:08.088307 21842 layer_factory.hpp:77] Creating layer relu5_3
I0411 21:11:08.088346 21842 net.cpp:100] Creating Layer relu5_3
I0411 21:11:08.088354 21842 net.cpp:434] relu5_3 <- conv5_3
I0411 21:11:08.088363 21842 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0411 21:11:08.088793 21842 net.cpp:150] Setting up relu5_3
I0411 21:11:08.088809 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:08.088815 21842 net.cpp:165] Memory required for data: 5756683648
I0411 21:11:08.088819 21842 layer_factory.hpp:77] Creating layer pool5
I0411 21:11:08.088837 21842 net.cpp:100] Creating Layer pool5
I0411 21:11:08.088842 21842 net.cpp:434] pool5 <- conv5_3
I0411 21:11:08.088851 21842 net.cpp:408] pool5 -> pool5
I0411 21:11:08.088913 21842 net.cpp:150] Setting up pool5
I0411 21:11:08.088922 21842 net.cpp:157] Top shape: 16 512 24 24 (4718592)
I0411 21:11:08.088927 21842 net.cpp:165] Memory required for data: 5775558016
I0411 21:11:08.088933 21842 layer_factory.hpp:77] Creating layer fc6
I0411 21:11:08.088949 21842 net.cpp:100] Creating Layer fc6
I0411 21:11:08.088955 21842 net.cpp:434] fc6 <- pool5
I0411 21:11:08.088968 21842 net.cpp:408] fc6 -> fc6
I0411 21:11:08.144711 21842 net.cpp:150] Setting up fc6
I0411 21:11:08.144744 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.144749 21842 net.cpp:165] Memory required for data: 5813306752
I0411 21:11:08.144759 21842 layer_factory.hpp:77] Creating layer relu6
I0411 21:11:08.144773 21842 net.cpp:100] Creating Layer relu6
I0411 21:11:08.144781 21842 net.cpp:434] relu6 <- fc6
I0411 21:11:08.144790 21842 net.cpp:395] relu6 -> fc6 (in-place)
I0411 21:11:08.145071 21842 net.cpp:150] Setting up relu6
I0411 21:11:08.145084 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.145089 21842 net.cpp:165] Memory required for data: 5851055488
I0411 21:11:08.145094 21842 layer_factory.hpp:77] Creating layer fc7
I0411 21:11:08.145112 21842 net.cpp:100] Creating Layer fc7
I0411 21:11:08.145119 21842 net.cpp:434] fc7 <- fc6
I0411 21:11:08.145128 21842 net.cpp:408] fc7 -> fc7
I0411 21:11:08.159003 21842 net.cpp:150] Setting up fc7
I0411 21:11:08.159021 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.159025 21842 net.cpp:165] Memory required for data: 5888804224
I0411 21:11:08.159034 21842 layer_factory.hpp:77] Creating layer relu7
I0411 21:11:08.159044 21842 net.cpp:100] Creating Layer relu7
I0411 21:11:08.159052 21842 net.cpp:434] relu7 <- fc7
I0411 21:11:08.159059 21842 net.cpp:395] relu7 -> fc7 (in-place)
I0411 21:11:08.159466 21842 net.cpp:150] Setting up relu7
I0411 21:11:08.159482 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.159487 21842 net.cpp:165] Memory required for data: 5926552960
I0411 21:11:08.159490 21842 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0411 21:11:08.159498 21842 net.cpp:100] Creating Layer fc7_relu7_0_split
I0411 21:11:08.159502 21842 net.cpp:434] fc7_relu7_0_split <- fc7
I0411 21:11:08.159510 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0411 21:11:08.159521 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0411 21:11:08.159548 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0411 21:11:08.159575 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0411 21:11:08.159662 21842 net.cpp:150] Setting up fc7_relu7_0_split
I0411 21:11:08.159672 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.159682 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.159687 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.159693 21842 net.cpp:157] Top shape: 16 1024 24 24 (9437184)
I0411 21:11:08.159695 21842 net.cpp:165] Memory required for data: 6077547904
I0411 21:11:08.159700 21842 layer_factory.hpp:77] Creating layer conv6_1
I0411 21:11:08.159716 21842 net.cpp:100] Creating Layer conv6_1
I0411 21:11:08.159723 21842 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0411 21:11:08.159731 21842 net.cpp:408] conv6_1 -> conv6_1
I0411 21:11:08.164033 21842 net.cpp:150] Setting up conv6_1
I0411 21:11:08.164052 21842 net.cpp:157] Top shape: 16 256 24 24 (2359296)
I0411 21:11:08.164055 21842 net.cpp:165] Memory required for data: 6086985088
I0411 21:11:08.164062 21842 layer_factory.hpp:77] Creating layer conv6_1_relu
I0411 21:11:08.164073 21842 net.cpp:100] Creating Layer conv6_1_relu
I0411 21:11:08.164078 21842 net.cpp:434] conv6_1_relu <- conv6_1
I0411 21:11:08.164085 21842 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0411 21:11:08.164481 21842 net.cpp:150] Setting up conv6_1_relu
I0411 21:11:08.164496 21842 net.cpp:157] Top shape: 16 256 24 24 (2359296)
I0411 21:11:08.164500 21842 net.cpp:165] Memory required for data: 6096422272
I0411 21:11:08.164505 21842 layer_factory.hpp:77] Creating layer conv6_2
I0411 21:11:08.164517 21842 net.cpp:100] Creating Layer conv6_2
I0411 21:11:08.164523 21842 net.cpp:434] conv6_2 <- conv6_1
I0411 21:11:08.164531 21842 net.cpp:408] conv6_2 -> conv6_2
I0411 21:11:08.179507 21842 net.cpp:150] Setting up conv6_2
I0411 21:11:08.179527 21842 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0411 21:11:08.179531 21842 net.cpp:165] Memory required for data: 6101140864
I0411 21:11:08.179558 21842 layer_factory.hpp:77] Creating layer conv6_2_relu
I0411 21:11:08.179569 21842 net.cpp:100] Creating Layer conv6_2_relu
I0411 21:11:08.179574 21842 net.cpp:434] conv6_2_relu <- conv6_2
I0411 21:11:08.179579 21842 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0411 21:11:08.179791 21842 net.cpp:150] Setting up conv6_2_relu
I0411 21:11:08.179806 21842 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0411 21:11:08.179811 21842 net.cpp:165] Memory required for data: 6105859456
I0411 21:11:08.179814 21842 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0411 21:11:08.179821 21842 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0411 21:11:08.179826 21842 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0411 21:11:08.179832 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0411 21:11:08.179844 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0411 21:11:08.179852 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0411 21:11:08.179860 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0411 21:11:08.179944 21842 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0411 21:11:08.179952 21842 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0411 21:11:08.179957 21842 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0411 21:11:08.179961 21842 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0411 21:11:08.179966 21842 net.cpp:157] Top shape: 16 512 12 12 (1179648)
I0411 21:11:08.179970 21842 net.cpp:165] Memory required for data: 6124733824
I0411 21:11:08.179973 21842 layer_factory.hpp:77] Creating layer conv7_1
I0411 21:11:08.179987 21842 net.cpp:100] Creating Layer conv7_1
I0411 21:11:08.179994 21842 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0411 21:11:08.180002 21842 net.cpp:408] conv7_1 -> conv7_1
I0411 21:11:08.182173 21842 net.cpp:150] Setting up conv7_1
I0411 21:11:08.182190 21842 net.cpp:157] Top shape: 16 128 12 12 (294912)
I0411 21:11:08.182215 21842 net.cpp:165] Memory required for data: 6125913472
I0411 21:11:08.182226 21842 layer_factory.hpp:77] Creating layer conv7_1_relu
I0411 21:11:08.182234 21842 net.cpp:100] Creating Layer conv7_1_relu
I0411 21:11:08.182238 21842 net.cpp:434] conv7_1_relu <- conv7_1
I0411 21:11:08.182245 21842 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0411 21:11:08.182693 21842 net.cpp:150] Setting up conv7_1_relu
I0411 21:11:08.182710 21842 net.cpp:157] Top shape: 16 128 12 12 (294912)
I0411 21:11:08.182714 21842 net.cpp:165] Memory required for data: 6127093120
I0411 21:11:08.182718 21842 layer_factory.hpp:77] Creating layer conv7_2
I0411 21:11:08.182734 21842 net.cpp:100] Creating Layer conv7_2
I0411 21:11:08.182739 21842 net.cpp:434] conv7_2 <- conv7_1
I0411 21:11:08.182749 21842 net.cpp:408] conv7_2 -> conv7_2
I0411 21:11:08.187480 21842 net.cpp:150] Setting up conv7_2
I0411 21:11:08.187500 21842 net.cpp:157] Top shape: 16 256 6 6 (147456)
I0411 21:11:08.187505 21842 net.cpp:165] Memory required for data: 6127682944
I0411 21:11:08.187512 21842 layer_factory.hpp:77] Creating layer conv7_2_relu
I0411 21:11:08.187520 21842 net.cpp:100] Creating Layer conv7_2_relu
I0411 21:11:08.187525 21842 net.cpp:434] conv7_2_relu <- conv7_2
I0411 21:11:08.187530 21842 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0411 21:11:08.187927 21842 net.cpp:150] Setting up conv7_2_relu
I0411 21:11:08.187942 21842 net.cpp:157] Top shape: 16 256 6 6 (147456)
I0411 21:11:08.187947 21842 net.cpp:165] Memory required for data: 6128272768
I0411 21:11:08.187950 21842 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0411 21:11:08.187958 21842 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0411 21:11:08.187963 21842 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0411 21:11:08.187971 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0411 21:11:08.187980 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0411 21:11:08.187988 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0411 21:11:08.187994 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0411 21:11:08.188077 21842 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0411 21:11:08.188086 21842 net.cpp:157] Top shape: 16 256 6 6 (147456)
I0411 21:11:08.188091 21842 net.cpp:157] Top shape: 16 256 6 6 (147456)
I0411 21:11:08.188096 21842 net.cpp:157] Top shape: 16 256 6 6 (147456)
I0411 21:11:08.188099 21842 net.cpp:157] Top shape: 16 256 6 6 (147456)
I0411 21:11:08.188103 21842 net.cpp:165] Memory required for data: 6130632064
I0411 21:11:08.188108 21842 layer_factory.hpp:77] Creating layer conv8_1
I0411 21:11:08.188119 21842 net.cpp:100] Creating Layer conv8_1
I0411 21:11:08.188127 21842 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0411 21:11:08.188136 21842 net.cpp:408] conv8_1 -> conv8_1
I0411 21:11:08.189756 21842 net.cpp:150] Setting up conv8_1
I0411 21:11:08.189772 21842 net.cpp:157] Top shape: 16 128 6 6 (73728)
I0411 21:11:08.189777 21842 net.cpp:165] Memory required for data: 6130926976
I0411 21:11:08.189785 21842 layer_factory.hpp:77] Creating layer conv8_1_relu
I0411 21:11:08.189795 21842 net.cpp:100] Creating Layer conv8_1_relu
I0411 21:11:08.189800 21842 net.cpp:434] conv8_1_relu <- conv8_1
I0411 21:11:08.189806 21842 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0411 21:11:08.190011 21842 net.cpp:150] Setting up conv8_1_relu
I0411 21:11:08.190023 21842 net.cpp:157] Top shape: 16 128 6 6 (73728)
I0411 21:11:08.190032 21842 net.cpp:165] Memory required for data: 6131221888
I0411 21:11:08.190035 21842 layer_factory.hpp:77] Creating layer conv8_2
I0411 21:11:08.190052 21842 net.cpp:100] Creating Layer conv8_2
I0411 21:11:08.190057 21842 net.cpp:434] conv8_2 <- conv8_1
I0411 21:11:08.190065 21842 net.cpp:408] conv8_2 -> conv8_2
I0411 21:11:08.194983 21842 net.cpp:150] Setting up conv8_2
I0411 21:11:08.195000 21842 net.cpp:157] Top shape: 16 256 4 4 (65536)
I0411 21:11:08.195004 21842 net.cpp:165] Memory required for data: 6131484032
I0411 21:11:08.195025 21842 layer_factory.hpp:77] Creating layer conv8_2_relu
I0411 21:11:08.195034 21842 net.cpp:100] Creating Layer conv8_2_relu
I0411 21:11:08.195039 21842 net.cpp:434] conv8_2_relu <- conv8_2
I0411 21:11:08.195045 21842 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0411 21:11:08.195444 21842 net.cpp:150] Setting up conv8_2_relu
I0411 21:11:08.195461 21842 net.cpp:157] Top shape: 16 256 4 4 (65536)
I0411 21:11:08.195464 21842 net.cpp:165] Memory required for data: 6131746176
I0411 21:11:08.195468 21842 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0411 21:11:08.195479 21842 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0411 21:11:08.195484 21842 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0411 21:11:08.195492 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0411 21:11:08.195502 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0411 21:11:08.195508 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0411 21:11:08.195516 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0411 21:11:08.195600 21842 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0411 21:11:08.195611 21842 net.cpp:157] Top shape: 16 256 4 4 (65536)
I0411 21:11:08.195616 21842 net.cpp:157] Top shape: 16 256 4 4 (65536)
I0411 21:11:08.195619 21842 net.cpp:157] Top shape: 16 256 4 4 (65536)
I0411 21:11:08.195623 21842 net.cpp:157] Top shape: 16 256 4 4 (65536)
I0411 21:11:08.195627 21842 net.cpp:165] Memory required for data: 6132794752
I0411 21:11:08.195631 21842 layer_factory.hpp:77] Creating layer conv9_1
I0411 21:11:08.195643 21842 net.cpp:100] Creating Layer conv9_1
I0411 21:11:08.195652 21842 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0411 21:11:08.195658 21842 net.cpp:408] conv9_1 -> conv9_1
I0411 21:11:08.197101 21842 net.cpp:150] Setting up conv9_1
I0411 21:11:08.197118 21842 net.cpp:157] Top shape: 16 128 4 4 (32768)
I0411 21:11:08.197121 21842 net.cpp:165] Memory required for data: 6132925824
I0411 21:11:08.197130 21842 layer_factory.hpp:77] Creating layer conv9_1_relu
I0411 21:11:08.197139 21842 net.cpp:100] Creating Layer conv9_1_relu
I0411 21:11:08.197145 21842 net.cpp:434] conv9_1_relu <- conv9_1
I0411 21:11:08.197151 21842 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0411 21:11:08.197541 21842 net.cpp:150] Setting up conv9_1_relu
I0411 21:11:08.197556 21842 net.cpp:157] Top shape: 16 128 4 4 (32768)
I0411 21:11:08.197561 21842 net.cpp:165] Memory required for data: 6133056896
I0411 21:11:08.197564 21842 layer_factory.hpp:77] Creating layer conv9_2
I0411 21:11:08.197579 21842 net.cpp:100] Creating Layer conv9_2
I0411 21:11:08.197584 21842 net.cpp:434] conv9_2 <- conv9_1
I0411 21:11:08.197592 21842 net.cpp:408] conv9_2 -> conv9_2
I0411 21:11:08.202719 21842 net.cpp:150] Setting up conv9_2
I0411 21:11:08.202736 21842 net.cpp:157] Top shape: 16 256 2 2 (16384)
I0411 21:11:08.202741 21842 net.cpp:165] Memory required for data: 6133122432
I0411 21:11:08.202749 21842 layer_factory.hpp:77] Creating layer conv9_2_relu
I0411 21:11:08.202757 21842 net.cpp:100] Creating Layer conv9_2_relu
I0411 21:11:08.202762 21842 net.cpp:434] conv9_2_relu <- conv9_2
I0411 21:11:08.202771 21842 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0411 21:11:08.202972 21842 net.cpp:150] Setting up conv9_2_relu
I0411 21:11:08.202985 21842 net.cpp:157] Top shape: 16 256 2 2 (16384)
I0411 21:11:08.202988 21842 net.cpp:165] Memory required for data: 6133187968
I0411 21:11:08.202991 21842 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0411 21:11:08.202998 21842 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0411 21:11:08.203002 21842 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0411 21:11:08.203011 21842 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0411 21:11:08.203019 21842 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0411 21:11:08.203030 21842 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0411 21:11:08.203114 21842 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0411 21:11:08.203122 21842 net.cpp:157] Top shape: 16 256 2 2 (16384)
I0411 21:11:08.203127 21842 net.cpp:157] Top shape: 16 256 2 2 (16384)
I0411 21:11:08.203131 21842 net.cpp:157] Top shape: 16 256 2 2 (16384)
I0411 21:11:08.203137 21842 net.cpp:165] Memory required for data: 6133384576
I0411 21:11:08.203142 21842 layer_factory.hpp:77] Creating layer conv4_3_norm
I0411 21:11:08.203155 21842 net.cpp:100] Creating Layer conv4_3_norm
I0411 21:11:08.203160 21842 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0411 21:11:08.203168 21842 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0411 21:11:08.203361 21842 net.cpp:150] Setting up conv4_3_norm
I0411 21:11:08.203371 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:08.203375 21842 net.cpp:165] Memory required for data: 6208882048
I0411 21:11:08.203382 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0411 21:11:08.203389 21842 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0411 21:11:08.203394 21842 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0411 21:11:08.203400 21842 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0411 21:11:08.203409 21842 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0411 21:11:08.203415 21842 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0411 21:11:08.203476 21842 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0411 21:11:08.203485 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:08.203490 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:08.203495 21842 net.cpp:157] Top shape: 16 512 48 48 (18874368)
I0411 21:11:08.203497 21842 net.cpp:165] Memory required for data: 6435374464
I0411 21:11:08.203501 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0411 21:11:08.203519 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0411 21:11:08.203526 21842 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0411 21:11:08.203532 21842 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0411 21:11:08.226183 21842 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0411 21:11:08.226214 21842 net.cpp:157] Top shape: 16 240 48 48 (8847360)
I0411 21:11:08.226219 21842 net.cpp:165] Memory required for data: 6470763904
I0411 21:11:08.226229 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0411 21:11:08.226241 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0411 21:11:08.226246 21842 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0411 21:11:08.226254 21842 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0411 21:11:08.226397 21842 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0411 21:11:08.226408 21842 net.cpp:157] Top shape: 16 48 48 240 (8847360)
I0411 21:11:08.226411 21842 net.cpp:165] Memory required for data: 6506153344
I0411 21:11:08.226415 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0411 21:11:08.226438 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0411 21:11:08.226444 21842 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0411 21:11:08.226451 21842 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0411 21:11:08.226495 21842 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0411 21:11:08.226506 21842 net.cpp:157] Top shape: 16 552960 (8847360)
I0411 21:11:08.226511 21842 net.cpp:165] Memory required for data: 6541542784
I0411 21:11:08.226514 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0411 21:11:08.226536 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0411 21:11:08.226541 21842 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0411 21:11:08.226548 21842 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0411 21:11:08.231678 21842 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0411 21:11:08.231696 21842 net.cpp:157] Top shape: 16 40 48 48 (1474560)
I0411 21:11:08.231701 21842 net.cpp:165] Memory required for data: 6547441024
I0411 21:11:08.231709 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0411 21:11:08.231717 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0411 21:11:08.231722 21842 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0411 21:11:08.231729 21842 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0411 21:11:08.231863 21842 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0411 21:11:08.231871 21842 net.cpp:157] Top shape: 16 48 48 40 (1474560)
I0411 21:11:08.231875 21842 net.cpp:165] Memory required for data: 6553339264
I0411 21:11:08.231880 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0411 21:11:08.231889 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0411 21:11:08.231894 21842 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0411 21:11:08.231901 21842 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0411 21:11:08.231932 21842 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0411 21:11:08.231940 21842 net.cpp:157] Top shape: 16 92160 (1474560)
I0411 21:11:08.231945 21842 net.cpp:165] Memory required for data: 6559237504
I0411 21:11:08.231947 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0411 21:11:08.231958 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0411 21:11:08.231963 21842 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0411 21:11:08.231971 21842 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0411 21:11:08.231979 21842 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0411 21:11:08.232017 21842 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0411 21:11:08.232025 21842 net.cpp:157] Top shape: 1 2 184320 (368640)
I0411 21:11:08.232029 21842 net.cpp:165] Memory required for data: 6560712064
I0411 21:11:08.232033 21842 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0411 21:11:08.232045 21842 net.cpp:100] Creating Layer fc7_mbox_loc
I0411 21:11:08.232053 21842 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0411 21:11:08.232062 21842 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0411 21:11:08.276274 21842 net.cpp:150] Setting up fc7_mbox_loc
I0411 21:11:08.276312 21842 net.cpp:157] Top shape: 16 240 24 24 (2211840)
I0411 21:11:08.276319 21842 net.cpp:165] Memory required for data: 6569559424
I0411 21:11:08.276330 21842 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0411 21:11:08.276343 21842 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0411 21:11:08.276355 21842 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0411 21:11:08.276370 21842 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0411 21:11:08.276507 21842 net.cpp:150] Setting up fc7_mbox_loc_perm
I0411 21:11:08.276517 21842 net.cpp:157] Top shape: 16 24 24 240 (2211840)
I0411 21:11:08.276521 21842 net.cpp:165] Memory required for data: 6578406784
I0411 21:11:08.276525 21842 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0411 21:11:08.276535 21842 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0411 21:11:08.276542 21842 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0411 21:11:08.276548 21842 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0411 21:11:08.276581 21842 net.cpp:150] Setting up fc7_mbox_loc_flat
I0411 21:11:08.276587 21842 net.cpp:157] Top shape: 16 138240 (2211840)
I0411 21:11:08.276592 21842 net.cpp:165] Memory required for data: 6587254144
I0411 21:11:08.276595 21842 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0411 21:11:08.276608 21842 net.cpp:100] Creating Layer fc7_mbox_conf
I0411 21:11:08.276617 21842 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0411 21:11:08.276625 21842 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0411 21:11:08.285048 21842 net.cpp:150] Setting up fc7_mbox_conf
I0411 21:11:08.285085 21842 net.cpp:157] Top shape: 16 40 24 24 (368640)
I0411 21:11:08.285091 21842 net.cpp:165] Memory required for data: 6588728704
I0411 21:11:08.285099 21842 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0411 21:11:08.285107 21842 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0411 21:11:08.285112 21842 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0411 21:11:08.285120 21842 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0411 21:11:08.285256 21842 net.cpp:150] Setting up fc7_mbox_conf_perm
I0411 21:11:08.285266 21842 net.cpp:157] Top shape: 16 24 24 40 (368640)
I0411 21:11:08.285270 21842 net.cpp:165] Memory required for data: 6590203264
I0411 21:11:08.285275 21842 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0411 21:11:08.285284 21842 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0411 21:11:08.285290 21842 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0411 21:11:08.285295 21842 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0411 21:11:08.285327 21842 net.cpp:150] Setting up fc7_mbox_conf_flat
I0411 21:11:08.285336 21842 net.cpp:157] Top shape: 16 23040 (368640)
I0411 21:11:08.285339 21842 net.cpp:165] Memory required for data: 6591677824
I0411 21:11:08.285343 21842 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0411 21:11:08.285351 21842 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0411 21:11:08.285356 21842 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0411 21:11:08.285362 21842 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0411 21:11:08.285369 21842 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0411 21:11:08.285405 21842 net.cpp:150] Setting up fc7_mbox_priorbox
I0411 21:11:08.285413 21842 net.cpp:157] Top shape: 1 2 46080 (92160)
I0411 21:11:08.285418 21842 net.cpp:165] Memory required for data: 6592046464
I0411 21:11:08.285420 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0411 21:11:08.285435 21842 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0411 21:11:08.285440 21842 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0411 21:11:08.285449 21842 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0411 21:11:08.308815 21842 net.cpp:150] Setting up conv6_2_mbox_loc
I0411 21:11:08.308851 21842 net.cpp:157] Top shape: 16 240 12 12 (552960)
I0411 21:11:08.308856 21842 net.cpp:165] Memory required for data: 6594258304
I0411 21:11:08.308871 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0411 21:11:08.308881 21842 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0411 21:11:08.308887 21842 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0411 21:11:08.308894 21842 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0411 21:11:08.309038 21842 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0411 21:11:08.309049 21842 net.cpp:157] Top shape: 16 12 12 240 (552960)
I0411 21:11:08.309053 21842 net.cpp:165] Memory required for data: 6596470144
I0411 21:11:08.309056 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0411 21:11:08.309064 21842 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0411 21:11:08.309069 21842 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0411 21:11:08.309075 21842 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0411 21:11:08.309106 21842 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0411 21:11:08.309115 21842 net.cpp:157] Top shape: 16 34560 (552960)
I0411 21:11:08.309119 21842 net.cpp:165] Memory required for data: 6598681984
I0411 21:11:08.309123 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0411 21:11:08.309134 21842 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0411 21:11:08.309139 21842 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0411 21:11:08.309147 21842 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0411 21:11:08.314214 21842 net.cpp:150] Setting up conv6_2_mbox_conf
I0411 21:11:08.314231 21842 net.cpp:157] Top shape: 16 40 12 12 (92160)
I0411 21:11:08.314236 21842 net.cpp:165] Memory required for data: 6599050624
I0411 21:11:08.314257 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0411 21:11:08.314267 21842 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0411 21:11:08.314272 21842 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0411 21:11:08.314281 21842 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0411 21:11:08.314416 21842 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0411 21:11:08.314429 21842 net.cpp:157] Top shape: 16 12 12 40 (92160)
I0411 21:11:08.314432 21842 net.cpp:165] Memory required for data: 6599419264
I0411 21:11:08.314437 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0411 21:11:08.314443 21842 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0411 21:11:08.314448 21842 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0411 21:11:08.314455 21842 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0411 21:11:08.314486 21842 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0411 21:11:08.314494 21842 net.cpp:157] Top shape: 16 5760 (92160)
I0411 21:11:08.314498 21842 net.cpp:165] Memory required for data: 6599787904
I0411 21:11:08.314502 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0411 21:11:08.314512 21842 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0411 21:11:08.314517 21842 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0411 21:11:08.314522 21842 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0411 21:11:08.314528 21842 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0411 21:11:08.314563 21842 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0411 21:11:08.314571 21842 net.cpp:157] Top shape: 1 2 11520 (23040)
I0411 21:11:08.314575 21842 net.cpp:165] Memory required for data: 6599880064
I0411 21:11:08.314579 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0411 21:11:08.314589 21842 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0411 21:11:08.314594 21842 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0411 21:11:08.314602 21842 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0411 21:11:08.326689 21842 net.cpp:150] Setting up conv7_2_mbox_loc
I0411 21:11:08.326709 21842 net.cpp:157] Top shape: 16 240 6 6 (138240)
I0411 21:11:08.326712 21842 net.cpp:165] Memory required for data: 6600433024
I0411 21:11:08.326721 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0411 21:11:08.326730 21842 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0411 21:11:08.326735 21842 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0411 21:11:08.326742 21842 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0411 21:11:08.326879 21842 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0411 21:11:08.326889 21842 net.cpp:157] Top shape: 16 6 6 240 (138240)
I0411 21:11:08.326894 21842 net.cpp:165] Memory required for data: 6600985984
I0411 21:11:08.326897 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0411 21:11:08.326905 21842 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0411 21:11:08.326910 21842 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0411 21:11:08.326915 21842 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0411 21:11:08.326947 21842 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0411 21:11:08.326956 21842 net.cpp:157] Top shape: 16 8640 (138240)
I0411 21:11:08.326959 21842 net.cpp:165] Memory required for data: 6601538944
I0411 21:11:08.326962 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0411 21:11:08.326977 21842 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0411 21:11:08.326982 21842 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0411 21:11:08.326990 21842 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0411 21:11:08.330687 21842 net.cpp:150] Setting up conv7_2_mbox_conf
I0411 21:11:08.330703 21842 net.cpp:157] Top shape: 16 40 6 6 (23040)
I0411 21:11:08.330708 21842 net.cpp:165] Memory required for data: 6601631104
I0411 21:11:08.330715 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0411 21:11:08.330739 21842 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0411 21:11:08.330744 21842 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0411 21:11:08.330751 21842 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0411 21:11:08.330891 21842 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0411 21:11:08.330901 21842 net.cpp:157] Top shape: 16 6 6 40 (23040)
I0411 21:11:08.330905 21842 net.cpp:165] Memory required for data: 6601723264
I0411 21:11:08.330909 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0411 21:11:08.330915 21842 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0411 21:11:08.330919 21842 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0411 21:11:08.330927 21842 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0411 21:11:08.330958 21842 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0411 21:11:08.330968 21842 net.cpp:157] Top shape: 16 1440 (23040)
I0411 21:11:08.330972 21842 net.cpp:165] Memory required for data: 6601815424
I0411 21:11:08.330976 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0411 21:11:08.330983 21842 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0411 21:11:08.330987 21842 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0411 21:11:08.330992 21842 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0411 21:11:08.331001 21842 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0411 21:11:08.331033 21842 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0411 21:11:08.331041 21842 net.cpp:157] Top shape: 1 2 2880 (5760)
I0411 21:11:08.331045 21842 net.cpp:165] Memory required for data: 6601838464
I0411 21:11:08.331048 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0411 21:11:08.331060 21842 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0411 21:11:08.331064 21842 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0411 21:11:08.331074 21842 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0411 21:11:08.343025 21842 net.cpp:150] Setting up conv8_2_mbox_loc
I0411 21:11:08.343044 21842 net.cpp:157] Top shape: 16 240 4 4 (61440)
I0411 21:11:08.343049 21842 net.cpp:165] Memory required for data: 6602084224
I0411 21:11:08.343077 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0411 21:11:08.343087 21842 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0411 21:11:08.343092 21842 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0411 21:11:08.343101 21842 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0411 21:11:08.343240 21842 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0411 21:11:08.343250 21842 net.cpp:157] Top shape: 16 4 4 240 (61440)
I0411 21:11:08.343253 21842 net.cpp:165] Memory required for data: 6602329984
I0411 21:11:08.343257 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0411 21:11:08.343264 21842 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0411 21:11:08.343269 21842 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0411 21:11:08.343276 21842 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0411 21:11:08.343307 21842 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0411 21:11:08.343317 21842 net.cpp:157] Top shape: 16 3840 (61440)
I0411 21:11:08.343320 21842 net.cpp:165] Memory required for data: 6602575744
I0411 21:11:08.343323 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0411 21:11:08.343335 21842 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0411 21:11:08.343339 21842 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0411 21:11:08.343348 21842 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0411 21:11:08.346818 21842 net.cpp:150] Setting up conv8_2_mbox_conf
I0411 21:11:08.346837 21842 net.cpp:157] Top shape: 16 40 4 4 (10240)
I0411 21:11:08.346840 21842 net.cpp:165] Memory required for data: 6602616704
I0411 21:11:08.346848 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0411 21:11:08.346858 21842 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0411 21:11:08.346864 21842 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0411 21:11:08.346884 21842 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0411 21:11:08.347025 21842 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0411 21:11:08.347036 21842 net.cpp:157] Top shape: 16 4 4 40 (10240)
I0411 21:11:08.347039 21842 net.cpp:165] Memory required for data: 6602657664
I0411 21:11:08.347044 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0411 21:11:08.347050 21842 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0411 21:11:08.347055 21842 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0411 21:11:08.347064 21842 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0411 21:11:08.347097 21842 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0411 21:11:08.347105 21842 net.cpp:157] Top shape: 16 640 (10240)
I0411 21:11:08.347110 21842 net.cpp:165] Memory required for data: 6602698624
I0411 21:11:08.347113 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0411 21:11:08.347121 21842 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0411 21:11:08.347126 21842 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0411 21:11:08.347131 21842 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0411 21:11:08.347138 21842 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0411 21:11:08.347178 21842 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0411 21:11:08.347187 21842 net.cpp:157] Top shape: 1 2 1280 (2560)
I0411 21:11:08.347192 21842 net.cpp:165] Memory required for data: 6602708864
I0411 21:11:08.347194 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0411 21:11:08.347205 21842 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0411 21:11:08.347210 21842 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0411 21:11:08.347218 21842 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0411 21:11:08.359311 21842 net.cpp:150] Setting up conv9_2_mbox_loc
I0411 21:11:08.359329 21842 net.cpp:157] Top shape: 16 240 2 2 (15360)
I0411 21:11:08.359334 21842 net.cpp:165] Memory required for data: 6602770304
I0411 21:11:08.359341 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0411 21:11:08.359352 21842 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0411 21:11:08.359357 21842 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0411 21:11:08.359364 21842 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0411 21:11:08.359503 21842 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0411 21:11:08.359513 21842 net.cpp:157] Top shape: 16 2 2 240 (15360)
I0411 21:11:08.359515 21842 net.cpp:165] Memory required for data: 6602831744
I0411 21:11:08.359519 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0411 21:11:08.359525 21842 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0411 21:11:08.359529 21842 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0411 21:11:08.359540 21842 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0411 21:11:08.359575 21842 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0411 21:11:08.359582 21842 net.cpp:157] Top shape: 16 960 (15360)
I0411 21:11:08.359586 21842 net.cpp:165] Memory required for data: 6602893184
I0411 21:11:08.359591 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0411 21:11:08.359601 21842 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0411 21:11:08.359606 21842 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0411 21:11:08.359614 21842 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0411 21:11:08.363088 21842 net.cpp:150] Setting up conv9_2_mbox_conf
I0411 21:11:08.363106 21842 net.cpp:157] Top shape: 16 40 2 2 (2560)
I0411 21:11:08.363111 21842 net.cpp:165] Memory required for data: 6602903424
I0411 21:11:08.363117 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0411 21:11:08.363126 21842 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0411 21:11:08.363131 21842 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0411 21:11:08.363140 21842 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0411 21:11:08.363297 21842 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0411 21:11:08.363308 21842 net.cpp:157] Top shape: 16 2 2 40 (2560)
I0411 21:11:08.363312 21842 net.cpp:165] Memory required for data: 6602913664
I0411 21:11:08.363317 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0411 21:11:08.363322 21842 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0411 21:11:08.363327 21842 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0411 21:11:08.363335 21842 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0411 21:11:08.363366 21842 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0411 21:11:08.363374 21842 net.cpp:157] Top shape: 16 160 (2560)
I0411 21:11:08.363379 21842 net.cpp:165] Memory required for data: 6602923904
I0411 21:11:08.363382 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0411 21:11:08.363390 21842 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0411 21:11:08.363394 21842 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0411 21:11:08.363400 21842 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0411 21:11:08.363407 21842 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0411 21:11:08.363441 21842 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0411 21:11:08.363449 21842 net.cpp:157] Top shape: 1 2 320 (640)
I0411 21:11:08.363453 21842 net.cpp:165] Memory required for data: 6602926464
I0411 21:11:08.363457 21842 layer_factory.hpp:77] Creating layer mbox_loc
I0411 21:11:08.363481 21842 net.cpp:100] Creating Layer mbox_loc
I0411 21:11:08.363487 21842 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0411 21:11:08.363494 21842 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0411 21:11:08.363500 21842 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0411 21:11:08.363505 21842 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0411 21:11:08.363509 21842 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0411 21:11:08.363514 21842 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0411 21:11:08.363519 21842 net.cpp:408] mbox_loc -> mbox_loc
I0411 21:11:08.363584 21842 net.cpp:150] Setting up mbox_loc
I0411 21:11:08.363592 21842 net.cpp:157] Top shape: 16 739200 (11827200)
I0411 21:11:08.363596 21842 net.cpp:165] Memory required for data: 6650235264
I0411 21:11:08.363600 21842 layer_factory.hpp:77] Creating layer mbox_conf
I0411 21:11:08.363606 21842 net.cpp:100] Creating Layer mbox_conf
I0411 21:11:08.363610 21842 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0411 21:11:08.363616 21842 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0411 21:11:08.363621 21842 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0411 21:11:08.363626 21842 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0411 21:11:08.363631 21842 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0411 21:11:08.363636 21842 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0411 21:11:08.363642 21842 net.cpp:408] mbox_conf -> mbox_conf
I0411 21:11:08.363674 21842 net.cpp:150] Setting up mbox_conf
I0411 21:11:08.363682 21842 net.cpp:157] Top shape: 16 123200 (1971200)
I0411 21:11:08.363687 21842 net.cpp:165] Memory required for data: 6658120064
I0411 21:11:08.363689 21842 layer_factory.hpp:77] Creating layer mbox_priorbox
I0411 21:11:08.363696 21842 net.cpp:100] Creating Layer mbox_priorbox
I0411 21:11:08.363701 21842 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0411 21:11:08.363706 21842 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0411 21:11:08.363711 21842 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0411 21:11:08.363715 21842 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0411 21:11:08.363719 21842 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0411 21:11:08.363723 21842 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0411 21:11:08.363730 21842 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0411 21:11:08.363762 21842 net.cpp:150] Setting up mbox_priorbox
I0411 21:11:08.363770 21842 net.cpp:157] Top shape: 1 2 246400 (492800)
I0411 21:11:08.363773 21842 net.cpp:165] Memory required for data: 6660091264
I0411 21:11:08.363786 21842 layer_factory.hpp:77] Creating layer mbox_loss
I0411 21:11:08.363798 21842 net.cpp:100] Creating Layer mbox_loss
I0411 21:11:08.363802 21842 net.cpp:434] mbox_loss <- mbox_loc
I0411 21:11:08.363808 21842 net.cpp:434] mbox_loss <- mbox_conf
I0411 21:11:08.363812 21842 net.cpp:434] mbox_loss <- mbox_priorbox
I0411 21:11:08.363816 21842 net.cpp:434] mbox_loss <- label
I0411 21:11:08.363826 21842 net.cpp:408] mbox_loss -> mbox_loss
I0411 21:11:08.363909 21842 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0411 21:11:08.364082 21842 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0411 21:11:08.364096 21842 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0411 21:11:08.364460 21842 net.cpp:150] Setting up mbox_loss
I0411 21:11:08.364475 21842 net.cpp:157] Top shape: (1)
I0411 21:11:08.364478 21842 net.cpp:160]     with loss weight 1
I0411 21:11:08.364514 21842 net.cpp:165] Memory required for data: 6660091268
I0411 21:11:08.364519 21842 net.cpp:226] mbox_loss needs backward computation.
I0411 21:11:08.364526 21842 net.cpp:228] mbox_priorbox does not need backward computation.
I0411 21:11:08.364532 21842 net.cpp:226] mbox_conf needs backward computation.
I0411 21:11:08.364539 21842 net.cpp:226] mbox_loc needs backward computation.
I0411 21:11:08.364544 21842 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.364549 21842 net.cpp:226] conv9_2_mbox_conf_flat needs backward computation.
I0411 21:11:08.364553 21842 net.cpp:226] conv9_2_mbox_conf_perm needs backward computation.
I0411 21:11:08.364557 21842 net.cpp:226] conv9_2_mbox_conf needs backward computation.
I0411 21:11:08.364562 21842 net.cpp:226] conv9_2_mbox_loc_flat needs backward computation.
I0411 21:11:08.364565 21842 net.cpp:226] conv9_2_mbox_loc_perm needs backward computation.
I0411 21:11:08.364569 21842 net.cpp:226] conv9_2_mbox_loc needs backward computation.
I0411 21:11:08.364573 21842 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.364578 21842 net.cpp:226] conv8_2_mbox_conf_flat needs backward computation.
I0411 21:11:08.364583 21842 net.cpp:226] conv8_2_mbox_conf_perm needs backward computation.
I0411 21:11:08.364586 21842 net.cpp:226] conv8_2_mbox_conf needs backward computation.
I0411 21:11:08.364590 21842 net.cpp:226] conv8_2_mbox_loc_flat needs backward computation.
I0411 21:11:08.364593 21842 net.cpp:226] conv8_2_mbox_loc_perm needs backward computation.
I0411 21:11:08.364598 21842 net.cpp:226] conv8_2_mbox_loc needs backward computation.
I0411 21:11:08.364601 21842 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.364606 21842 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0411 21:11:08.364611 21842 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0411 21:11:08.364615 21842 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0411 21:11:08.364619 21842 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0411 21:11:08.364624 21842 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0411 21:11:08.364627 21842 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0411 21:11:08.364631 21842 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.364636 21842 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0411 21:11:08.364640 21842 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0411 21:11:08.364645 21842 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0411 21:11:08.364648 21842 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0411 21:11:08.364652 21842 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0411 21:11:08.364656 21842 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0411 21:11:08.364660 21842 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0411 21:11:08.364665 21842 net.cpp:226] fc7_mbox_conf_flat needs backward computation.
I0411 21:11:08.364679 21842 net.cpp:226] fc7_mbox_conf_perm needs backward computation.
I0411 21:11:08.364684 21842 net.cpp:226] fc7_mbox_conf needs backward computation.
I0411 21:11:08.364689 21842 net.cpp:226] fc7_mbox_loc_flat needs backward computation.
I0411 21:11:08.364693 21842 net.cpp:226] fc7_mbox_loc_perm needs backward computation.
I0411 21:11:08.364697 21842 net.cpp:226] fc7_mbox_loc needs backward computation.
I0411 21:11:08.364702 21842 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0411 21:11:08.364707 21842 net.cpp:226] conv4_3_norm_mbox_conf_flat needs backward computation.
I0411 21:11:08.364711 21842 net.cpp:226] conv4_3_norm_mbox_conf_perm needs backward computation.
I0411 21:11:08.364715 21842 net.cpp:226] conv4_3_norm_mbox_conf needs backward computation.
I0411 21:11:08.364720 21842 net.cpp:226] conv4_3_norm_mbox_loc_flat needs backward computation.
I0411 21:11:08.364723 21842 net.cpp:226] conv4_3_norm_mbox_loc_perm needs backward computation.
I0411 21:11:08.364728 21842 net.cpp:226] conv4_3_norm_mbox_loc needs backward computation.
I0411 21:11:08.364732 21842 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0411 21:11:08.364737 21842 net.cpp:226] conv4_3_norm needs backward computation.
I0411 21:11:08.364742 21842 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0411 21:11:08.364745 21842 net.cpp:226] conv9_2_relu needs backward computation.
I0411 21:11:08.364749 21842 net.cpp:226] conv9_2 needs backward computation.
I0411 21:11:08.364753 21842 net.cpp:226] conv9_1_relu needs backward computation.
I0411 21:11:08.364758 21842 net.cpp:226] conv9_1 needs backward computation.
I0411 21:11:08.364761 21842 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0411 21:11:08.364766 21842 net.cpp:226] conv8_2_relu needs backward computation.
I0411 21:11:08.364769 21842 net.cpp:226] conv8_2 needs backward computation.
I0411 21:11:08.364774 21842 net.cpp:226] conv8_1_relu needs backward computation.
I0411 21:11:08.364778 21842 net.cpp:226] conv8_1 needs backward computation.
I0411 21:11:08.364781 21842 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0411 21:11:08.364785 21842 net.cpp:226] conv7_2_relu needs backward computation.
I0411 21:11:08.364789 21842 net.cpp:226] conv7_2 needs backward computation.
I0411 21:11:08.364794 21842 net.cpp:226] conv7_1_relu needs backward computation.
I0411 21:11:08.364797 21842 net.cpp:226] conv7_1 needs backward computation.
I0411 21:11:08.364801 21842 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0411 21:11:08.364805 21842 net.cpp:226] conv6_2_relu needs backward computation.
I0411 21:11:08.364809 21842 net.cpp:226] conv6_2 needs backward computation.
I0411 21:11:08.364814 21842 net.cpp:226] conv6_1_relu needs backward computation.
I0411 21:11:08.364816 21842 net.cpp:226] conv6_1 needs backward computation.
I0411 21:11:08.364822 21842 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0411 21:11:08.364827 21842 net.cpp:226] relu7 needs backward computation.
I0411 21:11:08.364831 21842 net.cpp:226] fc7 needs backward computation.
I0411 21:11:08.364835 21842 net.cpp:226] relu6 needs backward computation.
I0411 21:11:08.364838 21842 net.cpp:226] fc6 needs backward computation.
I0411 21:11:08.364842 21842 net.cpp:226] pool5 needs backward computation.
I0411 21:11:08.364846 21842 net.cpp:226] relu5_3 needs backward computation.
I0411 21:11:08.364850 21842 net.cpp:226] conv5_3 needs backward computation.
I0411 21:11:08.364854 21842 net.cpp:226] relu5_2 needs backward computation.
I0411 21:11:08.364858 21842 net.cpp:226] conv5_2 needs backward computation.
I0411 21:11:08.364862 21842 net.cpp:226] relu5_1 needs backward computation.
I0411 21:11:08.364866 21842 net.cpp:226] conv5_1 needs backward computation.
I0411 21:11:08.364871 21842 net.cpp:226] pool4 needs backward computation.
I0411 21:11:08.364874 21842 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0411 21:11:08.364878 21842 net.cpp:226] relu4_3 needs backward computation.
I0411 21:11:08.364888 21842 net.cpp:226] conv4_3 needs backward computation.
I0411 21:11:08.364892 21842 net.cpp:226] relu4_2 needs backward computation.
I0411 21:11:08.364902 21842 net.cpp:226] conv4_2 needs backward computation.
I0411 21:11:08.364907 21842 net.cpp:226] relu4_1 needs backward computation.
I0411 21:11:08.364910 21842 net.cpp:226] conv4_1 needs backward computation.
I0411 21:11:08.364914 21842 net.cpp:226] pool3 needs backward computation.
I0411 21:11:08.364918 21842 net.cpp:226] relu3_3 needs backward computation.
I0411 21:11:08.364926 21842 net.cpp:226] conv3_3 needs backward computation.
I0411 21:11:08.364930 21842 net.cpp:226] relu3_2 needs backward computation.
I0411 21:11:08.364934 21842 net.cpp:226] conv3_2 needs backward computation.
I0411 21:11:08.364941 21842 net.cpp:226] relu3_1 needs backward computation.
I0411 21:11:08.364945 21842 net.cpp:226] conv3_1 needs backward computation.
I0411 21:11:08.364949 21842 net.cpp:228] pool2 does not need backward computation.
I0411 21:11:08.364954 21842 net.cpp:228] relu2_2 does not need backward computation.
I0411 21:11:08.364958 21842 net.cpp:228] conv2_2 does not need backward computation.
I0411 21:11:08.364962 21842 net.cpp:228] relu2_1 does not need backward computation.
I0411 21:11:08.364965 21842 net.cpp:228] conv2_1 does not need backward computation.
I0411 21:11:08.364970 21842 net.cpp:228] pool1 does not need backward computation.
I0411 21:11:08.364974 21842 net.cpp:228] relu1_2 does not need backward computation.
I0411 21:11:08.364977 21842 net.cpp:228] conv1_2 does not need backward computation.
I0411 21:11:08.364981 21842 net.cpp:228] relu1_1 does not need backward computation.
I0411 21:11:08.364985 21842 net.cpp:228] conv1_1 does not need backward computation.
I0411 21:11:08.364992 21842 net.cpp:228] data_data_0_split does not need backward computation.
I0411 21:11:08.364997 21842 net.cpp:228] data does not need backward computation.
I0411 21:11:08.365000 21842 net.cpp:270] This network produces output mbox_loss
I0411 21:11:08.365085 21842 net.cpp:283] Network initialization done.
I0411 21:11:08.368064 21842 solver.cpp:196] Creating test net (#0) specified by test_net file: models/VGGNet/text/text_polygon_precise_fix_order_384x384/test.prototxt
I0411 21:11:08.368911 21842 net.cpp:58] Initializing net from parameters: 
name: "VGG_text_text_polygon_precise_fix_order_384x384_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 384
      width: 384
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "./data/test_lmdb/"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data/text/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 90
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 90
    max_size: 150
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 150
    max_size: 210
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 210
    max_size: 270
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 240
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_h: 1
    pad_w: 2
    kernel_h: 3
    kernel_w: 5
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 270
    max_size: 330
    aspect_ratio: 2
    aspect_ratio: 3
    aspect_ratio: 4
    aspect_ratio: 5
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
    denser_prior_boxes: true
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 2
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 2
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "/home/amax/data/text/results/text/text_polygon_precise_fix_order_384x384/Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "data/text/labelmap_voc.prototxt"
      num_test_image: 500
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
    use_polygon: true
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 2
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    use_polygon: true
  }
}
I0411 21:11:08.369410 21842 layer_factory.hpp:77] Creating layer data
I0411 21:11:08.369508 21842 net.cpp:100] Creating Layer data
I0411 21:11:08.369520 21842 net.cpp:408] data -> data
I0411 21:11:08.369537 21842 net.cpp:408] data -> label
I0411 21:11:08.370893 21873 db_lmdb.cpp:35] Opened lmdb ./data/test_lmdb/
I0411 21:11:08.378347 21842 annotated_data_layer.cpp:62] output data size: 1,3,384,384
I0411 21:11:08.383021 21842 net.cpp:150] Setting up data
I0411 21:11:08.383040 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383047 21842 net.cpp:157] Top shape: 1 1 49 16 (784)
I0411 21:11:08.383051 21842 net.cpp:165] Memory required for data: 1772608
I0411 21:11:08.383056 21842 layer_factory.hpp:77] Creating layer data_data_0_split
I0411 21:11:08.383066 21842 net.cpp:100] Creating Layer data_data_0_split
I0411 21:11:08.383070 21842 net.cpp:434] data_data_0_split <- data
I0411 21:11:08.383078 21842 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0411 21:11:08.383088 21842 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0411 21:11:08.383098 21842 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0411 21:11:08.383106 21842 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0411 21:11:08.383112 21842 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0411 21:11:08.383118 21842 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0411 21:11:08.383124 21842 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0411 21:11:08.383280 21842 net.cpp:150] Setting up data_data_0_split
I0411 21:11:08.383289 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383294 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383299 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383304 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383308 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383313 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383317 21842 net.cpp:157] Top shape: 1 3 384 384 (442368)
I0411 21:11:08.383322 21842 net.cpp:165] Memory required for data: 14158912
I0411 21:11:08.383325 21842 layer_factory.hpp:77] Creating layer conv1_1
I0411 21:11:08.383337 21842 net.cpp:100] Creating Layer conv1_1
I0411 21:11:08.383342 21842 net.cpp:434] conv1_1 <- data_data_0_split_0
I0411 21:11:08.383349 21842 net.cpp:408] conv1_1 -> conv1_1
I0411 21:11:08.385818 21842 net.cpp:150] Setting up conv1_1
I0411 21:11:08.385836 21842 net.cpp:157] Top shape: 1 64 384 384 (9437184)
I0411 21:11:08.385841 21842 net.cpp:165] Memory required for data: 51907648
I0411 21:11:08.385854 21842 layer_factory.hpp:77] Creating layer relu1_1
I0411 21:11:08.385862 21842 net.cpp:100] Creating Layer relu1_1
I0411 21:11:08.385867 21842 net.cpp:434] relu1_1 <- conv1_1
I0411 21:11:08.385872 21842 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0411 21:11:08.386288 21842 net.cpp:150] Setting up relu1_1
I0411 21:11:08.386306 21842 net.cpp:157] Top shape: 1 64 384 384 (9437184)
I0411 21:11:08.386309 21842 net.cpp:165] Memory required for data: 89656384
I0411 21:11:08.386313 21842 layer_factory.hpp:77] Creating layer conv1_2
I0411 21:11:08.386325 21842 net.cpp:100] Creating Layer conv1_2
I0411 21:11:08.386329 21842 net.cpp:434] conv1_2 <- conv1_1
I0411 21:11:08.386337 21842 net.cpp:408] conv1_2 -> conv1_2
I0411 21:11:08.389523 21842 net.cpp:150] Setting up conv1_2
I0411 21:11:08.389539 21842 net.cpp:157] Top shape: 1 64 384 384 (9437184)
I0411 21:11:08.389544 21842 net.cpp:165] Memory required for data: 127405120
I0411 21:11:08.389555 21842 layer_factory.hpp:77] Creating layer relu1_2
I0411 21:11:08.389564 21842 net.cpp:100] Creating Layer relu1_2
I0411 21:11:08.389567 21842 net.cpp:434] relu1_2 <- conv1_2
I0411 21:11:08.389590 21842 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0411 21:11:08.389816 21842 net.cpp:150] Setting up relu1_2
I0411 21:11:08.389828 21842 net.cpp:157] Top shape: 1 64 384 384 (9437184)
I0411 21:11:08.389833 21842 net.cpp:165] Memory required for data: 165153856
I0411 21:11:08.389838 21842 layer_factory.hpp:77] Creating layer pool1
I0411 21:11:08.389845 21842 net.cpp:100] Creating Layer pool1
I0411 21:11:08.389849 21842 net.cpp:434] pool1 <- conv1_2
I0411 21:11:08.389855 21842 net.cpp:408] pool1 -> pool1
I0411 21:11:08.389921 21842 net.cpp:150] Setting up pool1
I0411 21:11:08.389930 21842 net.cpp:157] Top shape: 1 64 192 192 (2359296)
I0411 21:11:08.389935 21842 net.cpp:165] Memory required for data: 174591040
I0411 21:11:08.389937 21842 layer_factory.hpp:77] Creating layer conv2_1
I0411 21:11:08.389948 21842 net.cpp:100] Creating Layer conv2_1
I0411 21:11:08.389955 21842 net.cpp:434] conv2_1 <- pool1
I0411 21:11:08.389961 21842 net.cpp:408] conv2_1 -> conv2_1
I0411 21:11:08.392249 21842 net.cpp:150] Setting up conv2_1
I0411 21:11:08.392267 21842 net.cpp:157] Top shape: 1 128 192 192 (4718592)
I0411 21:11:08.392271 21842 net.cpp:165] Memory required for data: 193465408
I0411 21:11:08.392283 21842 layer_factory.hpp:77] Creating layer relu2_1
I0411 21:11:08.392292 21842 net.cpp:100] Creating Layer relu2_1
I0411 21:11:08.392297 21842 net.cpp:434] relu2_1 <- conv2_1
I0411 21:11:08.392303 21842 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0411 21:11:08.392514 21842 net.cpp:150] Setting up relu2_1
I0411 21:11:08.392526 21842 net.cpp:157] Top shape: 1 128 192 192 (4718592)
I0411 21:11:08.392530 21842 net.cpp:165] Memory required for data: 212339776
I0411 21:11:08.392534 21842 layer_factory.hpp:77] Creating layer conv2_2
I0411 21:11:08.392545 21842 net.cpp:100] Creating Layer conv2_2
I0411 21:11:08.392550 21842 net.cpp:434] conv2_2 <- conv2_1
I0411 21:11:08.392558 21842 net.cpp:408] conv2_2 -> conv2_2
I0411 21:11:08.396186 21842 net.cpp:150] Setting up conv2_2
I0411 21:11:08.396203 21842 net.cpp:157] Top shape: 1 128 192 192 (4718592)
I0411 21:11:08.396209 21842 net.cpp:165] Memory required for data: 231214144
I0411 21:11:08.396216 21842 layer_factory.hpp:77] Creating layer relu2_2
I0411 21:11:08.396224 21842 net.cpp:100] Creating Layer relu2_2
I0411 21:11:08.396229 21842 net.cpp:434] relu2_2 <- conv2_2
I0411 21:11:08.396235 21842 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0411 21:11:08.396842 21842 net.cpp:150] Setting up relu2_2
I0411 21:11:08.396858 21842 net.cpp:157] Top shape: 1 128 192 192 (4718592)
I0411 21:11:08.396862 21842 net.cpp:165] Memory required for data: 250088512
I0411 21:11:08.396867 21842 layer_factory.hpp:77] Creating layer pool2
I0411 21:11:08.396874 21842 net.cpp:100] Creating Layer pool2
I0411 21:11:08.396878 21842 net.cpp:434] pool2 <- conv2_2
I0411 21:11:08.396886 21842 net.cpp:408] pool2 -> pool2
I0411 21:11:08.396951 21842 net.cpp:150] Setting up pool2
I0411 21:11:08.396961 21842 net.cpp:157] Top shape: 1 128 96 96 (1179648)
I0411 21:11:08.396965 21842 net.cpp:165] Memory required for data: 254807104
I0411 21:11:08.396970 21842 layer_factory.hpp:77] Creating layer conv3_1
I0411 21:11:08.396980 21842 net.cpp:100] Creating Layer conv3_1
I0411 21:11:08.396983 21842 net.cpp:434] conv3_1 <- pool2
I0411 21:11:08.396991 21842 net.cpp:408] conv3_1 -> conv3_1
I0411 21:11:08.402017 21842 net.cpp:150] Setting up conv3_1
I0411 21:11:08.402035 21842 net.cpp:157] Top shape: 1 256 96 96 (2359296)
I0411 21:11:08.402040 21842 net.cpp:165] Memory required for data: 264244288
I0411 21:11:08.402051 21842 layer_factory.hpp:77] Creating layer relu3_1
I0411 21:11:08.402060 21842 net.cpp:100] Creating Layer relu3_1
I0411 21:11:08.402063 21842 net.cpp:434] relu3_1 <- conv3_1
I0411 21:11:08.402070 21842 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0411 21:11:08.402287 21842 net.cpp:150] Setting up relu3_1
I0411 21:11:08.402299 21842 net.cpp:157] Top shape: 1 256 96 96 (2359296)
I0411 21:11:08.402303 21842 net.cpp:165] Memory required for data: 273681472
I0411 21:11:08.402307 21842 layer_factory.hpp:77] Creating layer conv3_2
I0411 21:11:08.402331 21842 net.cpp:100] Creating Layer conv3_2
I0411 21:11:08.402338 21842 net.cpp:434] conv3_2 <- conv3_1
I0411 21:11:08.402345 21842 net.cpp:408] conv3_2 -> conv3_2
I0411 21:11:08.410749 21842 net.cpp:150] Setting up conv3_2
I0411 21:11:08.410768 21842 net.cpp:157] Top shape: 1 256 96 96 (2359296)
I0411 21:11:08.410773 21842 net.cpp:165] Memory required for data: 283118656
I0411 21:11:08.410780 21842 layer_factory.hpp:77] Creating layer relu3_2
I0411 21:11:08.410787 21842 net.cpp:100] Creating Layer relu3_2
I0411 21:11:08.410792 21842 net.cpp:434] relu3_2 <- conv3_2
I0411 21:11:08.410799 21842 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0411 21:11:08.411011 21842 net.cpp:150] Setting up relu3_2
I0411 21:11:08.411025 21842 net.cpp:157] Top shape: 1 256 96 96 (2359296)
I0411 21:11:08.411028 21842 net.cpp:165] Memory required for data: 292555840
I0411 21:11:08.411032 21842 layer_factory.hpp:77] Creating layer conv3_3
I0411 21:11:08.411046 21842 net.cpp:100] Creating Layer conv3_3
I0411 21:11:08.411051 21842 net.cpp:434] conv3_3 <- conv3_2
I0411 21:11:08.411061 21842 net.cpp:408] conv3_3 -> conv3_3
I0411 21:11:08.419574 21842 net.cpp:150] Setting up conv3_3
I0411 21:11:08.419592 21842 net.cpp:157] Top shape: 1 256 96 96 (2359296)
I0411 21:11:08.419596 21842 net.cpp:165] Memory required for data: 301993024
I0411 21:11:08.419605 21842 layer_factory.hpp:77] Creating layer relu3_3
I0411 21:11:08.419611 21842 net.cpp:100] Creating Layer relu3_3
I0411 21:11:08.419616 21842 net.cpp:434] relu3_3 <- conv3_3
I0411 21:11:08.419625 21842 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0411 21:11:08.420032 21842 net.cpp:150] Setting up relu3_3
I0411 21:11:08.420047 21842 net.cpp:157] Top shape: 1 256 96 96 (2359296)
I0411 21:11:08.420051 21842 net.cpp:165] Memory required for data: 311430208
I0411 21:11:08.420055 21842 layer_factory.hpp:77] Creating layer pool3
I0411 21:11:08.420063 21842 net.cpp:100] Creating Layer pool3
I0411 21:11:08.420074 21842 net.cpp:434] pool3 <- conv3_3
I0411 21:11:08.420083 21842 net.cpp:408] pool3 -> pool3
I0411 21:11:08.420148 21842 net.cpp:150] Setting up pool3
I0411 21:11:08.420158 21842 net.cpp:157] Top shape: 1 256 48 48 (589824)
I0411 21:11:08.420162 21842 net.cpp:165] Memory required for data: 313789504
I0411 21:11:08.420166 21842 layer_factory.hpp:77] Creating layer conv4_1
I0411 21:11:08.420178 21842 net.cpp:100] Creating Layer conv4_1
I0411 21:11:08.420183 21842 net.cpp:434] conv4_1 <- pool3
I0411 21:11:08.420191 21842 net.cpp:408] conv4_1 -> conv4_1
I0411 21:11:08.435324 21842 net.cpp:150] Setting up conv4_1
I0411 21:11:08.435344 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.435348 21842 net.cpp:165] Memory required for data: 318508096
I0411 21:11:08.435356 21842 layer_factory.hpp:77] Creating layer relu4_1
I0411 21:11:08.435364 21842 net.cpp:100] Creating Layer relu4_1
I0411 21:11:08.435370 21842 net.cpp:434] relu4_1 <- conv4_1
I0411 21:11:08.435376 21842 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0411 21:11:08.435603 21842 net.cpp:150] Setting up relu4_1
I0411 21:11:08.435616 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.435619 21842 net.cpp:165] Memory required for data: 323226688
I0411 21:11:08.435623 21842 layer_factory.hpp:77] Creating layer conv4_2
I0411 21:11:08.435636 21842 net.cpp:100] Creating Layer conv4_2
I0411 21:11:08.435640 21842 net.cpp:434] conv4_2 <- conv4_1
I0411 21:11:08.435649 21842 net.cpp:408] conv4_2 -> conv4_2
I0411 21:11:08.464438 21842 net.cpp:150] Setting up conv4_2
I0411 21:11:08.464470 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.464474 21842 net.cpp:165] Memory required for data: 327945280
I0411 21:11:08.464491 21842 layer_factory.hpp:77] Creating layer relu4_2
I0411 21:11:08.464503 21842 net.cpp:100] Creating Layer relu4_2
I0411 21:11:08.464509 21842 net.cpp:434] relu4_2 <- conv4_2
I0411 21:11:08.464517 21842 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0411 21:11:08.464741 21842 net.cpp:150] Setting up relu4_2
I0411 21:11:08.464754 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.464773 21842 net.cpp:165] Memory required for data: 332663872
I0411 21:11:08.464778 21842 layer_factory.hpp:77] Creating layer conv4_3
I0411 21:11:08.464792 21842 net.cpp:100] Creating Layer conv4_3
I0411 21:11:08.464797 21842 net.cpp:434] conv4_3 <- conv4_2
I0411 21:11:08.464804 21842 net.cpp:408] conv4_3 -> conv4_3
I0411 21:11:08.493813 21842 net.cpp:150] Setting up conv4_3
I0411 21:11:08.493844 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.493849 21842 net.cpp:165] Memory required for data: 337382464
I0411 21:11:08.493860 21842 layer_factory.hpp:77] Creating layer relu4_3
I0411 21:11:08.493876 21842 net.cpp:100] Creating Layer relu4_3
I0411 21:11:08.493882 21842 net.cpp:434] relu4_3 <- conv4_3
I0411 21:11:08.493891 21842 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0411 21:11:08.494325 21842 net.cpp:150] Setting up relu4_3
I0411 21:11:08.494344 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.494349 21842 net.cpp:165] Memory required for data: 342101056
I0411 21:11:08.494354 21842 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0411 21:11:08.494360 21842 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0411 21:11:08.494366 21842 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0411 21:11:08.494375 21842 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0411 21:11:08.494385 21842 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0411 21:11:08.494451 21842 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0411 21:11:08.494462 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.494467 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.494470 21842 net.cpp:165] Memory required for data: 351538240
I0411 21:11:08.494474 21842 layer_factory.hpp:77] Creating layer pool4
I0411 21:11:08.494482 21842 net.cpp:100] Creating Layer pool4
I0411 21:11:08.494487 21842 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0411 21:11:08.494493 21842 net.cpp:408] pool4 -> pool4
I0411 21:11:08.494556 21842 net.cpp:150] Setting up pool4
I0411 21:11:08.494565 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.494570 21842 net.cpp:165] Memory required for data: 352717888
I0411 21:11:08.494573 21842 layer_factory.hpp:77] Creating layer conv5_1
I0411 21:11:08.494586 21842 net.cpp:100] Creating Layer conv5_1
I0411 21:11:08.494592 21842 net.cpp:434] conv5_1 <- pool4
I0411 21:11:08.494602 21842 net.cpp:408] conv5_1 -> conv5_1
I0411 21:11:08.523550 21842 net.cpp:150] Setting up conv5_1
I0411 21:11:08.523587 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.523592 21842 net.cpp:165] Memory required for data: 353897536
I0411 21:11:08.523602 21842 layer_factory.hpp:77] Creating layer relu5_1
I0411 21:11:08.523619 21842 net.cpp:100] Creating Layer relu5_1
I0411 21:11:08.523625 21842 net.cpp:434] relu5_1 <- conv5_1
I0411 21:11:08.523634 21842 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0411 21:11:08.523880 21842 net.cpp:150] Setting up relu5_1
I0411 21:11:08.523892 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.523896 21842 net.cpp:165] Memory required for data: 355077184
I0411 21:11:08.523900 21842 layer_factory.hpp:77] Creating layer conv5_2
I0411 21:11:08.523918 21842 net.cpp:100] Creating Layer conv5_2
I0411 21:11:08.523926 21842 net.cpp:434] conv5_2 <- conv5_1
I0411 21:11:08.523934 21842 net.cpp:408] conv5_2 -> conv5_2
I0411 21:11:08.552845 21842 net.cpp:150] Setting up conv5_2
I0411 21:11:08.552877 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.552882 21842 net.cpp:165] Memory required for data: 356256832
I0411 21:11:08.552891 21842 layer_factory.hpp:77] Creating layer relu5_2
I0411 21:11:08.552901 21842 net.cpp:100] Creating Layer relu5_2
I0411 21:11:08.552907 21842 net.cpp:434] relu5_2 <- conv5_2
I0411 21:11:08.552917 21842 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0411 21:11:08.553153 21842 net.cpp:150] Setting up relu5_2
I0411 21:11:08.553167 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.553192 21842 net.cpp:165] Memory required for data: 357436480
I0411 21:11:08.553197 21842 layer_factory.hpp:77] Creating layer conv5_3
I0411 21:11:08.553216 21842 net.cpp:100] Creating Layer conv5_3
I0411 21:11:08.553223 21842 net.cpp:434] conv5_3 <- conv5_2
I0411 21:11:08.553231 21842 net.cpp:408] conv5_3 -> conv5_3
I0411 21:11:08.582348 21842 net.cpp:150] Setting up conv5_3
I0411 21:11:08.582382 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.582387 21842 net.cpp:165] Memory required for data: 358616128
I0411 21:11:08.582397 21842 layer_factory.hpp:77] Creating layer relu5_3
I0411 21:11:08.582413 21842 net.cpp:100] Creating Layer relu5_3
I0411 21:11:08.582420 21842 net.cpp:434] relu5_3 <- conv5_3
I0411 21:11:08.582430 21842 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0411 21:11:08.582890 21842 net.cpp:150] Setting up relu5_3
I0411 21:11:08.582906 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.582911 21842 net.cpp:165] Memory required for data: 359795776
I0411 21:11:08.582914 21842 layer_factory.hpp:77] Creating layer pool5
I0411 21:11:08.582926 21842 net.cpp:100] Creating Layer pool5
I0411 21:11:08.582931 21842 net.cpp:434] pool5 <- conv5_3
I0411 21:11:08.582938 21842 net.cpp:408] pool5 -> pool5
I0411 21:11:08.583015 21842 net.cpp:150] Setting up pool5
I0411 21:11:08.583025 21842 net.cpp:157] Top shape: 1 512 24 24 (294912)
I0411 21:11:08.583029 21842 net.cpp:165] Memory required for data: 360975424
I0411 21:11:08.583034 21842 layer_factory.hpp:77] Creating layer fc6
I0411 21:11:08.583048 21842 net.cpp:100] Creating Layer fc6
I0411 21:11:08.583055 21842 net.cpp:434] fc6 <- pool5
I0411 21:11:08.583063 21842 net.cpp:408] fc6 -> fc6
I0411 21:11:08.637949 21842 net.cpp:150] Setting up fc6
I0411 21:11:08.637987 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.637992 21842 net.cpp:165] Memory required for data: 363334720
I0411 21:11:08.638002 21842 layer_factory.hpp:77] Creating layer relu6
I0411 21:11:08.638015 21842 net.cpp:100] Creating Layer relu6
I0411 21:11:08.638021 21842 net.cpp:434] relu6 <- fc6
I0411 21:11:08.638036 21842 net.cpp:395] relu6 -> fc6 (in-place)
I0411 21:11:08.638336 21842 net.cpp:150] Setting up relu6
I0411 21:11:08.638350 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.638353 21842 net.cpp:165] Memory required for data: 365694016
I0411 21:11:08.638357 21842 layer_factory.hpp:77] Creating layer fc7
I0411 21:11:08.638371 21842 net.cpp:100] Creating Layer fc7
I0411 21:11:08.638376 21842 net.cpp:434] fc7 <- fc6
I0411 21:11:08.638386 21842 net.cpp:408] fc7 -> fc7
I0411 21:11:08.652243 21842 net.cpp:150] Setting up fc7
I0411 21:11:08.652262 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.652266 21842 net.cpp:165] Memory required for data: 368053312
I0411 21:11:08.652274 21842 layer_factory.hpp:77] Creating layer relu7
I0411 21:11:08.652283 21842 net.cpp:100] Creating Layer relu7
I0411 21:11:08.652288 21842 net.cpp:434] relu7 <- fc7
I0411 21:11:08.652295 21842 net.cpp:395] relu7 -> fc7 (in-place)
I0411 21:11:08.652750 21842 net.cpp:150] Setting up relu7
I0411 21:11:08.652766 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.652770 21842 net.cpp:165] Memory required for data: 370412608
I0411 21:11:08.652775 21842 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0411 21:11:08.652782 21842 net.cpp:100] Creating Layer fc7_relu7_0_split
I0411 21:11:08.652786 21842 net.cpp:434] fc7_relu7_0_split <- fc7
I0411 21:11:08.652796 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0411 21:11:08.652803 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0411 21:11:08.652817 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0411 21:11:08.652825 21842 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0411 21:11:08.652935 21842 net.cpp:150] Setting up fc7_relu7_0_split
I0411 21:11:08.652945 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.652951 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.652956 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.652976 21842 net.cpp:157] Top shape: 1 1024 24 24 (589824)
I0411 21:11:08.652981 21842 net.cpp:165] Memory required for data: 379849792
I0411 21:11:08.652984 21842 layer_factory.hpp:77] Creating layer conv6_1
I0411 21:11:08.652997 21842 net.cpp:100] Creating Layer conv6_1
I0411 21:11:08.653002 21842 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0411 21:11:08.653010 21842 net.cpp:408] conv6_1 -> conv6_1
I0411 21:11:08.657507 21842 net.cpp:150] Setting up conv6_1
I0411 21:11:08.657526 21842 net.cpp:157] Top shape: 1 256 24 24 (147456)
I0411 21:11:08.657531 21842 net.cpp:165] Memory required for data: 380439616
I0411 21:11:08.657539 21842 layer_factory.hpp:77] Creating layer conv6_1_relu
I0411 21:11:08.657546 21842 net.cpp:100] Creating Layer conv6_1_relu
I0411 21:11:08.657552 21842 net.cpp:434] conv6_1_relu <- conv6_1
I0411 21:11:08.657557 21842 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0411 21:11:08.657982 21842 net.cpp:150] Setting up conv6_1_relu
I0411 21:11:08.657999 21842 net.cpp:157] Top shape: 1 256 24 24 (147456)
I0411 21:11:08.658002 21842 net.cpp:165] Memory required for data: 381029440
I0411 21:11:08.658006 21842 layer_factory.hpp:77] Creating layer conv6_2
I0411 21:11:08.658020 21842 net.cpp:100] Creating Layer conv6_2
I0411 21:11:08.658025 21842 net.cpp:434] conv6_2 <- conv6_1
I0411 21:11:08.658032 21842 net.cpp:408] conv6_2 -> conv6_2
I0411 21:11:08.673262 21842 net.cpp:150] Setting up conv6_2
I0411 21:11:08.673281 21842 net.cpp:157] Top shape: 1 512 12 12 (73728)
I0411 21:11:08.673287 21842 net.cpp:165] Memory required for data: 381324352
I0411 21:11:08.673305 21842 layer_factory.hpp:77] Creating layer conv6_2_relu
I0411 21:11:08.673313 21842 net.cpp:100] Creating Layer conv6_2_relu
I0411 21:11:08.673318 21842 net.cpp:434] conv6_2_relu <- conv6_2
I0411 21:11:08.673324 21842 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0411 21:11:08.673609 21842 net.cpp:150] Setting up conv6_2_relu
I0411 21:11:08.673624 21842 net.cpp:157] Top shape: 1 512 12 12 (73728)
I0411 21:11:08.673629 21842 net.cpp:165] Memory required for data: 381619264
I0411 21:11:08.673632 21842 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0411 21:11:08.673640 21842 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0411 21:11:08.673643 21842 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0411 21:11:08.673650 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0411 21:11:08.673658 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0411 21:11:08.673669 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0411 21:11:08.673676 21842 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0411 21:11:08.673785 21842 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0411 21:11:08.673794 21842 net.cpp:157] Top shape: 1 512 12 12 (73728)
I0411 21:11:08.673799 21842 net.cpp:157] Top shape: 1 512 12 12 (73728)
I0411 21:11:08.673804 21842 net.cpp:157] Top shape: 1 512 12 12 (73728)
I0411 21:11:08.673807 21842 net.cpp:157] Top shape: 1 512 12 12 (73728)
I0411 21:11:08.673811 21842 net.cpp:165] Memory required for data: 382798912
I0411 21:11:08.673815 21842 layer_factory.hpp:77] Creating layer conv7_1
I0411 21:11:08.673830 21842 net.cpp:100] Creating Layer conv7_1
I0411 21:11:08.673835 21842 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0411 21:11:08.673842 21842 net.cpp:408] conv7_1 -> conv7_1
I0411 21:11:08.675976 21842 net.cpp:150] Setting up conv7_1
I0411 21:11:08.675992 21842 net.cpp:157] Top shape: 1 128 12 12 (18432)
I0411 21:11:08.675997 21842 net.cpp:165] Memory required for data: 382872640
I0411 21:11:08.676004 21842 layer_factory.hpp:77] Creating layer conv7_1_relu
I0411 21:11:08.676012 21842 net.cpp:100] Creating Layer conv7_1_relu
I0411 21:11:08.676017 21842 net.cpp:434] conv7_1_relu <- conv7_1
I0411 21:11:08.676025 21842 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0411 21:11:08.676440 21842 net.cpp:150] Setting up conv7_1_relu
I0411 21:11:08.676470 21842 net.cpp:157] Top shape: 1 128 12 12 (18432)
I0411 21:11:08.676475 21842 net.cpp:165] Memory required for data: 382946368
I0411 21:11:08.676478 21842 layer_factory.hpp:77] Creating layer conv7_2
I0411 21:11:08.676491 21842 net.cpp:100] Creating Layer conv7_2
I0411 21:11:08.676496 21842 net.cpp:434] conv7_2 <- conv7_1
I0411 21:11:08.676506 21842 net.cpp:408] conv7_2 -> conv7_2
I0411 21:11:08.681596 21842 net.cpp:150] Setting up conv7_2
I0411 21:11:08.681618 21842 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0411 21:11:08.681623 21842 net.cpp:165] Memory required for data: 382983232
I0411 21:11:08.681630 21842 layer_factory.hpp:77] Creating layer conv7_2_relu
I0411 21:11:08.681638 21842 net.cpp:100] Creating Layer conv7_2_relu
I0411 21:11:08.681643 21842 net.cpp:434] conv7_2_relu <- conv7_2
I0411 21:11:08.681649 21842 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0411 21:11:08.682061 21842 net.cpp:150] Setting up conv7_2_relu
I0411 21:11:08.682078 21842 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0411 21:11:08.682082 21842 net.cpp:165] Memory required for data: 383020096
I0411 21:11:08.682086 21842 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0411 21:11:08.682094 21842 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0411 21:11:08.682099 21842 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0411 21:11:08.682107 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0411 21:11:08.682116 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0411 21:11:08.682123 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0411 21:11:08.682130 21842 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0411 21:11:08.682246 21842 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0411 21:11:08.682256 21842 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0411 21:11:08.682261 21842 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0411 21:11:08.682265 21842 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0411 21:11:08.682270 21842 net.cpp:157] Top shape: 1 256 6 6 (9216)
I0411 21:11:08.682273 21842 net.cpp:165] Memory required for data: 383167552
I0411 21:11:08.682276 21842 layer_factory.hpp:77] Creating layer conv8_1
I0411 21:11:08.682289 21842 net.cpp:100] Creating Layer conv8_1
I0411 21:11:08.682294 21842 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0411 21:11:08.682301 21842 net.cpp:408] conv8_1 -> conv8_1
I0411 21:11:08.684095 21842 net.cpp:150] Setting up conv8_1
I0411 21:11:08.684113 21842 net.cpp:157] Top shape: 1 128 6 6 (4608)
I0411 21:11:08.684118 21842 net.cpp:165] Memory required for data: 383185984
I0411 21:11:08.684125 21842 layer_factory.hpp:77] Creating layer conv8_1_relu
I0411 21:11:08.684134 21842 net.cpp:100] Creating Layer conv8_1_relu
I0411 21:11:08.684139 21842 net.cpp:434] conv8_1_relu <- conv8_1
I0411 21:11:08.684145 21842 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0411 21:11:08.684363 21842 net.cpp:150] Setting up conv8_1_relu
I0411 21:11:08.684376 21842 net.cpp:157] Top shape: 1 128 6 6 (4608)
I0411 21:11:08.684381 21842 net.cpp:165] Memory required for data: 383204416
I0411 21:11:08.684384 21842 layer_factory.hpp:77] Creating layer conv8_2
I0411 21:11:08.684397 21842 net.cpp:100] Creating Layer conv8_2
I0411 21:11:08.684402 21842 net.cpp:434] conv8_2 <- conv8_1
I0411 21:11:08.684409 21842 net.cpp:408] conv8_2 -> conv8_2
I0411 21:11:08.689476 21842 net.cpp:150] Setting up conv8_2
I0411 21:11:08.689493 21842 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0411 21:11:08.689498 21842 net.cpp:165] Memory required for data: 383220800
I0411 21:11:08.689505 21842 layer_factory.hpp:77] Creating layer conv8_2_relu
I0411 21:11:08.689513 21842 net.cpp:100] Creating Layer conv8_2_relu
I0411 21:11:08.689517 21842 net.cpp:434] conv8_2_relu <- conv8_2
I0411 21:11:08.689527 21842 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0411 21:11:08.689949 21842 net.cpp:150] Setting up conv8_2_relu
I0411 21:11:08.689965 21842 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0411 21:11:08.689980 21842 net.cpp:165] Memory required for data: 383237184
I0411 21:11:08.689985 21842 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0411 21:11:08.689993 21842 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0411 21:11:08.689997 21842 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0411 21:11:08.690006 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0411 21:11:08.690014 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0411 21:11:08.690021 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0411 21:11:08.690028 21842 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0411 21:11:08.690137 21842 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0411 21:11:08.690150 21842 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0411 21:11:08.690155 21842 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0411 21:11:08.690158 21842 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0411 21:11:08.690162 21842 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0411 21:11:08.690165 21842 net.cpp:165] Memory required for data: 383302720
I0411 21:11:08.690170 21842 layer_factory.hpp:77] Creating layer conv9_1
I0411 21:11:08.690181 21842 net.cpp:100] Creating Layer conv9_1
I0411 21:11:08.690186 21842 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0411 21:11:08.690196 21842 net.cpp:408] conv9_1 -> conv9_1
I0411 21:11:08.691805 21842 net.cpp:150] Setting up conv9_1
I0411 21:11:08.691823 21842 net.cpp:157] Top shape: 1 128 4 4 (2048)
I0411 21:11:08.691828 21842 net.cpp:165] Memory required for data: 383310912
I0411 21:11:08.691835 21842 layer_factory.hpp:77] Creating layer conv9_1_relu
I0411 21:11:08.691843 21842 net.cpp:100] Creating Layer conv9_1_relu
I0411 21:11:08.691846 21842 net.cpp:434] conv9_1_relu <- conv9_1
I0411 21:11:08.691854 21842 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0411 21:11:08.692275 21842 net.cpp:150] Setting up conv9_1_relu
I0411 21:11:08.692291 21842 net.cpp:157] Top shape: 1 128 4 4 (2048)
I0411 21:11:08.692293 21842 net.cpp:165] Memory required for data: 383319104
I0411 21:11:08.692297 21842 layer_factory.hpp:77] Creating layer conv9_2
I0411 21:11:08.692312 21842 net.cpp:100] Creating Layer conv9_2
I0411 21:11:08.692317 21842 net.cpp:434] conv9_2 <- conv9_1
I0411 21:11:08.692325 21842 net.cpp:408] conv9_2 -> conv9_2
I0411 21:11:08.697374 21842 net.cpp:150] Setting up conv9_2
I0411 21:11:08.697392 21842 net.cpp:157] Top shape: 1 256 2 2 (1024)
I0411 21:11:08.697396 21842 net.cpp:165] Memory required for data: 383323200
I0411 21:11:08.697403 21842 layer_factory.hpp:77] Creating layer conv9_2_relu
I0411 21:11:08.697410 21842 net.cpp:100] Creating Layer conv9_2_relu
I0411 21:11:08.697415 21842 net.cpp:434] conv9_2_relu <- conv9_2
I0411 21:11:08.697424 21842 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0411 21:11:08.697644 21842 net.cpp:150] Setting up conv9_2_relu
I0411 21:11:08.697656 21842 net.cpp:157] Top shape: 1 256 2 2 (1024)
I0411 21:11:08.697660 21842 net.cpp:165] Memory required for data: 383327296
I0411 21:11:08.697664 21842 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0411 21:11:08.697672 21842 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0411 21:11:08.697677 21842 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0411 21:11:08.697684 21842 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0411 21:11:08.697691 21842 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0411 21:11:08.697700 21842 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0411 21:11:08.697787 21842 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0411 21:11:08.697795 21842 net.cpp:157] Top shape: 1 256 2 2 (1024)
I0411 21:11:08.697800 21842 net.cpp:157] Top shape: 1 256 2 2 (1024)
I0411 21:11:08.697804 21842 net.cpp:157] Top shape: 1 256 2 2 (1024)
I0411 21:11:08.697808 21842 net.cpp:165] Memory required for data: 383339584
I0411 21:11:08.697811 21842 layer_factory.hpp:77] Creating layer conv4_3_norm
I0411 21:11:08.697832 21842 net.cpp:100] Creating Layer conv4_3_norm
I0411 21:11:08.697837 21842 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0411 21:11:08.697844 21842 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0411 21:11:08.698096 21842 net.cpp:150] Setting up conv4_3_norm
I0411 21:11:08.698107 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.698109 21842 net.cpp:165] Memory required for data: 388058176
I0411 21:11:08.698115 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0411 21:11:08.698122 21842 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0411 21:11:08.698127 21842 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0411 21:11:08.698133 21842 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0411 21:11:08.698141 21842 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0411 21:11:08.698148 21842 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0411 21:11:08.698231 21842 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0411 21:11:08.698240 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.698246 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.698249 21842 net.cpp:157] Top shape: 1 512 48 48 (1179648)
I0411 21:11:08.698253 21842 net.cpp:165] Memory required for data: 402213952
I0411 21:11:08.698258 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0411 21:11:08.698268 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0411 21:11:08.698273 21842 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0411 21:11:08.698281 21842 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0411 21:11:08.721114 21842 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0411 21:11:08.721137 21842 net.cpp:157] Top shape: 1 240 48 48 (552960)
I0411 21:11:08.721140 21842 net.cpp:165] Memory required for data: 404425792
I0411 21:11:08.721148 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0411 21:11:08.721160 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0411 21:11:08.721166 21842 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0411 21:11:08.721175 21842 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0411 21:11:08.721345 21842 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0411 21:11:08.721355 21842 net.cpp:157] Top shape: 1 48 48 240 (552960)
I0411 21:11:08.721364 21842 net.cpp:165] Memory required for data: 406637632
I0411 21:11:08.721369 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0411 21:11:08.721376 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0411 21:11:08.721380 21842 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0411 21:11:08.721386 21842 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0411 21:11:08.721437 21842 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0411 21:11:08.721447 21842 net.cpp:157] Top shape: 1 552960 (552960)
I0411 21:11:08.721451 21842 net.cpp:165] Memory required for data: 408849472
I0411 21:11:08.721455 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0411 21:11:08.721475 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0411 21:11:08.721480 21842 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0411 21:11:08.721487 21842 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0411 21:11:08.726732 21842 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0411 21:11:08.726748 21842 net.cpp:157] Top shape: 1 40 48 48 (92160)
I0411 21:11:08.726753 21842 net.cpp:165] Memory required for data: 409218112
I0411 21:11:08.726761 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0411 21:11:08.726769 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0411 21:11:08.726776 21842 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0411 21:11:08.726799 21842 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0411 21:11:08.726974 21842 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0411 21:11:08.726984 21842 net.cpp:157] Top shape: 1 48 48 40 (92160)
I0411 21:11:08.726987 21842 net.cpp:165] Memory required for data: 409586752
I0411 21:11:08.726991 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0411 21:11:08.726997 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0411 21:11:08.727002 21842 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0411 21:11:08.727008 21842 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0411 21:11:08.727048 21842 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0411 21:11:08.727057 21842 net.cpp:157] Top shape: 1 92160 (92160)
I0411 21:11:08.727061 21842 net.cpp:165] Memory required for data: 409955392
I0411 21:11:08.727064 21842 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0411 21:11:08.727074 21842 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0411 21:11:08.727078 21842 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0411 21:11:08.727084 21842 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0411 21:11:08.727090 21842 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0411 21:11:08.727134 21842 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0411 21:11:08.727144 21842 net.cpp:157] Top shape: 1 2 184320 (368640)
I0411 21:11:08.727147 21842 net.cpp:165] Memory required for data: 411429952
I0411 21:11:08.727151 21842 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0411 21:11:08.727161 21842 net.cpp:100] Creating Layer fc7_mbox_loc
I0411 21:11:08.727166 21842 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0411 21:11:08.727174 21842 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0411 21:11:08.771806 21842 net.cpp:150] Setting up fc7_mbox_loc
I0411 21:11:08.771839 21842 net.cpp:157] Top shape: 1 240 24 24 (138240)
I0411 21:11:08.771844 21842 net.cpp:165] Memory required for data: 411982912
I0411 21:11:08.771854 21842 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0411 21:11:08.771865 21842 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0411 21:11:08.771872 21842 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0411 21:11:08.771883 21842 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0411 21:11:08.772059 21842 net.cpp:150] Setting up fc7_mbox_loc_perm
I0411 21:11:08.772069 21842 net.cpp:157] Top shape: 1 24 24 240 (138240)
I0411 21:11:08.772073 21842 net.cpp:165] Memory required for data: 412535872
I0411 21:11:08.772078 21842 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0411 21:11:08.772086 21842 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0411 21:11:08.772091 21842 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0411 21:11:08.772097 21842 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0411 21:11:08.772137 21842 net.cpp:150] Setting up fc7_mbox_loc_flat
I0411 21:11:08.772147 21842 net.cpp:157] Top shape: 1 138240 (138240)
I0411 21:11:08.772151 21842 net.cpp:165] Memory required for data: 413088832
I0411 21:11:08.772156 21842 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0411 21:11:08.772167 21842 net.cpp:100] Creating Layer fc7_mbox_conf
I0411 21:11:08.772172 21842 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0411 21:11:08.772181 21842 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0411 21:11:08.780978 21842 net.cpp:150] Setting up fc7_mbox_conf
I0411 21:11:08.780997 21842 net.cpp:157] Top shape: 1 40 24 24 (23040)
I0411 21:11:08.781000 21842 net.cpp:165] Memory required for data: 413180992
I0411 21:11:08.781008 21842 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0411 21:11:08.781018 21842 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0411 21:11:08.781023 21842 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0411 21:11:08.781033 21842 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0411 21:11:08.781199 21842 net.cpp:150] Setting up fc7_mbox_conf_perm
I0411 21:11:08.781226 21842 net.cpp:157] Top shape: 1 24 24 40 (23040)
I0411 21:11:08.781230 21842 net.cpp:165] Memory required for data: 413273152
I0411 21:11:08.781234 21842 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0411 21:11:08.781242 21842 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0411 21:11:08.781247 21842 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0411 21:11:08.781253 21842 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0411 21:11:08.781296 21842 net.cpp:150] Setting up fc7_mbox_conf_flat
I0411 21:11:08.781306 21842 net.cpp:157] Top shape: 1 23040 (23040)
I0411 21:11:08.781309 21842 net.cpp:165] Memory required for data: 413365312
I0411 21:11:08.781312 21842 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0411 21:11:08.781322 21842 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0411 21:11:08.781327 21842 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0411 21:11:08.781333 21842 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0411 21:11:08.781339 21842 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0411 21:11:08.781383 21842 net.cpp:150] Setting up fc7_mbox_priorbox
I0411 21:11:08.781391 21842 net.cpp:157] Top shape: 1 2 46080 (92160)
I0411 21:11:08.781395 21842 net.cpp:165] Memory required for data: 413733952
I0411 21:11:08.781399 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0411 21:11:08.781409 21842 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0411 21:11:08.781415 21842 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0411 21:11:08.781424 21842 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0411 21:11:08.804471 21842 net.cpp:150] Setting up conv6_2_mbox_loc
I0411 21:11:08.804488 21842 net.cpp:157] Top shape: 1 240 12 12 (34560)
I0411 21:11:08.804493 21842 net.cpp:165] Memory required for data: 413872192
I0411 21:11:08.804502 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0411 21:11:08.804513 21842 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0411 21:11:08.804519 21842 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0411 21:11:08.804527 21842 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0411 21:11:08.804711 21842 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0411 21:11:08.804723 21842 net.cpp:157] Top shape: 1 12 12 240 (34560)
I0411 21:11:08.804726 21842 net.cpp:165] Memory required for data: 414010432
I0411 21:11:08.804729 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0411 21:11:08.804736 21842 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0411 21:11:08.804740 21842 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0411 21:11:08.804749 21842 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0411 21:11:08.804786 21842 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0411 21:11:08.804800 21842 net.cpp:157] Top shape: 1 34560 (34560)
I0411 21:11:08.804805 21842 net.cpp:165] Memory required for data: 414148672
I0411 21:11:08.804808 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0411 21:11:08.804821 21842 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0411 21:11:08.804826 21842 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0411 21:11:08.804831 21842 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0411 21:11:08.810113 21842 net.cpp:150] Setting up conv6_2_mbox_conf
I0411 21:11:08.810132 21842 net.cpp:157] Top shape: 1 40 12 12 (5760)
I0411 21:11:08.810137 21842 net.cpp:165] Memory required for data: 414171712
I0411 21:11:08.810144 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0411 21:11:08.810153 21842 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0411 21:11:08.810158 21842 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0411 21:11:08.810164 21842 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0411 21:11:08.810348 21842 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0411 21:11:08.810359 21842 net.cpp:157] Top shape: 1 12 12 40 (5760)
I0411 21:11:08.810364 21842 net.cpp:165] Memory required for data: 414194752
I0411 21:11:08.810381 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0411 21:11:08.810390 21842 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0411 21:11:08.810395 21842 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0411 21:11:08.810401 21842 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0411 21:11:08.810444 21842 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0411 21:11:08.810454 21842 net.cpp:157] Top shape: 1 5760 (5760)
I0411 21:11:08.810458 21842 net.cpp:165] Memory required for data: 414217792
I0411 21:11:08.810462 21842 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0411 21:11:08.810469 21842 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0411 21:11:08.810473 21842 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0411 21:11:08.810479 21842 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0411 21:11:08.810487 21842 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0411 21:11:08.810529 21842 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0411 21:11:08.810539 21842 net.cpp:157] Top shape: 1 2 11520 (23040)
I0411 21:11:08.810542 21842 net.cpp:165] Memory required for data: 414309952
I0411 21:11:08.810546 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0411 21:11:08.810559 21842 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0411 21:11:08.810564 21842 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0411 21:11:08.810570 21842 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0411 21:11:08.822911 21842 net.cpp:150] Setting up conv7_2_mbox_loc
I0411 21:11:08.822928 21842 net.cpp:157] Top shape: 1 240 6 6 (8640)
I0411 21:11:08.822933 21842 net.cpp:165] Memory required for data: 414344512
I0411 21:11:08.822940 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0411 21:11:08.822952 21842 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0411 21:11:08.822958 21842 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0411 21:11:08.822965 21842 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0411 21:11:08.823139 21842 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0411 21:11:08.823149 21842 net.cpp:157] Top shape: 1 6 6 240 (8640)
I0411 21:11:08.823153 21842 net.cpp:165] Memory required for data: 414379072
I0411 21:11:08.823158 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0411 21:11:08.823163 21842 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0411 21:11:08.823168 21842 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0411 21:11:08.823175 21842 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0411 21:11:08.823216 21842 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0411 21:11:08.823225 21842 net.cpp:157] Top shape: 1 8640 (8640)
I0411 21:11:08.823230 21842 net.cpp:165] Memory required for data: 414413632
I0411 21:11:08.823232 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0411 21:11:08.823243 21842 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0411 21:11:08.823247 21842 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0411 21:11:08.823256 21842 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0411 21:11:08.827044 21842 net.cpp:150] Setting up conv7_2_mbox_conf
I0411 21:11:08.827062 21842 net.cpp:157] Top shape: 1 40 6 6 (1440)
I0411 21:11:08.827066 21842 net.cpp:165] Memory required for data: 414419392
I0411 21:11:08.827075 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0411 21:11:08.827082 21842 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0411 21:11:08.827087 21842 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0411 21:11:08.827096 21842 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0411 21:11:08.827275 21842 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0411 21:11:08.827286 21842 net.cpp:157] Top shape: 1 6 6 40 (1440)
I0411 21:11:08.827289 21842 net.cpp:165] Memory required for data: 414425152
I0411 21:11:08.827293 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0411 21:11:08.827299 21842 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0411 21:11:08.827319 21842 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0411 21:11:08.827328 21842 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0411 21:11:08.827369 21842 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0411 21:11:08.827379 21842 net.cpp:157] Top shape: 1 1440 (1440)
I0411 21:11:08.827383 21842 net.cpp:165] Memory required for data: 414430912
I0411 21:11:08.827386 21842 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0411 21:11:08.827395 21842 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0411 21:11:08.827400 21842 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0411 21:11:08.827406 21842 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0411 21:11:08.827414 21842 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0411 21:11:08.827456 21842 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0411 21:11:08.827466 21842 net.cpp:157] Top shape: 1 2 2880 (5760)
I0411 21:11:08.827469 21842 net.cpp:165] Memory required for data: 414453952
I0411 21:11:08.827472 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0411 21:11:08.827486 21842 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0411 21:11:08.827489 21842 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0411 21:11:08.827497 21842 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0411 21:11:08.839990 21842 net.cpp:150] Setting up conv8_2_mbox_loc
I0411 21:11:08.840008 21842 net.cpp:157] Top shape: 1 240 4 4 (3840)
I0411 21:11:08.840013 21842 net.cpp:165] Memory required for data: 414469312
I0411 21:11:08.840036 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0411 21:11:08.840045 21842 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0411 21:11:08.840050 21842 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0411 21:11:08.840059 21842 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0411 21:11:08.840239 21842 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0411 21:11:08.840250 21842 net.cpp:157] Top shape: 1 4 4 240 (3840)
I0411 21:11:08.840253 21842 net.cpp:165] Memory required for data: 414484672
I0411 21:11:08.840257 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0411 21:11:08.840265 21842 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0411 21:11:08.840270 21842 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0411 21:11:08.840276 21842 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0411 21:11:08.840317 21842 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0411 21:11:08.840327 21842 net.cpp:157] Top shape: 1 3840 (3840)
I0411 21:11:08.840330 21842 net.cpp:165] Memory required for data: 414500032
I0411 21:11:08.840333 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0411 21:11:08.840344 21842 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0411 21:11:08.840349 21842 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0411 21:11:08.840358 21842 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0411 21:11:08.843828 21842 net.cpp:150] Setting up conv8_2_mbox_conf
I0411 21:11:08.843847 21842 net.cpp:157] Top shape: 1 40 4 4 (640)
I0411 21:11:08.843850 21842 net.cpp:165] Memory required for data: 414502592
I0411 21:11:08.843858 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0411 21:11:08.843865 21842 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0411 21:11:08.843870 21842 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0411 21:11:08.843879 21842 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0411 21:11:08.844061 21842 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0411 21:11:08.844071 21842 net.cpp:157] Top shape: 1 4 4 40 (640)
I0411 21:11:08.844075 21842 net.cpp:165] Memory required for data: 414505152
I0411 21:11:08.844079 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0411 21:11:08.844086 21842 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0411 21:11:08.844091 21842 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0411 21:11:08.844110 21842 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0411 21:11:08.844156 21842 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0411 21:11:08.844166 21842 net.cpp:157] Top shape: 1 640 (640)
I0411 21:11:08.844168 21842 net.cpp:165] Memory required for data: 414507712
I0411 21:11:08.844172 21842 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0411 21:11:08.844182 21842 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0411 21:11:08.844187 21842 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0411 21:11:08.844192 21842 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0411 21:11:08.844198 21842 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0411 21:11:08.844243 21842 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0411 21:11:08.844251 21842 net.cpp:157] Top shape: 1 2 1280 (2560)
I0411 21:11:08.844255 21842 net.cpp:165] Memory required for data: 414517952
I0411 21:11:08.844259 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0411 21:11:08.844269 21842 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0411 21:11:08.844274 21842 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0411 21:11:08.844283 21842 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0411 21:11:08.857985 21842 net.cpp:150] Setting up conv9_2_mbox_loc
I0411 21:11:08.858002 21842 net.cpp:157] Top shape: 1 240 2 2 (960)
I0411 21:11:08.858006 21842 net.cpp:165] Memory required for data: 414521792
I0411 21:11:08.858014 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0411 21:11:08.858022 21842 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0411 21:11:08.858027 21842 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0411 21:11:08.858036 21842 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0411 21:11:08.858229 21842 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0411 21:11:08.858240 21842 net.cpp:157] Top shape: 1 2 2 240 (960)
I0411 21:11:08.858244 21842 net.cpp:165] Memory required for data: 414525632
I0411 21:11:08.858248 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0411 21:11:08.858255 21842 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0411 21:11:08.858260 21842 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0411 21:11:08.858266 21842 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0411 21:11:08.858309 21842 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0411 21:11:08.858319 21842 net.cpp:157] Top shape: 1 960 (960)
I0411 21:11:08.858322 21842 net.cpp:165] Memory required for data: 414529472
I0411 21:11:08.858326 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0411 21:11:08.858336 21842 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0411 21:11:08.858341 21842 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0411 21:11:08.858350 21842 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0411 21:11:08.863677 21842 net.cpp:150] Setting up conv9_2_mbox_conf
I0411 21:11:08.863693 21842 net.cpp:157] Top shape: 1 40 2 2 (160)
I0411 21:11:08.863698 21842 net.cpp:165] Memory required for data: 414530112
I0411 21:11:08.863705 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0411 21:11:08.863714 21842 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0411 21:11:08.863720 21842 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0411 21:11:08.863729 21842 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0411 21:11:08.863910 21842 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0411 21:11:08.863921 21842 net.cpp:157] Top shape: 1 2 2 40 (160)
I0411 21:11:08.863925 21842 net.cpp:165] Memory required for data: 414530752
I0411 21:11:08.863929 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0411 21:11:08.863936 21842 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0411 21:11:08.863941 21842 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0411 21:11:08.863947 21842 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0411 21:11:08.864006 21842 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0411 21:11:08.864017 21842 net.cpp:157] Top shape: 1 160 (160)
I0411 21:11:08.864019 21842 net.cpp:165] Memory required for data: 414531392
I0411 21:11:08.864023 21842 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0411 21:11:08.864032 21842 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0411 21:11:08.864037 21842 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0411 21:11:08.864042 21842 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0411 21:11:08.864048 21842 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0411 21:11:08.864094 21842 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0411 21:11:08.864102 21842 net.cpp:157] Top shape: 1 2 320 (640)
I0411 21:11:08.864106 21842 net.cpp:165] Memory required for data: 414533952
I0411 21:11:08.864110 21842 layer_factory.hpp:77] Creating layer mbox_loc
I0411 21:11:08.864117 21842 net.cpp:100] Creating Layer mbox_loc
I0411 21:11:08.864123 21842 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0411 21:11:08.864130 21842 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0411 21:11:08.864138 21842 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0411 21:11:08.864143 21842 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0411 21:11:08.864148 21842 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0411 21:11:08.864152 21842 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0411 21:11:08.864158 21842 net.cpp:408] mbox_loc -> mbox_loc
I0411 21:11:08.864200 21842 net.cpp:150] Setting up mbox_loc
I0411 21:11:08.864213 21842 net.cpp:157] Top shape: 1 739200 (739200)
I0411 21:11:08.864217 21842 net.cpp:165] Memory required for data: 417490752
I0411 21:11:08.864220 21842 layer_factory.hpp:77] Creating layer mbox_conf
I0411 21:11:08.864228 21842 net.cpp:100] Creating Layer mbox_conf
I0411 21:11:08.864233 21842 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0411 21:11:08.864239 21842 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0411 21:11:08.864244 21842 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0411 21:11:08.864249 21842 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0411 21:11:08.864253 21842 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0411 21:11:08.864259 21842 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0411 21:11:08.864264 21842 net.cpp:408] mbox_conf -> mbox_conf
I0411 21:11:08.864302 21842 net.cpp:150] Setting up mbox_conf
I0411 21:11:08.864315 21842 net.cpp:157] Top shape: 1 123200 (123200)
I0411 21:11:08.864317 21842 net.cpp:165] Memory required for data: 417983552
I0411 21:11:08.864321 21842 layer_factory.hpp:77] Creating layer mbox_priorbox
I0411 21:11:08.864329 21842 net.cpp:100] Creating Layer mbox_priorbox
I0411 21:11:08.864333 21842 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0411 21:11:08.864339 21842 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0411 21:11:08.864343 21842 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0411 21:11:08.864348 21842 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0411 21:11:08.864352 21842 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0411 21:11:08.864356 21842 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0411 21:11:08.864362 21842 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0411 21:11:08.864400 21842 net.cpp:150] Setting up mbox_priorbox
I0411 21:11:08.864414 21842 net.cpp:157] Top shape: 1 2 246400 (492800)
I0411 21:11:08.864418 21842 net.cpp:165] Memory required for data: 419954752
I0411 21:11:08.864423 21842 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0411 21:11:08.864437 21842 net.cpp:100] Creating Layer mbox_conf_reshape
I0411 21:11:08.864441 21842 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0411 21:11:08.864449 21842 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0411 21:11:08.864503 21842 net.cpp:150] Setting up mbox_conf_reshape
I0411 21:11:08.864512 21842 net.cpp:157] Top shape: 1 61600 2 (123200)
I0411 21:11:08.864516 21842 net.cpp:165] Memory required for data: 420447552
I0411 21:11:08.864519 21842 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0411 21:11:08.864537 21842 net.cpp:100] Creating Layer mbox_conf_softmax
I0411 21:11:08.864542 21842 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0411 21:11:08.864548 21842 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0411 21:11:08.864887 21842 net.cpp:150] Setting up mbox_conf_softmax
I0411 21:11:08.864902 21842 net.cpp:157] Top shape: 1 61600 2 (123200)
I0411 21:11:08.864907 21842 net.cpp:165] Memory required for data: 420940352
I0411 21:11:08.864909 21842 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0411 21:11:08.864915 21842 net.cpp:100] Creating Layer mbox_conf_flatten
I0411 21:11:08.864920 21842 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0411 21:11:08.864926 21842 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0411 21:11:08.864970 21842 net.cpp:150] Setting up mbox_conf_flatten
I0411 21:11:08.864977 21842 net.cpp:157] Top shape: 1 123200 (123200)
I0411 21:11:08.864980 21842 net.cpp:165] Memory required for data: 421433152
I0411 21:11:08.864984 21842 layer_factory.hpp:77] Creating layer detection_out
I0411 21:11:08.865000 21842 net.cpp:100] Creating Layer detection_out
I0411 21:11:08.865005 21842 net.cpp:434] detection_out <- mbox_loc
I0411 21:11:08.865008 21842 net.cpp:434] detection_out <- mbox_conf_flatten
I0411 21:11:08.865013 21842 net.cpp:434] detection_out <- mbox_priorbox
I0411 21:11:08.865020 21842 net.cpp:408] detection_out -> detection_out
I0411 21:11:08.865514 21842 net.cpp:150] Setting up detection_out
I0411 21:11:08.865530 21842 net.cpp:157] Top shape: 1 1 1 15 (15)
I0411 21:11:08.865535 21842 net.cpp:165] Memory required for data: 421433212
I0411 21:11:08.865538 21842 layer_factory.hpp:77] Creating layer detection_eval
I0411 21:11:08.865547 21842 net.cpp:100] Creating Layer detection_eval
I0411 21:11:08.865552 21842 net.cpp:434] detection_eval <- detection_out
I0411 21:11:08.865559 21842 net.cpp:434] detection_eval <- label
I0411 21:11:08.865566 21842 net.cpp:408] detection_eval -> detection_eval
I0411 21:11:08.865643 21842 net.cpp:150] Setting up detection_eval
I0411 21:11:08.865653 21842 net.cpp:157] Top shape: 1 1 2 5 (10)
I0411 21:11:08.865656 21842 net.cpp:165] Memory required for data: 421433252
I0411 21:11:08.865659 21842 net.cpp:228] detection_eval does not need backward computation.
I0411 21:11:08.865664 21842 net.cpp:228] detection_out does not need backward computation.
I0411 21:11:08.865669 21842 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0411 21:11:08.865672 21842 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0411 21:11:08.865676 21842 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0411 21:11:08.865679 21842 net.cpp:228] mbox_priorbox does not need backward computation.
I0411 21:11:08.865685 21842 net.cpp:228] mbox_conf does not need backward computation.
I0411 21:11:08.865690 21842 net.cpp:228] mbox_loc does not need backward computation.
I0411 21:11:08.865696 21842 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.865700 21842 net.cpp:228] conv9_2_mbox_conf_flat does not need backward computation.
I0411 21:11:08.865703 21842 net.cpp:228] conv9_2_mbox_conf_perm does not need backward computation.
I0411 21:11:08.865707 21842 net.cpp:228] conv9_2_mbox_conf does not need backward computation.
I0411 21:11:08.865711 21842 net.cpp:228] conv9_2_mbox_loc_flat does not need backward computation.
I0411 21:11:08.865715 21842 net.cpp:228] conv9_2_mbox_loc_perm does not need backward computation.
I0411 21:11:08.865720 21842 net.cpp:228] conv9_2_mbox_loc does not need backward computation.
I0411 21:11:08.865723 21842 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.865727 21842 net.cpp:228] conv8_2_mbox_conf_flat does not need backward computation.
I0411 21:11:08.865731 21842 net.cpp:228] conv8_2_mbox_conf_perm does not need backward computation.
I0411 21:11:08.865734 21842 net.cpp:228] conv8_2_mbox_conf does not need backward computation.
I0411 21:11:08.865738 21842 net.cpp:228] conv8_2_mbox_loc_flat does not need backward computation.
I0411 21:11:08.865753 21842 net.cpp:228] conv8_2_mbox_loc_perm does not need backward computation.
I0411 21:11:08.865758 21842 net.cpp:228] conv8_2_mbox_loc does not need backward computation.
I0411 21:11:08.865762 21842 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.865767 21842 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0411 21:11:08.865770 21842 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0411 21:11:08.865774 21842 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0411 21:11:08.865778 21842 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0411 21:11:08.865782 21842 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0411 21:11:08.865787 21842 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0411 21:11:08.865790 21842 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0411 21:11:08.865795 21842 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0411 21:11:08.865800 21842 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0411 21:11:08.865804 21842 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0411 21:11:08.865808 21842 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0411 21:11:08.865811 21842 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0411 21:11:08.865815 21842 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0411 21:11:08.865820 21842 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0411 21:11:08.865824 21842 net.cpp:228] fc7_mbox_conf_flat does not need backward computation.
I0411 21:11:08.865828 21842 net.cpp:228] fc7_mbox_conf_perm does not need backward computation.
I0411 21:11:08.865833 21842 net.cpp:228] fc7_mbox_conf does not need backward computation.
I0411 21:11:08.865837 21842 net.cpp:228] fc7_mbox_loc_flat does not need backward computation.
I0411 21:11:08.865841 21842 net.cpp:228] fc7_mbox_loc_perm does not need backward computation.
I0411 21:11:08.865845 21842 net.cpp:228] fc7_mbox_loc does not need backward computation.
I0411 21:11:08.865849 21842 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0411 21:11:08.865854 21842 net.cpp:228] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0411 21:11:08.865859 21842 net.cpp:228] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0411 21:11:08.865864 21842 net.cpp:228] conv4_3_norm_mbox_conf does not need backward computation.
I0411 21:11:08.865867 21842 net.cpp:228] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0411 21:11:08.865871 21842 net.cpp:228] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0411 21:11:08.865875 21842 net.cpp:228] conv4_3_norm_mbox_loc does not need backward computation.
I0411 21:11:08.865880 21842 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0411 21:11:08.865883 21842 net.cpp:228] conv4_3_norm does not need backward computation.
I0411 21:11:08.865888 21842 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0411 21:11:08.865892 21842 net.cpp:228] conv9_2_relu does not need backward computation.
I0411 21:11:08.865896 21842 net.cpp:228] conv9_2 does not need backward computation.
I0411 21:11:08.865900 21842 net.cpp:228] conv9_1_relu does not need backward computation.
I0411 21:11:08.865905 21842 net.cpp:228] conv9_1 does not need backward computation.
I0411 21:11:08.865908 21842 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0411 21:11:08.865912 21842 net.cpp:228] conv8_2_relu does not need backward computation.
I0411 21:11:08.865916 21842 net.cpp:228] conv8_2 does not need backward computation.
I0411 21:11:08.865921 21842 net.cpp:228] conv8_1_relu does not need backward computation.
I0411 21:11:08.865924 21842 net.cpp:228] conv8_1 does not need backward computation.
I0411 21:11:08.865934 21842 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0411 21:11:08.865939 21842 net.cpp:228] conv7_2_relu does not need backward computation.
I0411 21:11:08.865942 21842 net.cpp:228] conv7_2 does not need backward computation.
I0411 21:11:08.865947 21842 net.cpp:228] conv7_1_relu does not need backward computation.
I0411 21:11:08.865950 21842 net.cpp:228] conv7_1 does not need backward computation.
I0411 21:11:08.865954 21842 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0411 21:11:08.865959 21842 net.cpp:228] conv6_2_relu does not need backward computation.
I0411 21:11:08.865963 21842 net.cpp:228] conv6_2 does not need backward computation.
I0411 21:11:08.865967 21842 net.cpp:228] conv6_1_relu does not need backward computation.
I0411 21:11:08.865970 21842 net.cpp:228] conv6_1 does not need backward computation.
I0411 21:11:08.865975 21842 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0411 21:11:08.865979 21842 net.cpp:228] relu7 does not need backward computation.
I0411 21:11:08.865983 21842 net.cpp:228] fc7 does not need backward computation.
I0411 21:11:08.865988 21842 net.cpp:228] relu6 does not need backward computation.
I0411 21:11:08.865990 21842 net.cpp:228] fc6 does not need backward computation.
I0411 21:11:08.865994 21842 net.cpp:228] pool5 does not need backward computation.
I0411 21:11:08.865998 21842 net.cpp:228] relu5_3 does not need backward computation.
I0411 21:11:08.866003 21842 net.cpp:228] conv5_3 does not need backward computation.
I0411 21:11:08.866006 21842 net.cpp:228] relu5_2 does not need backward computation.
I0411 21:11:08.866010 21842 net.cpp:228] conv5_2 does not need backward computation.
I0411 21:11:08.866014 21842 net.cpp:228] relu5_1 does not need backward computation.
I0411 21:11:08.866017 21842 net.cpp:228] conv5_1 does not need backward computation.
I0411 21:11:08.866021 21842 net.cpp:228] pool4 does not need backward computation.
I0411 21:11:08.866026 21842 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0411 21:11:08.866030 21842 net.cpp:228] relu4_3 does not need backward computation.
I0411 21:11:08.866034 21842 net.cpp:228] conv4_3 does not need backward computation.
I0411 21:11:08.866037 21842 net.cpp:228] relu4_2 does not need backward computation.
I0411 21:11:08.866041 21842 net.cpp:228] conv4_2 does not need backward computation.
I0411 21:11:08.866045 21842 net.cpp:228] relu4_1 does not need backward computation.
I0411 21:11:08.866048 21842 net.cpp:228] conv4_1 does not need backward computation.
I0411 21:11:08.866052 21842 net.cpp:228] pool3 does not need backward computation.
I0411 21:11:08.866056 21842 net.cpp:228] relu3_3 does not need backward computation.
I0411 21:11:08.866060 21842 net.cpp:228] conv3_3 does not need backward computation.
I0411 21:11:08.866065 21842 net.cpp:228] relu3_2 does not need backward computation.
I0411 21:11:08.866068 21842 net.cpp:228] conv3_2 does not need backward computation.
I0411 21:11:08.866072 21842 net.cpp:228] relu3_1 does not need backward computation.
I0411 21:11:08.866076 21842 net.cpp:228] conv3_1 does not need backward computation.
I0411 21:11:08.866080 21842 net.cpp:228] pool2 does not need backward computation.
I0411 21:11:08.866084 21842 net.cpp:228] relu2_2 does not need backward computation.
I0411 21:11:08.866087 21842 net.cpp:228] conv2_2 does not need backward computation.
I0411 21:11:08.866091 21842 net.cpp:228] relu2_1 does not need backward computation.
I0411 21:11:08.866096 21842 net.cpp:228] conv2_1 does not need backward computation.
I0411 21:11:08.866099 21842 net.cpp:228] pool1 does not need backward computation.
I0411 21:11:08.866102 21842 net.cpp:228] relu1_2 does not need backward computation.
I0411 21:11:08.866106 21842 net.cpp:228] conv1_2 does not need backward computation.
I0411 21:11:08.866111 21842 net.cpp:228] relu1_1 does not need backward computation.
I0411 21:11:08.866113 21842 net.cpp:228] conv1_1 does not need backward computation.
I0411 21:11:08.866118 21842 net.cpp:228] data_data_0_split does not need backward computation.
I0411 21:11:08.866128 21842 net.cpp:228] data does not need backward computation.
I0411 21:11:08.866132 21842 net.cpp:270] This network produces output detection_eval
I0411 21:11:08.866230 21842 net.cpp:283] Network initialization done.
I0411 21:11:08.866608 21842 solver.cpp:75] Solver scaffolding done.
I0411 21:11:08.872473 21842 caffe.cpp:155] Finetuning from models/model_pre_train_syn.caffemodel
I0411 21:11:09.340728 21842 net.cpp:761] Ignoring source layer mbox_loss
I0411 21:11:09.361047 21842 parallel.cpp:392] GPUs pairs 2:3
I0411 21:11:09.749047 21842 annotated_data_layer.cpp:62] output data size: 16,3,384,384
I0411 21:11:10.715152 21842 parallel.cpp:425] Starting Optimization
I0411 21:11:10.715229 21842 solver.cpp:294] Solving VGG_text_text_polygon_precise_fix_order_384x384_train
I0411 21:11:10.715236 21842 solver.cpp:295] Learning Rate Policy: multistep
I0411 21:11:10.730825 21842 blocking_queue.cpp:50] Data layer prefetch queue empty
I0411 21:11:13.334445 21842 solver.cpp:243] Iteration 0, loss = 6.08991
I0411 21:11:13.334511 21842 solver.cpp:259]     Train net output #0: mbox_loss = 6.08991 (* 1 = 6.08991 loss)
I0411 21:11:14.823029 21842 sgd_solver.cpp:138] Iteration 0, lr = 0.0001
I0411 21:15:28.233300 21842 solver.cpp:243] Iteration 100, loss = 3.57642
I0411 21:15:28.233434 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.4504 (* 1 = 3.4504 loss)
I0411 21:15:28.233464 21842 sgd_solver.cpp:138] Iteration 100, lr = 0.0001
I0411 21:19:40.680651 21842 solver.cpp:243] Iteration 200, loss = 3.40554
I0411 21:19:40.680855 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.89808 (* 1 = 2.89808 loss)
I0411 21:19:41.330160 21842 sgd_solver.cpp:138] Iteration 200, lr = 0.0001
I0411 21:23:48.417088 21842 solver.cpp:243] Iteration 300, loss = 3.29457
I0411 21:23:48.417261 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.81 (* 1 = 2.81 loss)
I0411 21:23:49.151935 21842 sgd_solver.cpp:138] Iteration 300, lr = 0.0001
I0411 21:27:55.842880 21842 solver.cpp:243] Iteration 400, loss = 3.19788
I0411 21:27:55.843042 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.11013 (* 1 = 3.11013 loss)
I0411 21:27:55.843076 21842 sgd_solver.cpp:138] Iteration 400, lr = 0.0001
I0411 21:32:05.949772 21842 solver.cpp:243] Iteration 500, loss = 3.19411
I0411 21:32:05.949910 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.29905 (* 1 = 3.29905 loss)
I0411 21:32:06.581809 21842 sgd_solver.cpp:138] Iteration 500, lr = 0.0001
I0411 21:36:20.723176 21842 solver.cpp:243] Iteration 600, loss = 3.13442
I0411 21:36:20.723342 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65845 (* 1 = 2.65845 loss)
I0411 21:36:21.363045 21842 sgd_solver.cpp:138] Iteration 600, lr = 0.0001
I0411 21:40:26.156529 21842 solver.cpp:243] Iteration 700, loss = 3.12309
I0411 21:40:26.156714 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.52125 (* 1 = 3.52125 loss)
I0411 21:40:26.156750 21842 sgd_solver.cpp:138] Iteration 700, lr = 0.0001
I0411 21:44:35.798934 21842 solver.cpp:243] Iteration 800, loss = 3.10439
I0411 21:44:35.799127 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.19324 (* 1 = 3.19324 loss)
I0411 21:44:37.248028 21842 sgd_solver.cpp:138] Iteration 800, lr = 0.0001
I0411 21:48:50.825369 21842 solver.cpp:243] Iteration 900, loss = 3.03053
I0411 21:48:50.825529 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.0668 (* 1 = 3.0668 loss)
I0411 21:48:50.825563 21842 sgd_solver.cpp:138] Iteration 900, lr = 0.0001
I0411 21:52:56.140241 21842 solver.cpp:243] Iteration 1000, loss = 3.10377
I0411 21:52:56.140401 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.62119 (* 1 = 3.62119 loss)
I0411 21:52:56.140442 21842 sgd_solver.cpp:138] Iteration 1000, lr = 0.0001
I0411 21:57:04.440134 21842 solver.cpp:243] Iteration 1100, loss = 2.97808
I0411 21:57:04.440377 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.14263 (* 1 = 3.14263 loss)
I0411 21:57:05.097251 21842 sgd_solver.cpp:138] Iteration 1100, lr = 0.0001
I0411 22:01:19.687849 21842 solver.cpp:243] Iteration 1200, loss = 2.97946
I0411 22:01:19.688000 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.4419 (* 1 = 3.4419 loss)
I0411 22:01:21.136982 21842 sgd_solver.cpp:138] Iteration 1200, lr = 0.0001
I0411 22:05:32.688097 21842 solver.cpp:243] Iteration 1300, loss = 3.03336
I0411 22:05:32.688271 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.90988 (* 1 = 2.90988 loss)
I0411 22:05:32.688319 21842 sgd_solver.cpp:138] Iteration 1300, lr = 0.0001
I0411 22:09:48.705305 21842 solver.cpp:243] Iteration 1400, loss = 3.00197
I0411 22:09:48.705498 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.9789 (* 1 = 2.9789 loss)
I0411 22:09:50.160287 21842 sgd_solver.cpp:138] Iteration 1400, lr = 0.0001
I0411 22:14:03.607352 21842 solver.cpp:243] Iteration 1500, loss = 2.95993
I0411 22:14:03.607558 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8597 (* 1 = 2.8597 loss)
I0411 22:14:04.267871 21842 sgd_solver.cpp:138] Iteration 1500, lr = 0.0001
I0411 22:18:13.580421 21842 solver.cpp:243] Iteration 1600, loss = 3.05949
I0411 22:18:13.580596 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.92335 (* 1 = 2.92335 loss)
I0411 22:18:13.580631 21842 sgd_solver.cpp:138] Iteration 1600, lr = 0.0001
I0411 22:22:27.563275 21842 solver.cpp:243] Iteration 1700, loss = 3.0004
I0411 22:22:27.563446 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.3542 (* 1 = 3.3542 loss)
I0411 22:22:27.563482 21842 sgd_solver.cpp:138] Iteration 1700, lr = 0.0001
I0411 22:26:38.229691 21842 solver.cpp:243] Iteration 1800, loss = 3.01832
I0411 22:26:38.229856 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.00092 (* 1 = 3.00092 loss)
I0411 22:26:38.229897 21842 sgd_solver.cpp:138] Iteration 1800, lr = 0.0001
I0411 22:30:48.651510 21842 solver.cpp:243] Iteration 1900, loss = 2.95382
I0411 22:30:48.651669 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.24361 (* 1 = 3.24361 loss)
I0411 22:30:49.389015 21842 sgd_solver.cpp:138] Iteration 1900, lr = 0.0001
I0411 22:35:02.833359 21842 solver.cpp:243] Iteration 2000, loss = 2.94863
I0411 22:35:02.833544 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.54769 (* 1 = 2.54769 loss)
I0411 22:35:03.492619 21842 sgd_solver.cpp:138] Iteration 2000, lr = 0.0001
I0411 22:39:06.736331 21842 solver.cpp:243] Iteration 2100, loss = 2.99637
I0411 22:39:06.736516 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.71323 (* 1 = 2.71323 loss)
I0411 22:39:07.349378 21842 sgd_solver.cpp:138] Iteration 2100, lr = 0.0001
I0411 22:43:15.007598 21842 solver.cpp:243] Iteration 2200, loss = 2.92476
I0411 22:43:15.007794 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55769 (* 1 = 2.55769 loss)
I0411 22:43:15.007833 21842 sgd_solver.cpp:138] Iteration 2200, lr = 0.0001
I0411 22:47:28.783901 21842 solver.cpp:243] Iteration 2300, loss = 2.86242
I0411 22:47:28.784056 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49243 (* 1 = 2.49243 loss)
I0411 22:47:29.509752 21842 sgd_solver.cpp:138] Iteration 2300, lr = 0.0001
I0411 22:51:33.572213 21842 solver.cpp:243] Iteration 2400, loss = 2.95983
I0411 22:51:33.572398 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.92931 (* 1 = 2.92931 loss)
I0411 22:51:33.572434 21842 sgd_solver.cpp:138] Iteration 2400, lr = 0.0001
I0411 22:55:44.317750 21842 solver.cpp:243] Iteration 2500, loss = 2.9364
I0411 22:55:44.317909 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.6182 (* 1 = 3.6182 loss)
I0411 22:55:45.142354 21842 sgd_solver.cpp:138] Iteration 2500, lr = 0.0001
I0411 22:59:57.485605 21842 solver.cpp:243] Iteration 2600, loss = 2.83153
I0411 22:59:57.485769 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.76368 (* 1 = 2.76368 loss)
I0411 22:59:57.485802 21842 sgd_solver.cpp:138] Iteration 2600, lr = 0.0001
I0411 23:04:04.952234 21842 solver.cpp:243] Iteration 2700, loss = 2.93156
I0411 23:04:04.952438 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.81733 (* 1 = 2.81733 loss)
I0411 23:04:06.344036 21842 sgd_solver.cpp:138] Iteration 2700, lr = 0.0001
I0411 23:08:12.389752 21842 solver.cpp:243] Iteration 2800, loss = 2.9174
I0411 23:08:12.389924 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.15193 (* 1 = 3.15193 loss)
I0411 23:08:12.389964 21842 sgd_solver.cpp:138] Iteration 2800, lr = 0.0001
I0411 23:12:23.763998 21842 solver.cpp:243] Iteration 2900, loss = 2.81684
I0411 23:12:23.764119 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.0387 (* 1 = 3.0387 loss)
I0411 23:12:23.764161 21842 sgd_solver.cpp:138] Iteration 2900, lr = 0.0001
I0411 23:16:33.440642 21842 solver.cpp:243] Iteration 3000, loss = 2.87593
I0411 23:16:33.440811 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.47212 (* 1 = 3.47212 loss)
I0411 23:16:34.425714 21842 sgd_solver.cpp:138] Iteration 3000, lr = 0.0001
I0411 23:20:41.442276 21842 solver.cpp:243] Iteration 3100, loss = 2.87385
I0411 23:20:41.442461 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.24228 (* 1 = 3.24228 loss)
I0411 23:20:42.245079 21842 sgd_solver.cpp:138] Iteration 3100, lr = 0.0001
I0411 23:24:49.094099 21842 solver.cpp:243] Iteration 3200, loss = 2.94437
I0411 23:24:49.094282 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.76749 (* 1 = 2.76749 loss)
I0411 23:24:50.510143 21842 sgd_solver.cpp:138] Iteration 3200, lr = 0.0001
I0411 23:28:55.054059 21842 solver.cpp:243] Iteration 3300, loss = 2.84924
I0411 23:28:55.054240 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.78622 (* 1 = 2.78622 loss)
I0411 23:28:55.054275 21842 sgd_solver.cpp:138] Iteration 3300, lr = 0.0001
I0411 23:33:11.154572 21842 solver.cpp:243] Iteration 3400, loss = 2.83664
I0411 23:33:11.154752 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.16567 (* 1 = 3.16567 loss)
I0411 23:33:11.154794 21842 sgd_solver.cpp:138] Iteration 3400, lr = 0.0001
I0411 23:37:19.667994 21842 solver.cpp:243] Iteration 3500, loss = 2.90402
I0411 23:37:19.668171 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.54559 (* 1 = 2.54559 loss)
I0411 23:37:19.668205 21842 sgd_solver.cpp:138] Iteration 3500, lr = 0.0001
I0411 23:41:31.290904 21842 solver.cpp:243] Iteration 3600, loss = 2.85723
I0411 23:41:31.291083 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.83474 (* 1 = 2.83474 loss)
I0411 23:41:32.064790 21842 sgd_solver.cpp:138] Iteration 3600, lr = 0.0001
I0411 23:45:40.507735 21842 solver.cpp:243] Iteration 3700, loss = 2.81618
I0411 23:45:40.507889 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.66645 (* 1 = 2.66645 loss)
I0411 23:45:41.153749 21842 sgd_solver.cpp:138] Iteration 3700, lr = 0.0001
I0411 23:49:44.457758 21842 solver.cpp:243] Iteration 3800, loss = 2.84033
I0411 23:49:44.457926 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.99393 (* 1 = 2.99393 loss)
I0411 23:49:44.457958 21842 sgd_solver.cpp:138] Iteration 3800, lr = 0.0001
I0411 23:53:53.969353 21842 solver.cpp:243] Iteration 3900, loss = 2.82776
I0411 23:53:53.969535 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.88635 (* 1 = 2.88635 loss)
I0411 23:53:53.969569 21842 sgd_solver.cpp:138] Iteration 3900, lr = 0.0001
I0411 23:58:00.282284 21842 solver.cpp:243] Iteration 4000, loss = 2.8366
I0411 23:58:00.282419 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.65723 (* 1 = 3.65723 loss)
I0411 23:58:00.282455 21842 sgd_solver.cpp:138] Iteration 4000, lr = 0.0001
I0412 00:02:12.252568 21842 solver.cpp:243] Iteration 4100, loss = 2.8773
I0412 00:02:12.252733 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27628 (* 1 = 2.27628 loss)
I0412 00:02:13.654165 21842 sgd_solver.cpp:138] Iteration 4100, lr = 0.0001
I0412 00:06:31.763924 21842 solver.cpp:243] Iteration 4200, loss = 2.82278
I0412 00:06:31.764118 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.98204 (* 1 = 2.98204 loss)
I0412 00:06:31.764153 21842 sgd_solver.cpp:138] Iteration 4200, lr = 0.0001
I0412 00:10:35.672719 21842 solver.cpp:243] Iteration 4300, loss = 2.8481
I0412 00:10:35.672910 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.60984 (* 1 = 2.60984 loss)
I0412 00:10:37.107759 21842 sgd_solver.cpp:138] Iteration 4300, lr = 0.0001
I0412 00:14:40.380852 21842 solver.cpp:243] Iteration 4400, loss = 2.84188
I0412 00:14:40.381016 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25246 (* 1 = 2.25246 loss)
I0412 00:14:41.031682 21842 sgd_solver.cpp:138] Iteration 4400, lr = 0.0001
I0412 00:18:50.342641 21842 solver.cpp:243] Iteration 4500, loss = 2.83088
I0412 00:18:50.342830 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.74123 (* 1 = 2.74123 loss)
I0412 00:18:51.757520 21842 sgd_solver.cpp:138] Iteration 4500, lr = 0.0001
I0412 00:22:57.576429 21842 solver.cpp:243] Iteration 4600, loss = 2.85986
I0412 00:22:57.576609 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.76328 (* 1 = 2.76328 loss)
I0412 00:22:58.990756 21842 sgd_solver.cpp:138] Iteration 4600, lr = 0.0001
I0412 00:27:04.989154 21842 solver.cpp:243] Iteration 4700, loss = 2.84135
I0412 00:27:04.989346 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.85989 (* 1 = 2.85989 loss)
I0412 00:27:05.724061 21842 sgd_solver.cpp:138] Iteration 4700, lr = 0.0001
I0412 00:31:13.583173 21842 solver.cpp:243] Iteration 4800, loss = 2.75634
I0412 00:31:13.583333 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.20938 (* 1 = 3.20938 loss)
I0412 00:31:13.583367 21842 sgd_solver.cpp:138] Iteration 4800, lr = 0.0001
I0412 00:35:18.577891 21842 solver.cpp:243] Iteration 4900, loss = 2.80209
I0412 00:35:18.578058 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.5315 (* 1 = 2.5315 loss)
I0412 00:35:19.187142 21842 sgd_solver.cpp:138] Iteration 4900, lr = 0.0001
I0412 00:39:31.194181 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_5000.caffemodel
I0412 00:39:31.939599 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_5000.solverstate
I0412 00:39:32.256248 21842 solver.cpp:433] Iteration 5000, Testing net (#0)
I0412 00:39:32.279779 21842 net.cpp:693] Ignoring source layer mbox_loss
I0412 00:39:57.225524 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.450674
I0412 00:39:58.378496 21842 solver.cpp:243] Iteration 5000, loss = 2.87024
I0412 00:39:58.378548 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.42739 (* 1 = 2.42739 loss)
I0412 00:39:59.782622 21842 sgd_solver.cpp:138] Iteration 5000, lr = 0.0001
I0412 00:44:04.763505 21842 solver.cpp:243] Iteration 5100, loss = 2.75871
I0412 00:44:04.763674 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.45568 (* 1 = 2.45568 loss)
I0412 00:44:06.175462 21842 sgd_solver.cpp:138] Iteration 5100, lr = 0.0001
I0412 00:48:14.474930 21842 solver.cpp:243] Iteration 5200, loss = 2.82764
I0412 00:48:14.475096 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.12221 (* 1 = 3.12221 loss)
I0412 00:48:15.082139 21842 sgd_solver.cpp:138] Iteration 5200, lr = 0.0001
I0412 00:52:21.526443 21842 solver.cpp:243] Iteration 5300, loss = 2.78565
I0412 00:52:21.526615 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50027 (* 1 = 2.50027 loss)
I0412 00:52:22.272626 21842 sgd_solver.cpp:138] Iteration 5300, lr = 0.0001
I0412 00:56:26.738512 21842 solver.cpp:243] Iteration 5400, loss = 2.78782
I0412 00:56:26.738672 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68223 (* 1 = 2.68223 loss)
I0412 00:56:28.143247 21842 sgd_solver.cpp:138] Iteration 5400, lr = 0.0001
I0412 01:00:35.602275 21842 solver.cpp:243] Iteration 5500, loss = 2.80867
I0412 01:00:35.602466 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.16481 (* 1 = 3.16481 loss)
I0412 01:00:35.602581 21842 sgd_solver.cpp:138] Iteration 5500, lr = 0.0001
I0412 01:04:45.717010 21842 solver.cpp:243] Iteration 5600, loss = 2.74436
I0412 01:04:45.722270 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57536 (* 1 = 2.57536 loss)
I0412 01:04:45.722311 21842 sgd_solver.cpp:138] Iteration 5600, lr = 0.0001
I0412 01:08:52.283459 21842 solver.cpp:243] Iteration 5700, loss = 2.83793
I0412 01:08:52.283618 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.74971 (* 1 = 2.74971 loss)
I0412 01:08:53.728857 21842 sgd_solver.cpp:138] Iteration 5700, lr = 0.0001
I0412 01:12:58.212359 21842 solver.cpp:243] Iteration 5800, loss = 2.82585
I0412 01:12:58.212553 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.57812 (* 1 = 3.57812 loss)
I0412 01:12:58.212587 21842 sgd_solver.cpp:138] Iteration 5800, lr = 0.0001
I0412 01:17:13.725634 21842 solver.cpp:243] Iteration 5900, loss = 2.78519
I0412 01:17:13.725819 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65453 (* 1 = 2.65453 loss)
I0412 01:17:15.160420 21842 sgd_solver.cpp:138] Iteration 5900, lr = 0.0001
I0412 01:21:20.047492 21842 solver.cpp:243] Iteration 6000, loss = 2.81683
I0412 01:21:20.047631 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.98096 (* 1 = 2.98096 loss)
I0412 01:21:21.470556 21842 sgd_solver.cpp:138] Iteration 6000, lr = 0.0001
I0412 01:25:32.846659 21842 solver.cpp:243] Iteration 6100, loss = 2.7803
I0412 01:25:32.846869 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.21153 (* 1 = 3.21153 loss)
I0412 01:25:32.846920 21842 sgd_solver.cpp:138] Iteration 6100, lr = 0.0001
I0412 01:29:39.753764 21842 solver.cpp:243] Iteration 6200, loss = 2.7473
I0412 01:29:39.753937 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.99252 (* 1 = 1.99252 loss)
I0412 01:29:41.282781 21842 sgd_solver.cpp:138] Iteration 6200, lr = 0.0001
I0412 01:33:49.566998 21842 solver.cpp:243] Iteration 6300, loss = 2.79276
I0412 01:33:49.567159 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.30549 (* 1 = 3.30549 loss)
I0412 01:33:49.567193 21842 sgd_solver.cpp:138] Iteration 6300, lr = 0.0001
I0412 01:38:06.457352 21842 solver.cpp:243] Iteration 6400, loss = 2.79423
I0412 01:38:06.457537 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.46492 (* 1 = 2.46492 loss)
I0412 01:38:07.084203 21842 sgd_solver.cpp:138] Iteration 6400, lr = 0.0001
I0412 01:42:14.577453 21842 solver.cpp:243] Iteration 6500, loss = 2.73597
I0412 01:42:14.577633 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.0713 (* 1 = 3.0713 loss)
I0412 01:42:14.577670 21842 sgd_solver.cpp:138] Iteration 6500, lr = 0.0001
I0412 01:46:24.928325 21842 solver.cpp:243] Iteration 6600, loss = 2.78679
I0412 01:46:24.928486 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6246 (* 1 = 2.6246 loss)
I0412 01:46:25.690568 21842 sgd_solver.cpp:138] Iteration 6600, lr = 0.0001
I0412 01:50:36.799765 21842 solver.cpp:243] Iteration 6700, loss = 2.70884
I0412 01:50:36.799906 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.85893 (* 1 = 2.85893 loss)
I0412 01:50:36.799947 21842 sgd_solver.cpp:138] Iteration 6700, lr = 0.0001
I0412 01:54:42.074975 21842 solver.cpp:243] Iteration 6800, loss = 2.80017
I0412 01:54:42.075203 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.04587 (* 1 = 3.04587 loss)
I0412 01:54:42.075238 21842 sgd_solver.cpp:138] Iteration 6800, lr = 0.0001
I0412 01:58:50.074110 21842 solver.cpp:243] Iteration 6900, loss = 2.73715
I0412 01:58:50.074280 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.94612 (* 1 = 2.94612 loss)
I0412 01:58:50.074314 21842 sgd_solver.cpp:138] Iteration 6900, lr = 0.0001
I0412 02:03:03.340996 21842 solver.cpp:243] Iteration 7000, loss = 2.72325
I0412 02:03:03.341161 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.7031 (* 1 = 2.7031 loss)
I0412 02:03:03.341195 21842 sgd_solver.cpp:138] Iteration 7000, lr = 0.0001
I0412 02:07:09.239789 21842 solver.cpp:243] Iteration 7100, loss = 2.78741
I0412 02:07:09.239966 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93903 (* 1 = 2.93903 loss)
I0412 02:07:10.024421 21842 sgd_solver.cpp:138] Iteration 7100, lr = 0.0001
I0412 02:11:13.198734 21842 solver.cpp:243] Iteration 7200, loss = 2.74206
I0412 02:11:13.198951 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24446 (* 1 = 2.24446 loss)
I0412 02:11:14.621331 21842 sgd_solver.cpp:138] Iteration 7200, lr = 0.0001
I0412 02:15:23.299096 21842 solver.cpp:243] Iteration 7300, loss = 2.75938
I0412 02:15:23.299264 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.79569 (* 1 = 2.79569 loss)
I0412 02:15:23.299371 21842 sgd_solver.cpp:138] Iteration 7300, lr = 0.0001
I0412 02:19:25.844794 21842 solver.cpp:243] Iteration 7400, loss = 2.76484
I0412 02:19:25.844991 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.86437 (* 1 = 2.86437 loss)
I0412 02:19:25.845039 21842 sgd_solver.cpp:138] Iteration 7400, lr = 0.0001
I0412 02:23:33.824594 21842 solver.cpp:243] Iteration 7500, loss = 2.81249
I0412 02:23:33.824756 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.85407 (* 1 = 2.85407 loss)
I0412 02:23:33.824791 21842 sgd_solver.cpp:138] Iteration 7500, lr = 0.0001
I0412 02:27:42.651932 21842 solver.cpp:243] Iteration 7600, loss = 2.77282
I0412 02:27:42.652144 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36933 (* 1 = 2.36933 loss)
I0412 02:27:43.309090 21842 sgd_solver.cpp:138] Iteration 7600, lr = 0.0001
I0412 02:31:50.288776 21842 solver.cpp:243] Iteration 7700, loss = 2.80268
I0412 02:31:50.288961 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.80128 (* 1 = 2.80128 loss)
I0412 02:31:50.288995 21842 sgd_solver.cpp:138] Iteration 7700, lr = 0.0001
I0412 02:36:02.506577 21842 solver.cpp:243] Iteration 7800, loss = 2.70873
I0412 02:36:02.506764 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8264 (* 1 = 2.8264 loss)
I0412 02:36:03.932760 21842 sgd_solver.cpp:138] Iteration 7800, lr = 0.0001
I0412 02:40:06.772614 21842 solver.cpp:243] Iteration 7900, loss = 2.70698
I0412 02:40:06.772763 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.04972 (* 1 = 3.04972 loss)
I0412 02:40:08.206291 21842 sgd_solver.cpp:138] Iteration 7900, lr = 0.0001
I0412 02:44:12.622414 21842 solver.cpp:243] Iteration 8000, loss = 2.71941
I0412 02:44:12.622589 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57268 (* 1 = 2.57268 loss)
I0412 02:44:13.435974 21842 sgd_solver.cpp:138] Iteration 8000, lr = 0.0001
I0412 02:48:30.338145 21842 solver.cpp:243] Iteration 8100, loss = 2.74435
I0412 02:48:30.338310 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36603 (* 1 = 2.36603 loss)
I0412 02:48:30.338346 21842 sgd_solver.cpp:138] Iteration 8100, lr = 0.0001
I0412 02:52:39.576218 21842 solver.cpp:243] Iteration 8200, loss = 2.73657
I0412 02:52:39.576381 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.14299 (* 1 = 3.14299 loss)
I0412 02:52:40.184482 21842 sgd_solver.cpp:138] Iteration 8200, lr = 0.0001
I0412 02:56:40.774140 21842 solver.cpp:243] Iteration 8300, loss = 2.73581
I0412 02:56:40.774312 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.78116 (* 1 = 2.78116 loss)
I0412 02:56:40.774356 21842 sgd_solver.cpp:138] Iteration 8300, lr = 0.0001
I0412 03:00:52.667546 21842 solver.cpp:243] Iteration 8400, loss = 2.68652
I0412 03:00:52.667703 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56748 (* 1 = 2.56748 loss)
I0412 03:00:52.667745 21842 sgd_solver.cpp:138] Iteration 8400, lr = 0.0001
I0412 03:04:55.429111 21842 solver.cpp:243] Iteration 8500, loss = 2.75139
I0412 03:04:55.429281 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55563 (* 1 = 2.55563 loss)
I0412 03:04:56.180371 21842 sgd_solver.cpp:138] Iteration 8500, lr = 0.0001
I0412 03:09:03.399003 21842 solver.cpp:243] Iteration 8600, loss = 2.75333
I0412 03:09:03.399166 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.74522 (* 1 = 2.74522 loss)
I0412 03:09:03.399199 21842 sgd_solver.cpp:138] Iteration 8600, lr = 0.0001
I0412 03:13:09.077772 21842 solver.cpp:243] Iteration 8700, loss = 2.68557
I0412 03:13:09.077971 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31923 (* 1 = 2.31923 loss)
I0412 03:13:09.795168 21842 sgd_solver.cpp:138] Iteration 8700, lr = 0.0001
I0412 03:17:20.921263 21842 solver.cpp:243] Iteration 8800, loss = 2.71891
I0412 03:17:20.921423 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.08417 (* 1 = 3.08417 loss)
I0412 03:17:20.921458 21842 sgd_solver.cpp:138] Iteration 8800, lr = 0.0001
I0412 03:21:31.718256 21842 solver.cpp:243] Iteration 8900, loss = 2.75366
I0412 03:21:31.718433 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43599 (* 1 = 2.43599 loss)
I0412 03:21:31.718489 21842 sgd_solver.cpp:138] Iteration 8900, lr = 0.0001
I0412 03:25:36.628788 21842 solver.cpp:243] Iteration 9000, loss = 2.71527
I0412 03:25:36.628968 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.69864 (* 1 = 2.69864 loss)
I0412 03:25:36.629005 21842 sgd_solver.cpp:138] Iteration 9000, lr = 0.0001
I0412 03:29:44.201758 21842 solver.cpp:243] Iteration 9100, loss = 2.74403
I0412 03:29:44.201917 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.17073 (* 1 = 3.17073 loss)
I0412 03:29:45.641103 21842 sgd_solver.cpp:138] Iteration 9100, lr = 0.0001
I0412 03:33:58.452342 21842 solver.cpp:243] Iteration 9200, loss = 2.67633
I0412 03:33:58.452522 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.70012 (* 1 = 2.70012 loss)
I0412 03:33:59.892211 21842 sgd_solver.cpp:138] Iteration 9200, lr = 0.0001
I0412 03:38:04.048851 21842 solver.cpp:243] Iteration 9300, loss = 2.74387
I0412 03:38:04.049007 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.35227 (* 1 = 3.35227 loss)
I0412 03:38:04.049055 21842 sgd_solver.cpp:138] Iteration 9300, lr = 0.0001
I0412 03:42:11.865972 21842 solver.cpp:243] Iteration 9400, loss = 2.73247
I0412 03:42:11.866142 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.0531 (* 1 = 3.0531 loss)
I0412 03:42:11.866174 21842 sgd_solver.cpp:138] Iteration 9400, lr = 0.0001
I0412 03:46:25.730293 21842 solver.cpp:243] Iteration 9500, loss = 2.69922
I0412 03:46:25.730437 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.76199 (* 1 = 2.76199 loss)
I0412 03:46:27.158216 21842 sgd_solver.cpp:138] Iteration 9500, lr = 0.0001
I0412 03:50:30.684541 21842 solver.cpp:243] Iteration 9600, loss = 2.74017
I0412 03:50:30.684689 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.95915 (* 1 = 2.95915 loss)
I0412 03:50:31.386952 21842 sgd_solver.cpp:138] Iteration 9600, lr = 0.0001
I0412 03:54:34.130067 21842 solver.cpp:243] Iteration 9700, loss = 2.72701
I0412 03:54:34.130249 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31055 (* 1 = 2.31055 loss)
I0412 03:54:34.790673 21842 sgd_solver.cpp:138] Iteration 9700, lr = 0.0001
I0412 03:58:51.962679 21842 solver.cpp:243] Iteration 9800, loss = 2.73227
I0412 03:58:51.962838 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28511 (* 1 = 2.28511 loss)
I0412 03:58:52.605535 21842 sgd_solver.cpp:138] Iteration 9800, lr = 0.0001
I0412 04:02:59.824669 21842 solver.cpp:243] Iteration 9900, loss = 2.74702
I0412 04:02:59.824856 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93778 (* 1 = 2.93778 loss)
I0412 04:02:59.824890 21842 sgd_solver.cpp:138] Iteration 9900, lr = 0.0001
I0412 04:07:04.982156 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_10000.caffemodel
I0412 04:07:05.585966 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_10000.solverstate
I0412 04:07:05.950338 21842 solver.cpp:433] Iteration 10000, Testing net (#0)
I0412 04:07:05.950407 21842 net.cpp:693] Ignoring source layer mbox_loss
I0412 04:07:29.716598 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.506187
I0412 04:07:31.195246 21842 solver.cpp:243] Iteration 10000, loss = 2.75776
I0412 04:07:31.195307 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.00218 (* 1 = 3.00218 loss)
I0412 04:07:31.915045 21842 sgd_solver.cpp:138] Iteration 10000, lr = 0.0001
I0412 04:11:38.246893 21842 solver.cpp:243] Iteration 10100, loss = 2.69899
I0412 04:11:38.247087 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.79813 (* 1 = 2.79813 loss)
I0412 04:11:39.657673 21842 sgd_solver.cpp:138] Iteration 10100, lr = 0.0001
I0412 04:15:48.523619 21842 solver.cpp:243] Iteration 10200, loss = 2.77583
I0412 04:15:48.523794 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6051 (* 1 = 2.6051 loss)
I0412 04:15:48.523838 21842 sgd_solver.cpp:138] Iteration 10200, lr = 0.0001
I0412 04:19:58.803578 21842 solver.cpp:243] Iteration 10300, loss = 2.7114
I0412 04:19:58.803753 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4136 (* 1 = 2.4136 loss)
I0412 04:19:58.803788 21842 sgd_solver.cpp:138] Iteration 10300, lr = 0.0001
I0412 04:24:01.773022 21842 solver.cpp:243] Iteration 10400, loss = 2.76653
I0412 04:24:01.773195 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.92949 (* 1 = 2.92949 loss)
I0412 04:24:01.773228 21842 sgd_solver.cpp:138] Iteration 10400, lr = 0.0001
I0412 04:28:07.205576 21842 solver.cpp:243] Iteration 10500, loss = 2.73843
I0412 04:28:07.205756 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.99731 (* 1 = 2.99731 loss)
I0412 04:28:07.878480 21842 sgd_solver.cpp:138] Iteration 10500, lr = 0.0001
I0412 04:32:16.796404 21842 solver.cpp:243] Iteration 10600, loss = 2.66177
I0412 04:32:16.796583 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30649 (* 1 = 2.30649 loss)
I0412 04:32:18.199735 21842 sgd_solver.cpp:138] Iteration 10600, lr = 0.0001
I0412 04:36:21.800365 21842 solver.cpp:243] Iteration 10700, loss = 2.72639
I0412 04:36:21.800523 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25145 (* 1 = 2.25145 loss)
I0412 04:36:21.800565 21842 sgd_solver.cpp:138] Iteration 10700, lr = 0.0001
I0412 04:40:32.773272 21842 solver.cpp:243] Iteration 10800, loss = 2.72554
I0412 04:40:32.773442 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57628 (* 1 = 2.57628 loss)
I0412 04:40:34.166532 21842 sgd_solver.cpp:138] Iteration 10800, lr = 0.0001
I0412 04:44:43.217211 21842 solver.cpp:243] Iteration 10900, loss = 2.66976
I0412 04:44:43.217361 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.44706 (* 1 = 2.44706 loss)
I0412 04:44:43.217391 21842 sgd_solver.cpp:138] Iteration 10900, lr = 0.0001
I0412 04:48:52.289057 21842 solver.cpp:243] Iteration 11000, loss = 2.66929
I0412 04:48:52.289192 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35864 (* 1 = 2.35864 loss)
I0412 04:48:53.012886 21842 sgd_solver.cpp:138] Iteration 11000, lr = 0.0001
I0412 04:52:55.886365 21842 solver.cpp:243] Iteration 11100, loss = 2.70244
I0412 04:52:55.886521 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.25184 (* 1 = 3.25184 loss)
I0412 04:52:56.685106 21842 sgd_solver.cpp:138] Iteration 11100, lr = 0.0001
I0412 04:57:07.614333 21842 solver.cpp:243] Iteration 11200, loss = 2.59842
I0412 04:57:07.614493 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.67264 (* 1 = 2.67264 loss)
I0412 04:57:09.025251 21842 sgd_solver.cpp:138] Iteration 11200, lr = 0.0001
I0412 05:01:15.885613 21842 solver.cpp:243] Iteration 11300, loss = 2.71947
I0412 05:01:15.885795 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.96531 (* 1 = 2.96531 loss)
I0412 05:01:16.602846 21842 sgd_solver.cpp:138] Iteration 11300, lr = 0.0001
I0412 05:05:25.467416 21842 solver.cpp:243] Iteration 11400, loss = 2.75836
I0412 05:05:25.467589 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50781 (* 1 = 2.50781 loss)
I0412 05:05:25.467623 21842 sgd_solver.cpp:138] Iteration 11400, lr = 0.0001
I0412 05:09:33.471640 21842 solver.cpp:243] Iteration 11500, loss = 2.66095
I0412 05:09:33.471786 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.05311 (* 1 = 3.05311 loss)
I0412 05:09:33.471824 21842 sgd_solver.cpp:138] Iteration 11500, lr = 0.0001
I0412 05:13:38.354038 21842 solver.cpp:243] Iteration 11600, loss = 2.68611
I0412 05:13:38.354223 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.06316 (* 1 = 3.06316 loss)
I0412 05:13:39.186967 21842 sgd_solver.cpp:138] Iteration 11600, lr = 0.0001
I0412 05:17:51.093770 21842 solver.cpp:243] Iteration 11700, loss = 2.6759
I0412 05:17:51.093932 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32925 (* 1 = 2.32925 loss)
I0412 05:17:51.785423 21842 sgd_solver.cpp:138] Iteration 11700, lr = 0.0001
I0412 05:21:58.387950 21842 solver.cpp:243] Iteration 11800, loss = 2.67441
I0412 05:21:58.388128 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.39073 (* 1 = 3.39073 loss)
I0412 05:21:59.816038 21842 sgd_solver.cpp:138] Iteration 11800, lr = 0.0001
I0412 05:26:04.970132 21842 solver.cpp:243] Iteration 11900, loss = 2.66658
I0412 05:26:04.970309 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65889 (* 1 = 2.65889 loss)
I0412 05:26:04.970345 21842 sgd_solver.cpp:138] Iteration 11900, lr = 0.0001
I0412 05:30:22.032713 21842 solver.cpp:243] Iteration 12000, loss = 2.67921
I0412 05:30:22.032871 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.90648 (* 1 = 2.90648 loss)
I0412 05:30:22.809222 21842 sgd_solver.cpp:138] Iteration 12000, lr = 0.0001
I0412 05:34:24.900213 21842 solver.cpp:243] Iteration 12100, loss = 2.69518
I0412 05:34:24.900396 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56492 (* 1 = 2.56492 loss)
I0412 05:34:24.900430 21842 sgd_solver.cpp:138] Iteration 12100, lr = 0.0001
I0412 05:38:30.327586 21842 solver.cpp:243] Iteration 12200, loss = 2.66475
I0412 05:38:30.327749 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.67407 (* 1 = 2.67407 loss)
I0412 05:38:30.327785 21842 sgd_solver.cpp:138] Iteration 12200, lr = 0.0001
I0412 05:42:41.319599 21842 solver.cpp:243] Iteration 12300, loss = 2.67516
I0412 05:42:41.319792 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.75973 (* 1 = 2.75973 loss)
I0412 05:42:41.961068 21842 sgd_solver.cpp:138] Iteration 12300, lr = 0.0001
I0412 05:46:52.163801 21842 solver.cpp:243] Iteration 12400, loss = 2.66973
I0412 05:46:52.163981 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.62521 (* 1 = 2.62521 loss)
I0412 05:46:52.822490 21842 sgd_solver.cpp:138] Iteration 12400, lr = 0.0001
I0412 05:51:04.003403 21842 solver.cpp:243] Iteration 12500, loss = 2.66759
I0412 05:51:04.003573 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10283 (* 1 = 2.10283 loss)
I0412 05:51:04.003618 21842 sgd_solver.cpp:138] Iteration 12500, lr = 0.0001
I0412 05:55:14.091147 21842 solver.cpp:243] Iteration 12600, loss = 2.65399
I0412 05:55:14.091326 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32456 (* 1 = 2.32456 loss)
I0412 05:55:14.091367 21842 sgd_solver.cpp:138] Iteration 12600, lr = 0.0001
I0412 05:59:21.245582 21842 solver.cpp:243] Iteration 12700, loss = 2.74419
I0412 05:59:21.245751 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.96045 (* 1 = 2.96045 loss)
I0412 05:59:22.684867 21842 sgd_solver.cpp:138] Iteration 12700, lr = 0.0001
I0412 06:03:39.074183 21842 solver.cpp:243] Iteration 12800, loss = 2.6686
I0412 06:03:39.074383 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.02014 (* 1 = 3.02014 loss)
I0412 06:03:39.702302 21842 sgd_solver.cpp:138] Iteration 12800, lr = 0.0001
I0412 06:07:46.981521 21842 solver.cpp:243] Iteration 12900, loss = 2.69074
I0412 06:07:46.981709 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.46832 (* 1 = 2.46832 loss)
I0412 06:07:47.734676 21842 sgd_solver.cpp:138] Iteration 12900, lr = 0.0001
I0412 06:11:55.355618 21842 solver.cpp:243] Iteration 13000, loss = 2.67624
I0412 06:11:55.355808 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68454 (* 1 = 2.68454 loss)
I0412 06:11:56.007822 21842 sgd_solver.cpp:138] Iteration 13000, lr = 0.0001
I0412 06:16:02.016405 21842 solver.cpp:243] Iteration 13100, loss = 2.66111
I0412 06:16:02.016595 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.44499 (* 1 = 2.44499 loss)
I0412 06:16:02.016629 21842 sgd_solver.cpp:138] Iteration 13100, lr = 0.0001
I0412 06:20:08.497395 21842 solver.cpp:243] Iteration 13200, loss = 2.6871
I0412 06:20:08.497558 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15304 (* 1 = 2.15304 loss)
I0412 06:20:08.497594 21842 sgd_solver.cpp:138] Iteration 13200, lr = 0.0001
I0412 06:24:17.657234 21842 solver.cpp:243] Iteration 13300, loss = 2.63276
I0412 06:24:17.657409 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1964 (* 1 = 2.1964 loss)
I0412 06:24:17.657446 21842 sgd_solver.cpp:138] Iteration 13300, lr = 0.0001
I0412 06:28:29.413242 21842 solver.cpp:243] Iteration 13400, loss = 2.62087
I0412 06:28:29.413399 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.80967 (* 1 = 2.80967 loss)
I0412 06:28:29.413441 21842 sgd_solver.cpp:138] Iteration 13400, lr = 0.0001
I0412 06:32:37.953371 21842 solver.cpp:243] Iteration 13500, loss = 2.70459
I0412 06:32:37.953532 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.75397 (* 1 = 2.75397 loss)
I0412 06:32:37.953568 21842 sgd_solver.cpp:138] Iteration 13500, lr = 0.0001
I0412 06:36:51.008147 21842 solver.cpp:243] Iteration 13600, loss = 2.68061
I0412 06:36:51.008292 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36154 (* 1 = 2.36154 loss)
I0412 06:36:51.642752 21842 sgd_solver.cpp:138] Iteration 13600, lr = 0.0001
I0412 06:41:00.072314 21842 solver.cpp:243] Iteration 13700, loss = 2.63671
I0412 06:41:00.072486 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.45562 (* 1 = 2.45562 loss)
I0412 06:41:00.072522 21842 sgd_solver.cpp:138] Iteration 13700, lr = 0.0001
I0412 06:45:06.973747 21842 solver.cpp:243] Iteration 13800, loss = 2.69727
I0412 06:45:06.973899 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93588 (* 1 = 2.93588 loss)
I0412 06:45:06.973938 21842 sgd_solver.cpp:138] Iteration 13800, lr = 0.0001
I0412 06:49:17.824005 21842 solver.cpp:243] Iteration 13900, loss = 2.68343
I0412 06:49:17.824148 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31401 (* 1 = 2.31401 loss)
I0412 06:49:19.258242 21842 sgd_solver.cpp:138] Iteration 13900, lr = 0.0001
I0412 06:53:26.323426 21842 solver.cpp:243] Iteration 14000, loss = 2.59554
I0412 06:53:26.323609 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35403 (* 1 = 2.35403 loss)
I0412 06:53:27.735740 21842 sgd_solver.cpp:138] Iteration 14000, lr = 0.0001
I0412 06:57:30.727589 21842 solver.cpp:243] Iteration 14100, loss = 2.68746
I0412 06:57:30.727747 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24838 (* 1 = 2.24838 loss)
I0412 06:57:32.177980 21842 sgd_solver.cpp:138] Iteration 14100, lr = 0.0001
I0412 07:01:45.328631 21842 solver.cpp:243] Iteration 14200, loss = 2.67419
I0412 07:01:45.328812 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.58944 (* 1 = 2.58944 loss)
I0412 07:01:45.328846 21842 sgd_solver.cpp:138] Iteration 14200, lr = 0.0001
I0412 07:05:51.655900 21842 solver.cpp:243] Iteration 14300, loss = 2.64989
I0412 07:05:51.656064 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12547 (* 1 = 2.12547 loss)
I0412 07:05:53.065377 21842 sgd_solver.cpp:138] Iteration 14300, lr = 0.0001
I0412 07:10:00.076875 21842 solver.cpp:243] Iteration 14400, loss = 2.63046
I0412 07:10:00.077051 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51348 (* 1 = 2.51348 loss)
I0412 07:10:00.077088 21842 sgd_solver.cpp:138] Iteration 14400, lr = 0.0001
I0412 07:14:18.884135 21842 solver.cpp:243] Iteration 14500, loss = 2.64279
I0412 07:14:18.884311 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.77061 (* 1 = 2.77061 loss)
I0412 07:14:18.884351 21842 sgd_solver.cpp:138] Iteration 14500, lr = 0.0001
I0412 07:18:26.496381 21842 solver.cpp:243] Iteration 14600, loss = 2.73841
I0412 07:18:26.496557 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24207 (* 1 = 2.24207 loss)
I0412 07:18:26.496603 21842 sgd_solver.cpp:138] Iteration 14600, lr = 0.0001
I0412 07:22:35.215313 21842 solver.cpp:243] Iteration 14700, loss = 2.68154
I0412 07:22:35.215523 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17069 (* 1 = 2.17069 loss)
I0412 07:22:35.215579 21842 sgd_solver.cpp:138] Iteration 14700, lr = 0.0001
I0412 07:26:51.658227 21842 solver.cpp:243] Iteration 14800, loss = 2.65253
I0412 07:26:51.658433 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41862 (* 1 = 2.41862 loss)
I0412 07:26:53.046155 21842 sgd_solver.cpp:138] Iteration 14800, lr = 0.0001
I0412 07:31:02.640455 21842 solver.cpp:243] Iteration 14900, loss = 2.65637
I0412 07:31:02.640624 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.9647 (* 1 = 2.9647 loss)
I0412 07:31:04.064900 21842 sgd_solver.cpp:138] Iteration 14900, lr = 0.0001
I0412 07:35:02.286906 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_15000.caffemodel
I0412 07:35:02.886963 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_15000.solverstate
I0412 07:35:03.255686 21842 solver.cpp:433] Iteration 15000, Testing net (#0)
I0412 07:35:03.255774 21842 net.cpp:693] Ignoring source layer mbox_loss
I0412 07:35:28.352059 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.497129
I0412 07:35:29.595024 21842 solver.cpp:243] Iteration 15000, loss = 2.67153
I0412 07:35:29.595091 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.67609 (* 1 = 2.67609 loss)
I0412 07:35:30.341063 21842 sgd_solver.cpp:138] Iteration 15000, lr = 0.0001
I0412 07:39:29.508621 21842 solver.cpp:243] Iteration 15100, loss = 2.65669
I0412 07:39:29.508796 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.13852 (* 1 = 3.13852 loss)
I0412 07:39:29.508832 21842 sgd_solver.cpp:138] Iteration 15100, lr = 0.0001
I0412 07:43:32.042711 21842 solver.cpp:243] Iteration 15200, loss = 2.66168
I0412 07:43:32.042901 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.72821 (* 1 = 2.72821 loss)
I0412 07:43:32.042937 21842 sgd_solver.cpp:138] Iteration 15200, lr = 0.0001
I0412 07:47:41.031208 21842 solver.cpp:243] Iteration 15300, loss = 2.64916
I0412 07:47:41.031383 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43397 (* 1 = 2.43397 loss)
I0412 07:47:41.031419 21842 sgd_solver.cpp:138] Iteration 15300, lr = 0.0001
I0412 07:51:45.682750 21842 solver.cpp:243] Iteration 15400, loss = 2.62965
I0412 07:51:45.682921 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.50177 (* 1 = 3.50177 loss)
I0412 07:51:47.093155 21842 sgd_solver.cpp:138] Iteration 15400, lr = 0.0001
I0412 07:55:55.888620 21842 solver.cpp:243] Iteration 15500, loss = 2.73783
I0412 07:55:55.888808 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.98486 (* 1 = 2.98486 loss)
I0412 07:55:55.888844 21842 sgd_solver.cpp:138] Iteration 15500, lr = 0.0001
I0412 08:00:05.857590 21842 solver.cpp:243] Iteration 15600, loss = 2.63915
I0412 08:00:05.857760 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.67894 (* 1 = 2.67894 loss)
I0412 08:00:05.857794 21842 sgd_solver.cpp:138] Iteration 15600, lr = 0.0001
I0412 08:04:17.045352 21842 solver.cpp:243] Iteration 15700, loss = 2.68304
I0412 08:04:17.045492 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53096 (* 1 = 2.53096 loss)
I0412 08:04:17.045533 21842 sgd_solver.cpp:138] Iteration 15700, lr = 0.0001
I0412 08:08:26.942845 21842 solver.cpp:243] Iteration 15800, loss = 2.63222
I0412 08:08:26.943042 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93307 (* 1 = 2.93307 loss)
I0412 08:08:27.756539 21842 sgd_solver.cpp:138] Iteration 15800, lr = 0.0001
I0412 08:12:38.531383 21842 solver.cpp:243] Iteration 15900, loss = 2.6267
I0412 08:12:38.531553 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30437 (* 1 = 2.30437 loss)
I0412 08:12:39.266518 21842 sgd_solver.cpp:138] Iteration 15900, lr = 0.0001
I0412 08:16:45.277431 21842 solver.cpp:243] Iteration 16000, loss = 2.64701
I0412 08:16:45.277626 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.70768 (* 1 = 2.70768 loss)
I0412 08:16:45.277658 21842 sgd_solver.cpp:138] Iteration 16000, lr = 0.0001
I0412 08:20:53.182293 21842 solver.cpp:243] Iteration 16100, loss = 2.67927
I0412 08:20:53.182480 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.63133 (* 1 = 2.63133 loss)
I0412 08:20:54.590867 21842 sgd_solver.cpp:138] Iteration 16100, lr = 0.0001
I0412 08:25:05.941303 21842 solver.cpp:243] Iteration 16200, loss = 2.57541
I0412 08:25:05.941469 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65139 (* 1 = 2.65139 loss)
I0412 08:25:06.647269 21842 sgd_solver.cpp:138] Iteration 16200, lr = 0.0001
I0412 08:29:12.948915 21842 solver.cpp:243] Iteration 16300, loss = 2.68449
I0412 08:29:12.949084 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2839 (* 1 = 2.2839 loss)
I0412 08:29:14.411880 21842 sgd_solver.cpp:138] Iteration 16300, lr = 0.0001
I0412 08:33:30.210912 21842 solver.cpp:243] Iteration 16400, loss = 2.62597
I0412 08:33:30.211086 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22142 (* 1 = 2.22142 loss)
I0412 08:33:30.900316 21842 sgd_solver.cpp:138] Iteration 16400, lr = 0.0001
I0412 08:37:35.652564 21842 solver.cpp:243] Iteration 16500, loss = 2.6075
I0412 08:37:35.652741 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.64343 (* 1 = 2.64343 loss)
I0412 08:37:37.060591 21842 sgd_solver.cpp:138] Iteration 16500, lr = 0.0001
I0412 08:41:43.148876 21842 solver.cpp:243] Iteration 16600, loss = 2.61942
I0412 08:41:43.149053 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.33463 (* 1 = 2.33463 loss)
I0412 08:41:43.896387 21842 sgd_solver.cpp:138] Iteration 16600, lr = 0.0001
I0412 08:45:58.169342 21842 solver.cpp:243] Iteration 16700, loss = 2.62384
I0412 08:45:58.169531 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6889 (* 1 = 2.6889 loss)
I0412 08:45:58.169565 21842 sgd_solver.cpp:138] Iteration 16700, lr = 0.0001
I0412 08:50:09.482919 21842 solver.cpp:243] Iteration 16800, loss = 2.61426
I0412 08:50:09.483098 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.94847 (* 1 = 2.94847 loss)
I0412 08:50:10.910101 21842 sgd_solver.cpp:138] Iteration 16800, lr = 0.0001
I0412 08:54:17.151368 21842 solver.cpp:243] Iteration 16900, loss = 2.58993
I0412 08:54:17.151553 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53808 (* 1 = 2.53808 loss)
I0412 08:54:17.151592 21842 sgd_solver.cpp:138] Iteration 16900, lr = 0.0001
I0412 08:58:22.813738 21842 solver.cpp:243] Iteration 17000, loss = 2.57948
I0412 08:58:22.813930 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.04232 (* 1 = 3.04232 loss)
I0412 08:58:23.480695 21842 sgd_solver.cpp:138] Iteration 17000, lr = 0.0001
I0412 09:02:30.425462 21842 solver.cpp:243] Iteration 17100, loss = 2.66383
I0412 09:02:30.425633 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6175 (* 1 = 2.6175 loss)
I0412 09:02:30.425688 21842 sgd_solver.cpp:138] Iteration 17100, lr = 0.0001
I0412 09:06:36.714259 21842 solver.cpp:243] Iteration 17200, loss = 2.6504
I0412 09:06:36.714427 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8375 (* 1 = 2.8375 loss)
I0412 09:06:36.714475 21842 sgd_solver.cpp:138] Iteration 17200, lr = 0.0001
I0412 09:10:48.915911 21842 solver.cpp:243] Iteration 17300, loss = 2.58711
I0412 09:10:48.916143 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.42981 (* 1 = 2.42981 loss)
I0412 09:10:49.753432 21842 sgd_solver.cpp:138] Iteration 17300, lr = 0.0001
I0412 09:15:02.065584 21842 solver.cpp:243] Iteration 17400, loss = 2.6243
I0412 09:15:02.065768 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51116 (* 1 = 2.51116 loss)
I0412 09:15:02.065802 21842 sgd_solver.cpp:138] Iteration 17400, lr = 0.0001
I0412 09:19:13.709975 21842 solver.cpp:243] Iteration 17500, loss = 2.66179
I0412 09:19:13.710124 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.39219 (* 1 = 2.39219 loss)
I0412 09:19:14.511133 21842 sgd_solver.cpp:138] Iteration 17500, lr = 0.0001
I0412 09:23:23.403070 21842 solver.cpp:243] Iteration 17600, loss = 2.60186
I0412 09:23:23.403259 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.75731 (* 1 = 2.75731 loss)
I0412 09:23:24.198901 21842 sgd_solver.cpp:138] Iteration 17600, lr = 0.0001
I0412 09:27:32.213250 21842 solver.cpp:243] Iteration 17700, loss = 2.6559
I0412 09:27:32.213434 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53981 (* 1 = 2.53981 loss)
I0412 09:27:32.936866 21842 sgd_solver.cpp:138] Iteration 17700, lr = 0.0001
I0412 09:31:43.942136 21842 solver.cpp:243] Iteration 17800, loss = 2.6381
I0412 09:31:43.942333 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56456 (* 1 = 2.56456 loss)
I0412 09:31:44.751298 21842 sgd_solver.cpp:138] Iteration 17800, lr = 0.0001
I0412 09:35:50.632396 21842 solver.cpp:243] Iteration 17900, loss = 2.63268
I0412 09:35:50.632571 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.69956 (* 1 = 2.69956 loss)
I0412 09:35:50.632606 21842 sgd_solver.cpp:138] Iteration 17900, lr = 0.0001
I0412 09:39:58.012549 21842 solver.cpp:243] Iteration 18000, loss = 2.65315
I0412 09:39:58.012723 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.7872 (* 1 = 2.7872 loss)
I0412 09:39:58.012759 21842 sgd_solver.cpp:138] Iteration 18000, lr = 0.0001
I0412 09:44:14.903705 21842 solver.cpp:243] Iteration 18100, loss = 2.5919
I0412 09:44:14.903883 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41153 (* 1 = 2.41153 loss)
I0412 09:44:14.903914 21842 sgd_solver.cpp:138] Iteration 18100, lr = 0.0001
I0412 09:48:21.644951 21842 solver.cpp:243] Iteration 18200, loss = 2.62922
I0412 09:48:21.645117 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04071 (* 1 = 2.04071 loss)
I0412 09:48:23.063117 21842 sgd_solver.cpp:138] Iteration 18200, lr = 0.0001
I0412 09:52:33.615617 21842 solver.cpp:243] Iteration 18300, loss = 2.65516
I0412 09:52:33.615792 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11372 (* 1 = 2.11372 loss)
I0412 09:52:34.267323 21842 sgd_solver.cpp:138] Iteration 18300, lr = 0.0001
I0412 09:56:41.751487 21842 solver.cpp:243] Iteration 18400, loss = 2.58938
I0412 09:56:41.751649 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.72169 (* 1 = 2.72169 loss)
I0412 09:56:41.751683 21842 sgd_solver.cpp:138] Iteration 18400, lr = 0.0001
I0412 10:00:49.426389 21842 solver.cpp:243] Iteration 18500, loss = 2.65015
I0412 10:00:49.426568 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30472 (* 1 = 2.30472 loss)
I0412 10:00:49.426604 21842 sgd_solver.cpp:138] Iteration 18500, lr = 0.0001
I0412 10:05:02.800590 21842 solver.cpp:243] Iteration 18600, loss = 2.61914
I0412 10:05:02.800746 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.00134 (* 1 = 2.00134 loss)
I0412 10:05:04.241390 21842 sgd_solver.cpp:138] Iteration 18600, lr = 0.0001
I0412 10:09:06.299283 21842 solver.cpp:243] Iteration 18700, loss = 2.5872
I0412 10:09:06.299448 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.9744 (* 1 = 2.9744 loss)
I0412 10:09:07.058328 21842 sgd_solver.cpp:138] Iteration 18700, lr = 0.0001
I0412 10:13:15.767033 21842 solver.cpp:243] Iteration 18800, loss = 2.65022
I0412 10:13:15.767210 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34847 (* 1 = 2.34847 loss)
I0412 10:13:15.767243 21842 sgd_solver.cpp:138] Iteration 18800, lr = 0.0001
I0412 10:17:27.021142 21842 solver.cpp:243] Iteration 18900, loss = 2.63524
I0412 10:17:27.021306 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.20202 (* 1 = 2.20202 loss)
I0412 10:17:27.021345 21842 sgd_solver.cpp:138] Iteration 18900, lr = 0.0001
I0412 10:21:34.622833 21842 solver.cpp:243] Iteration 19000, loss = 2.60393
I0412 10:21:34.623018 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10612 (* 1 = 2.10612 loss)
I0412 10:21:34.623076 21842 sgd_solver.cpp:138] Iteration 19000, lr = 0.0001
I0412 10:25:42.185335 21842 solver.cpp:243] Iteration 19100, loss = 2.59948
I0412 10:25:42.185540 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53095 (* 1 = 2.53095 loss)
I0412 10:25:42.185578 21842 sgd_solver.cpp:138] Iteration 19100, lr = 0.0001
I0412 10:29:54.254097 21842 solver.cpp:243] Iteration 19200, loss = 2.58552
I0412 10:29:54.254262 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.99719 (* 1 = 2.99719 loss)
I0412 10:29:55.676883 21842 sgd_solver.cpp:138] Iteration 19200, lr = 0.0001
I0412 10:34:01.526603 21842 solver.cpp:243] Iteration 19300, loss = 2.69144
I0412 10:34:01.526764 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.20601 (* 1 = 2.20601 loss)
I0412 10:34:02.209816 21842 sgd_solver.cpp:138] Iteration 19300, lr = 0.0001
I0412 10:38:12.703336 21842 solver.cpp:243] Iteration 19400, loss = 2.64425
I0412 10:38:12.703495 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41548 (* 1 = 2.41548 loss)
I0412 10:38:14.119453 21842 sgd_solver.cpp:138] Iteration 19400, lr = 0.0001
I0412 10:42:27.427214 21842 solver.cpp:243] Iteration 19500, loss = 2.61232
I0412 10:42:27.427361 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.77174 (* 1 = 2.77174 loss)
I0412 10:42:28.176091 21842 sgd_solver.cpp:138] Iteration 19500, lr = 0.0001
I0412 10:46:32.543463 21842 solver.cpp:243] Iteration 19600, loss = 2.67328
I0412 10:46:32.543648 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.40733 (* 1 = 2.40733 loss)
I0412 10:46:32.543684 21842 sgd_solver.cpp:138] Iteration 19600, lr = 0.0001
I0412 10:50:36.290608 21842 solver.cpp:243] Iteration 19700, loss = 2.63957
I0412 10:50:36.290788 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73969 (* 1 = 2.73969 loss)
I0412 10:50:36.937126 21842 sgd_solver.cpp:138] Iteration 19700, lr = 0.0001
I0412 10:54:44.030686 21842 solver.cpp:243] Iteration 19800, loss = 2.55829
I0412 10:54:44.030840 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57999 (* 1 = 2.57999 loss)
I0412 10:54:45.473999 21842 sgd_solver.cpp:138] Iteration 19800, lr = 0.0001
I0412 10:58:52.782721 21842 solver.cpp:243] Iteration 19900, loss = 2.61513
I0412 10:58:52.782901 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.62228 (* 1 = 2.62228 loss)
I0412 10:58:53.471253 21842 sgd_solver.cpp:138] Iteration 19900, lr = 0.0001
I0412 11:02:58.017498 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_20000.caffemodel
I0412 11:02:59.087934 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_20000.solverstate
I0412 11:02:59.398633 21842 solver.cpp:433] Iteration 20000, Testing net (#0)
I0412 11:02:59.398697 21842 net.cpp:693] Ignoring source layer mbox_loss
I0412 11:03:23.261787 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.510575
I0412 11:03:24.655341 21842 solver.cpp:243] Iteration 20000, loss = 2.63577
I0412 11:03:24.655409 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.71666 (* 1 = 2.71666 loss)
I0412 11:03:26.076807 21842 sgd_solver.cpp:138] Iteration 20000, lr = 0.0001
I0412 11:07:28.619776 21842 solver.cpp:243] Iteration 20100, loss = 2.56148
I0412 11:07:28.619961 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.45947 (* 1 = 2.45947 loss)
I0412 11:07:28.619994 21842 sgd_solver.cpp:138] Iteration 20100, lr = 0.0001
I0412 11:11:39.533561 21842 solver.cpp:243] Iteration 20200, loss = 2.65248
I0412 11:11:39.533716 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30667 (* 1 = 2.30667 loss)
I0412 11:11:39.533751 21842 sgd_solver.cpp:138] Iteration 20200, lr = 0.0001
I0412 11:15:50.720134 21842 solver.cpp:243] Iteration 20300, loss = 2.54955
I0412 11:15:50.720307 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98215 (* 1 = 1.98215 loss)
I0412 11:15:52.163836 21842 sgd_solver.cpp:138] Iteration 20300, lr = 0.0001
I0412 11:20:01.230871 21842 solver.cpp:243] Iteration 20400, loss = 2.58417
I0412 11:20:01.231075 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.61694 (* 1 = 3.61694 loss)
I0412 11:20:01.231108 21842 sgd_solver.cpp:138] Iteration 20400, lr = 0.0001
I0412 11:24:11.996326 21842 solver.cpp:243] Iteration 20500, loss = 2.59374
I0412 11:24:11.996484 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.96243 (* 1 = 2.96243 loss)
I0412 11:24:12.821331 21842 sgd_solver.cpp:138] Iteration 20500, lr = 0.0001
I0412 11:28:27.323091 21842 solver.cpp:243] Iteration 20600, loss = 2.61502
I0412 11:28:27.323271 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.44795 (* 1 = 3.44795 loss)
I0412 11:28:28.072276 21842 sgd_solver.cpp:138] Iteration 20600, lr = 0.0001
I0412 11:32:38.872565 21842 solver.cpp:243] Iteration 20700, loss = 2.615
I0412 11:32:38.872748 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36815 (* 1 = 2.36815 loss)
I0412 11:32:38.872793 21842 sgd_solver.cpp:138] Iteration 20700, lr = 0.0001
I0412 11:36:46.464432 21842 solver.cpp:243] Iteration 20800, loss = 2.59412
I0412 11:36:46.464612 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36843 (* 1 = 2.36843 loss)
I0412 11:36:47.848369 21842 sgd_solver.cpp:138] Iteration 20800, lr = 0.0001
I0412 11:40:55.397578 21842 solver.cpp:243] Iteration 20900, loss = 2.57626
I0412 11:40:55.397758 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.83203 (* 1 = 2.83203 loss)
I0412 11:40:56.834882 21842 sgd_solver.cpp:138] Iteration 20900, lr = 0.0001
I0412 11:45:04.730581 21842 solver.cpp:243] Iteration 21000, loss = 2.63064
I0412 11:45:04.730767 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.44587 (* 1 = 2.44587 loss)
I0412 11:45:04.730800 21842 sgd_solver.cpp:138] Iteration 21000, lr = 0.0001
I0412 11:49:18.242175 21842 solver.cpp:243] Iteration 21100, loss = 2.67228
I0412 11:49:18.242327 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.9053 (* 1 = 2.9053 loss)
I0412 11:49:19.028336 21842 sgd_solver.cpp:138] Iteration 21100, lr = 0.0001
I0412 11:53:41.068087 21842 solver.cpp:243] Iteration 21200, loss = 2.51254
I0412 11:53:41.068236 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07129 (* 1 = 2.07129 loss)
I0412 11:53:41.068271 21842 sgd_solver.cpp:138] Iteration 21200, lr = 0.0001
I0412 11:58:06.808253 21842 solver.cpp:243] Iteration 21300, loss = 2.62904
I0412 11:58:06.808408 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.98314 (* 1 = 2.98314 loss)
I0412 11:58:06.808442 21842 sgd_solver.cpp:138] Iteration 21300, lr = 0.0001
I0412 12:02:38.314769 21842 solver.cpp:243] Iteration 21400, loss = 2.58297
I0412 12:02:38.314908 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.29286 (* 1 = 2.29286 loss)
I0412 12:02:38.314950 21842 sgd_solver.cpp:138] Iteration 21400, lr = 0.0001
I0412 12:06:59.548251 21842 solver.cpp:243] Iteration 21500, loss = 2.61213
I0412 12:06:59.548468 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6283 (* 1 = 2.6283 loss)
I0412 12:06:59.548514 21842 sgd_solver.cpp:138] Iteration 21500, lr = 0.0001
I0412 12:11:25.997068 21842 solver.cpp:243] Iteration 21600, loss = 2.63493
I0412 12:11:25.997231 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.52029 (* 1 = 2.52029 loss)
I0412 12:11:25.997284 21842 sgd_solver.cpp:138] Iteration 21600, lr = 0.0001
I0412 12:15:54.239732 21842 solver.cpp:243] Iteration 21700, loss = 2.5801
I0412 12:15:54.239867 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8005 (* 1 = 2.8005 loss)
I0412 12:15:54.239902 21842 sgd_solver.cpp:138] Iteration 21700, lr = 0.0001
I0412 12:20:15.835830 21842 solver.cpp:243] Iteration 21800, loss = 2.63125
I0412 12:20:15.842306 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.00366 (* 1 = 3.00366 loss)
I0412 12:20:17.270956 21842 sgd_solver.cpp:138] Iteration 21800, lr = 0.0001
I0412 12:24:34.683190 21842 solver.cpp:243] Iteration 21900, loss = 2.62819
I0412 12:24:34.683338 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.45232 (* 1 = 2.45232 loss)
I0412 12:24:34.683380 21842 sgd_solver.cpp:138] Iteration 21900, lr = 0.0001
I0412 12:28:57.847805 21842 solver.cpp:243] Iteration 22000, loss = 2.5623
I0412 12:28:57.848002 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73589 (* 1 = 2.73589 loss)
I0412 12:28:57.848084 21842 sgd_solver.cpp:138] Iteration 22000, lr = 0.0001
I0412 12:33:18.040237 21842 solver.cpp:243] Iteration 22100, loss = 2.5797
I0412 12:33:18.040375 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15641 (* 1 = 2.15641 loss)
I0412 12:33:18.040422 21842 sgd_solver.cpp:138] Iteration 22100, lr = 0.0001
I0412 12:37:36.614066 21842 solver.cpp:243] Iteration 22200, loss = 2.63281
I0412 12:37:36.614230 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4924 (* 1 = 2.4924 loss)
I0412 12:37:37.244513 21842 sgd_solver.cpp:138] Iteration 22200, lr = 0.0001
I0412 12:41:54.238155 21842 solver.cpp:243] Iteration 22300, loss = 2.51194
I0412 12:41:54.238286 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.67853 (* 1 = 2.67853 loss)
I0412 12:41:54.238320 21842 sgd_solver.cpp:138] Iteration 22300, lr = 0.0001
I0412 12:46:18.018848 21842 solver.cpp:243] Iteration 22400, loss = 2.61185
I0412 12:46:18.019037 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68911 (* 1 = 2.68911 loss)
I0412 12:46:19.463266 21842 sgd_solver.cpp:138] Iteration 22400, lr = 0.0001
I0412 12:50:42.529397 21842 solver.cpp:243] Iteration 22500, loss = 2.58581
I0412 12:50:42.529673 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.89747 (* 1 = 1.89747 loss)
I0412 12:50:44.041694 21842 sgd_solver.cpp:138] Iteration 22500, lr = 0.0001
I0412 12:55:01.693657 21842 solver.cpp:243] Iteration 22600, loss = 2.50521
I0412 12:55:01.693859 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22693 (* 1 = 2.22693 loss)
I0412 12:55:03.124806 21842 sgd_solver.cpp:138] Iteration 22600, lr = 0.0001
I0412 12:59:24.630651 21842 solver.cpp:243] Iteration 22700, loss = 2.61036
I0412 12:59:24.630764 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32659 (* 1 = 2.32659 loss)
I0412 12:59:24.630807 21842 sgd_solver.cpp:138] Iteration 22700, lr = 0.0001
I0412 13:03:50.603055 21842 solver.cpp:243] Iteration 22800, loss = 2.61229
I0412 13:03:50.603188 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8116 (* 1 = 2.8116 loss)
I0412 13:03:50.603230 21842 sgd_solver.cpp:138] Iteration 22800, lr = 0.0001
I0412 13:08:14.243268 21842 solver.cpp:243] Iteration 22900, loss = 2.62179
I0412 13:08:14.243419 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.61536 (* 1 = 2.61536 loss)
I0412 13:08:15.716562 21842 sgd_solver.cpp:138] Iteration 22900, lr = 0.0001
I0412 13:12:35.812139 21842 solver.cpp:243] Iteration 23000, loss = 2.61088
I0412 13:12:35.812322 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.42573 (* 1 = 2.42573 loss)
I0412 13:12:36.515465 21842 sgd_solver.cpp:138] Iteration 23000, lr = 0.0001
I0412 13:17:02.830888 21842 solver.cpp:243] Iteration 23100, loss = 2.58428
I0412 13:17:02.831607 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.66682 (* 1 = 2.66682 loss)
I0412 13:17:03.660195 21842 sgd_solver.cpp:138] Iteration 23100, lr = 0.0001
I0412 13:21:21.965663 21842 solver.cpp:243] Iteration 23200, loss = 2.60275
I0412 13:21:21.965801 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49727 (* 1 = 2.49727 loss)
I0412 13:21:21.965836 21842 sgd_solver.cpp:138] Iteration 23200, lr = 0.0001
I0412 13:25:38.808499 21842 solver.cpp:243] Iteration 23300, loss = 2.57183
I0412 13:25:38.808627 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06854 (* 1 = 2.06854 loss)
I0412 13:25:38.808667 21842 sgd_solver.cpp:138] Iteration 23300, lr = 0.0001
I0412 13:30:01.764636 21842 solver.cpp:243] Iteration 23400, loss = 2.52642
I0412 13:30:01.764783 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2661 (* 1 = 2.2661 loss)
I0412 13:30:01.764828 21842 sgd_solver.cpp:138] Iteration 23400, lr = 0.0001
I0412 13:34:19.943365 21842 solver.cpp:243] Iteration 23500, loss = 2.57889
I0412 13:34:19.943533 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28928 (* 1 = 2.28928 loss)
I0412 13:34:20.560322 21842 sgd_solver.cpp:138] Iteration 23500, lr = 0.0001
I0412 13:38:46.027640 21842 solver.cpp:243] Iteration 23600, loss = 2.58509
I0412 13:38:46.027808 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22169 (* 1 = 2.22169 loss)
I0412 13:38:46.027853 21842 sgd_solver.cpp:138] Iteration 23600, lr = 0.0001
I0412 13:43:09.208850 21842 solver.cpp:243] Iteration 23700, loss = 2.50405
I0412 13:43:09.208998 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.42263 (* 1 = 2.42263 loss)
I0412 13:43:09.209110 21842 sgd_solver.cpp:138] Iteration 23700, lr = 0.0001
I0412 13:47:37.591147 21842 solver.cpp:243] Iteration 23800, loss = 2.6163
I0412 13:47:37.591292 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.63304 (* 1 = 2.63304 loss)
I0412 13:47:37.591342 21842 sgd_solver.cpp:138] Iteration 23800, lr = 0.0001
I0412 13:52:03.830011 21842 solver.cpp:243] Iteration 23900, loss = 2.6201
I0412 13:52:03.830178 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.60429 (* 1 = 2.60429 loss)
I0412 13:52:05.302033 21842 sgd_solver.cpp:138] Iteration 23900, lr = 0.0001
I0412 13:56:20.692008 21842 solver.cpp:243] Iteration 24000, loss = 2.57094
I0412 13:56:20.692157 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.86546 (* 1 = 2.86546 loss)
I0412 13:56:20.692201 21842 sgd_solver.cpp:138] Iteration 24000, lr = 0.0001
I0412 14:00:44.523880 21842 solver.cpp:243] Iteration 24100, loss = 2.59764
I0412 14:00:44.524047 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73711 (* 1 = 2.73711 loss)
I0412 14:00:44.524150 21842 sgd_solver.cpp:138] Iteration 24100, lr = 0.0001
I0412 14:05:08.773439 21842 solver.cpp:243] Iteration 24200, loss = 2.5717
I0412 14:05:08.773610 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73093 (* 1 = 2.73093 loss)
I0412 14:05:10.227620 21842 sgd_solver.cpp:138] Iteration 24200, lr = 0.0001
I0412 14:09:30.943753 21842 solver.cpp:243] Iteration 24300, loss = 2.62242
I0412 14:09:30.943933 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37783 (* 1 = 2.37783 loss)
I0412 14:09:31.765897 21842 sgd_solver.cpp:138] Iteration 24300, lr = 0.0001
I0412 14:13:52.067390 21842 solver.cpp:243] Iteration 24400, loss = 2.58521
I0412 14:13:52.067535 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.78216 (* 1 = 2.78216 loss)
I0412 14:13:52.067613 21842 sgd_solver.cpp:138] Iteration 24400, lr = 0.0001
I0412 14:18:13.921007 21842 solver.cpp:243] Iteration 24500, loss = 2.55914
I0412 14:18:13.921150 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.38265 (* 1 = 2.38265 loss)
I0412 14:18:13.921188 21842 sgd_solver.cpp:138] Iteration 24500, lr = 0.0001
I0412 14:22:29.081974 21842 solver.cpp:243] Iteration 24600, loss = 2.58903
I0412 14:22:29.082157 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.339 (* 1 = 2.339 loss)
I0412 14:22:30.567893 21842 sgd_solver.cpp:138] Iteration 24600, lr = 0.0001
I0412 14:26:49.578914 21842 solver.cpp:243] Iteration 24700, loss = 2.56467
I0412 14:26:49.579064 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.39542 (* 1 = 2.39542 loss)
I0412 14:26:51.009413 21842 sgd_solver.cpp:138] Iteration 24700, lr = 0.0001
I0412 14:31:13.102452 21842 solver.cpp:243] Iteration 24800, loss = 2.50912
I0412 14:31:13.102599 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1482 (* 1 = 2.1482 loss)
I0412 14:31:13.884423 21842 sgd_solver.cpp:138] Iteration 24800, lr = 0.0001
I0412 14:35:33.768260 21842 solver.cpp:243] Iteration 24900, loss = 2.56138
I0412 14:35:33.769620 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56406 (* 1 = 2.56406 loss)
I0412 14:35:34.528259 21842 sgd_solver.cpp:138] Iteration 24900, lr = 0.0001
I0412 14:39:57.238446 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_25000.caffemodel
I0412 14:39:58.460559 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_25000.solverstate
I0412 14:39:58.898157 21842 solver.cpp:433] Iteration 25000, Testing net (#0)
I0412 14:39:58.898257 21842 net.cpp:693] Ignoring source layer mbox_loss
I0412 14:40:24.525498 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.492526
I0412 14:40:25.892465 21842 solver.cpp:243] Iteration 25000, loss = 2.59721
I0412 14:40:25.892531 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.92842 (* 1 = 1.92842 loss)
I0412 14:40:27.385480 21842 sgd_solver.cpp:138] Iteration 25000, lr = 0.0001
I0412 14:44:52.322271 21842 solver.cpp:243] Iteration 25100, loss = 2.56881
I0412 14:44:52.322407 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43798 (* 1 = 2.43798 loss)
I0412 14:44:52.322451 21842 sgd_solver.cpp:138] Iteration 25100, lr = 0.0001
I0412 14:49:08.549417 21842 solver.cpp:243] Iteration 25200, loss = 2.57831
I0412 14:49:08.549574 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11359 (* 1 = 2.11359 loss)
I0412 14:49:08.549671 21842 sgd_solver.cpp:138] Iteration 25200, lr = 0.0001
I0412 14:53:31.089007 21842 solver.cpp:243] Iteration 25300, loss = 2.52978
I0412 14:53:31.089160 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.54474 (* 1 = 2.54474 loss)
I0412 14:53:32.550391 21842 sgd_solver.cpp:138] Iteration 25300, lr = 0.0001
I0412 14:57:52.539822 21842 solver.cpp:243] Iteration 25400, loss = 2.60169
I0412 14:57:52.540004 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68952 (* 1 = 2.68952 loss)
I0412 14:57:53.214613 21842 sgd_solver.cpp:138] Iteration 25400, lr = 0.0001
I0412 15:02:12.047464 21842 solver.cpp:243] Iteration 25500, loss = 2.52381
I0412 15:02:12.047634 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8348 (* 1 = 2.8348 loss)
I0412 15:02:12.047691 21842 sgd_solver.cpp:138] Iteration 25500, lr = 0.0001
I0412 15:06:38.030809 21842 solver.cpp:243] Iteration 25600, loss = 2.50091
I0412 15:06:38.030941 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.86071 (* 1 = 2.86071 loss)
I0412 15:06:38.839213 21842 sgd_solver.cpp:138] Iteration 25600, lr = 0.0001
I0412 15:10:56.986340 21842 solver.cpp:243] Iteration 25700, loss = 2.53949
I0412 15:10:56.986521 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.74242 (* 1 = 2.74242 loss)
I0412 15:10:56.986596 21842 sgd_solver.cpp:138] Iteration 25700, lr = 0.0001
I0412 15:15:22.041738 21842 solver.cpp:243] Iteration 25800, loss = 2.58917
I0412 15:15:22.041934 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.80296 (* 1 = 2.80296 loss)
I0412 15:15:23.495149 21842 sgd_solver.cpp:138] Iteration 25800, lr = 0.0001
I0412 15:19:44.723428 21842 solver.cpp:243] Iteration 25900, loss = 2.51797
I0412 15:19:44.723597 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68939 (* 1 = 2.68939 loss)
I0412 15:19:46.178222 21842 sgd_solver.cpp:138] Iteration 25900, lr = 0.0001
I0412 15:24:07.271504 21842 solver.cpp:243] Iteration 26000, loss = 2.56042
I0412 15:24:07.271647 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4167 (* 1 = 2.4167 loss)
I0412 15:24:07.271744 21842 sgd_solver.cpp:138] Iteration 26000, lr = 0.0001
I0412 15:28:32.897953 21842 solver.cpp:243] Iteration 26100, loss = 2.58403
I0412 15:28:32.898106 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53405 (* 1 = 2.53405 loss)
I0412 15:28:34.416231 21842 sgd_solver.cpp:138] Iteration 26100, lr = 0.0001
I0412 15:32:54.127132 21842 solver.cpp:243] Iteration 26200, loss = 2.58892
I0412 15:32:54.127322 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.48356 (* 1 = 2.48356 loss)
I0412 15:32:54.127359 21842 sgd_solver.cpp:138] Iteration 26200, lr = 0.0001
I0412 15:37:13.557070 21842 solver.cpp:243] Iteration 26300, loss = 2.54638
I0412 15:37:13.557274 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37107 (* 1 = 2.37107 loss)
I0412 15:37:14.369918 21842 sgd_solver.cpp:138] Iteration 26300, lr = 0.0001
I0412 15:41:45.901657 21842 solver.cpp:243] Iteration 26400, loss = 2.55392
I0412 15:41:45.901855 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.63086 (* 1 = 2.63086 loss)
I0412 15:41:47.362253 21842 sgd_solver.cpp:138] Iteration 26400, lr = 0.0001
I0412 15:46:08.117883 21842 solver.cpp:243] Iteration 26500, loss = 2.56131
I0412 15:46:08.118032 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73432 (* 1 = 2.73432 loss)
I0412 15:46:08.118077 21842 sgd_solver.cpp:138] Iteration 26500, lr = 0.0001
I0412 15:50:35.657065 21842 solver.cpp:243] Iteration 26600, loss = 2.59278
I0412 15:50:35.657238 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.45695 (* 1 = 2.45695 loss)
I0412 15:50:35.657274 21842 sgd_solver.cpp:138] Iteration 26600, lr = 0.0001
I0412 15:55:01.394639 21842 solver.cpp:243] Iteration 26700, loss = 2.57692
I0412 15:55:01.394804 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.70435 (* 1 = 2.70435 loss)
I0412 15:55:01.394906 21842 sgd_solver.cpp:138] Iteration 26700, lr = 0.0001
I0412 15:59:23.336330 21842 solver.cpp:243] Iteration 26800, loss = 2.5779
I0412 15:59:23.336472 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8146 (* 1 = 2.8146 loss)
I0412 15:59:23.336504 21842 sgd_solver.cpp:138] Iteration 26800, lr = 0.0001
I0412 16:03:39.547760 21842 solver.cpp:243] Iteration 26900, loss = 2.54085
I0412 16:03:39.547910 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32249 (* 1 = 2.32249 loss)
I0412 16:03:40.336856 21842 sgd_solver.cpp:138] Iteration 26900, lr = 0.0001
I0412 16:08:06.576747 21842 solver.cpp:243] Iteration 27000, loss = 2.5055
I0412 16:08:06.576925 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24038 (* 1 = 2.24038 loss)
I0412 16:08:07.294906 21842 sgd_solver.cpp:138] Iteration 27000, lr = 0.0001
I0412 16:12:26.827764 21842 solver.cpp:243] Iteration 27100, loss = 2.58693
I0412 16:12:26.827888 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.39197 (* 1 = 2.39197 loss)
I0412 16:12:26.827934 21842 sgd_solver.cpp:138] Iteration 27100, lr = 0.0001
I0412 16:16:50.795929 21842 solver.cpp:243] Iteration 27200, loss = 2.57399
I0412 16:16:50.796064 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.75926 (* 1 = 2.75926 loss)
I0412 16:16:50.796098 21842 sgd_solver.cpp:138] Iteration 27200, lr = 0.0001
I0412 16:21:10.675542 21842 solver.cpp:243] Iteration 27300, loss = 2.52124
I0412 16:21:10.675704 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68712 (* 1 = 2.68712 loss)
I0412 16:21:12.372859 21842 sgd_solver.cpp:138] Iteration 27300, lr = 0.0001
I0412 16:25:33.327253 21842 solver.cpp:243] Iteration 27400, loss = 2.588
I0412 16:25:33.327405 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.63013 (* 1 = 2.63013 loss)
I0412 16:25:34.123818 21842 sgd_solver.cpp:138] Iteration 27400, lr = 0.0001
I0412 16:30:00.902624 21842 solver.cpp:243] Iteration 27500, loss = 2.52577
I0412 16:30:00.902762 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98741 (* 1 = 1.98741 loss)
I0412 16:30:00.902794 21842 sgd_solver.cpp:138] Iteration 27500, lr = 0.0001
I0412 16:34:19.971977 21842 solver.cpp:243] Iteration 27600, loss = 2.53329
I0412 16:34:19.972204 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56871 (* 1 = 2.56871 loss)
I0412 16:34:20.645596 21842 sgd_solver.cpp:138] Iteration 27600, lr = 0.0001
I0412 16:38:41.125205 21842 solver.cpp:243] Iteration 27700, loss = 2.58673
I0412 16:38:41.125419 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.72766 (* 1 = 2.72766 loss)
I0412 16:38:41.827567 21842 sgd_solver.cpp:138] Iteration 27700, lr = 0.0001
I0412 16:43:01.268342 21842 solver.cpp:243] Iteration 27800, loss = 2.57428
I0412 16:43:01.268512 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35736 (* 1 = 2.35736 loss)
I0412 16:43:01.940850 21842 sgd_solver.cpp:138] Iteration 27800, lr = 0.0001
I0412 16:47:25.324719 21842 solver.cpp:243] Iteration 27900, loss = 2.58975
I0412 16:47:25.324872 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.29285 (* 1 = 2.29285 loss)
I0412 16:47:26.155333 21842 sgd_solver.cpp:138] Iteration 27900, lr = 0.0001
I0412 16:51:53.940016 21842 solver.cpp:243] Iteration 28000, loss = 2.52153
I0412 16:51:53.940201 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59381 (* 1 = 2.59381 loss)
I0412 16:51:54.771297 21842 sgd_solver.cpp:138] Iteration 28000, lr = 0.0001
I0412 16:56:20.539243 21842 solver.cpp:243] Iteration 28100, loss = 2.5256
I0412 16:56:20.539373 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.48131 (* 1 = 2.48131 loss)
I0412 16:56:20.539407 21842 sgd_solver.cpp:138] Iteration 28100, lr = 0.0001
I0412 17:00:43.784588 21842 solver.cpp:243] Iteration 28200, loss = 2.59857
I0412 17:00:43.784767 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.33475 (* 1 = 2.33475 loss)
I0412 17:00:43.784857 21842 sgd_solver.cpp:138] Iteration 28200, lr = 0.0001
I0412 17:05:05.716224 21842 solver.cpp:243] Iteration 28300, loss = 2.55082
I0412 17:05:05.716346 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31802 (* 1 = 2.31802 loss)
I0412 17:05:07.179421 21842 sgd_solver.cpp:138] Iteration 28300, lr = 0.0001
I0412 17:09:33.666908 21842 solver.cpp:243] Iteration 28400, loss = 2.47885
I0412 17:09:33.667073 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35164 (* 1 = 2.35164 loss)
I0412 17:09:35.364662 21842 sgd_solver.cpp:138] Iteration 28400, lr = 0.0001
I0412 17:14:01.084743 21842 solver.cpp:243] Iteration 28500, loss = 2.52666
I0412 17:14:01.084882 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.23974 (* 1 = 3.23974 loss)
I0412 17:14:02.533802 21842 sgd_solver.cpp:138] Iteration 28500, lr = 0.0001
I0412 17:18:22.608875 21842 solver.cpp:243] Iteration 28600, loss = 2.60252
I0412 17:18:22.609009 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.74996 (* 1 = 2.74996 loss)
I0412 17:18:22.609050 21842 sgd_solver.cpp:138] Iteration 28600, lr = 0.0001
I0412 17:22:39.104039 21842 solver.cpp:243] Iteration 28700, loss = 2.50652
I0412 17:22:39.104193 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.29793 (* 1 = 2.29793 loss)
I0412 17:22:39.732384 21842 sgd_solver.cpp:138] Iteration 28700, lr = 0.0001
I0412 17:27:04.735457 21842 solver.cpp:243] Iteration 28800, loss = 2.57936
I0412 17:27:04.735594 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59886 (* 1 = 2.59886 loss)
I0412 17:27:06.226635 21842 sgd_solver.cpp:138] Iteration 28800, lr = 0.0001
I0412 17:31:32.224560 21842 solver.cpp:243] Iteration 28900, loss = 2.4762
I0412 17:31:32.224717 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.71805 (* 1 = 2.71805 loss)
I0412 17:31:32.224761 21842 sgd_solver.cpp:138] Iteration 28900, lr = 0.0001
I0412 17:35:52.770804 21842 solver.cpp:243] Iteration 29000, loss = 2.53632
I0412 17:35:52.770979 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.97129 (* 1 = 2.97129 loss)
I0412 17:35:52.771122 21842 sgd_solver.cpp:138] Iteration 29000, lr = 0.0001
I0412 17:40:16.337229 21842 solver.cpp:243] Iteration 29100, loss = 2.54316
I0412 17:40:16.337386 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24712 (* 1 = 2.24712 loss)
I0412 17:40:16.337430 21842 sgd_solver.cpp:138] Iteration 29100, lr = 0.0001
I0412 17:44:43.814836 21842 solver.cpp:243] Iteration 29200, loss = 2.53702
I0412 17:44:43.814977 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2895 (* 1 = 2.2895 loss)
I0412 17:44:44.494863 21842 sgd_solver.cpp:138] Iteration 29200, lr = 0.0001
I0412 17:49:03.912014 21842 solver.cpp:243] Iteration 29300, loss = 2.57334
I0412 17:49:03.912153 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51801 (* 1 = 2.51801 loss)
I0412 17:49:04.739706 21842 sgd_solver.cpp:138] Iteration 29300, lr = 0.0001
I0412 17:53:29.068114 21842 solver.cpp:243] Iteration 29400, loss = 2.54405
I0412 17:53:29.068251 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27007 (* 1 = 2.27007 loss)
I0412 17:53:29.068298 21842 sgd_solver.cpp:138] Iteration 29400, lr = 0.0001
I0412 17:57:55.830917 21842 solver.cpp:243] Iteration 29500, loss = 2.48518
I0412 17:57:55.831110 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11427 (* 1 = 2.11427 loss)
I0412 17:57:56.601258 21842 sgd_solver.cpp:138] Iteration 29500, lr = 0.0001
I0412 18:02:17.291482 21842 solver.cpp:243] Iteration 29600, loss = 2.52323
I0412 18:02:17.291631 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.64978 (* 1 = 2.64978 loss)
I0412 18:02:17.291664 21842 sgd_solver.cpp:138] Iteration 29600, lr = 0.0001
I0412 18:06:37.785485 21842 solver.cpp:243] Iteration 29700, loss = 2.52946
I0412 18:06:37.785636 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.58877 (* 1 = 2.58877 loss)
I0412 18:06:38.488350 21842 sgd_solver.cpp:138] Iteration 29700, lr = 0.0001
I0412 18:10:58.111383 21842 solver.cpp:243] Iteration 29800, loss = 2.526
I0412 18:10:58.111552 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.94824 (* 1 = 2.94824 loss)
I0412 18:10:58.111636 21842 sgd_solver.cpp:138] Iteration 29800, lr = 0.0001
I0412 18:15:16.831224 21842 solver.cpp:243] Iteration 29900, loss = 2.59473
I0412 18:15:16.831348 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.91566 (* 1 = 2.91566 loss)
I0412 18:15:17.543682 21842 sgd_solver.cpp:138] Iteration 29900, lr = 0.0001
I0412 18:19:42.359436 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_30000.caffemodel
I0412 18:19:43.520265 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_30000.solverstate
I0412 18:19:43.902765 21842 solver.cpp:433] Iteration 30000, Testing net (#0)
I0412 18:19:43.902848 21842 net.cpp:693] Ignoring source layer mbox_loss
I0412 18:20:08.499532 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.513404
I0412 18:20:10.766474 21842 solver.cpp:243] Iteration 30000, loss = 2.50526
I0412 18:20:10.766533 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98338 (* 1 = 1.98338 loss)
I0412 18:20:10.766562 21842 sgd_solver.cpp:138] Iteration 30000, lr = 0.0001
I0412 18:24:29.493003 21842 solver.cpp:243] Iteration 30100, loss = 2.51505
I0412 18:24:29.493149 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.69639 (* 1 = 2.69639 loss)
I0412 18:24:29.493183 21842 sgd_solver.cpp:138] Iteration 30100, lr = 0.0001
I0412 18:28:48.654424 21842 solver.cpp:243] Iteration 30200, loss = 2.57773
I0412 18:28:48.654588 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.69283 (* 1 = 2.69283 loss)
I0412 18:28:48.654693 21842 sgd_solver.cpp:138] Iteration 30200, lr = 0.0001
I0412 18:33:10.813796 21842 solver.cpp:243] Iteration 30300, loss = 2.49733
I0412 18:33:10.813967 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.96289 (* 1 = 2.96289 loss)
I0412 18:33:12.293524 21842 sgd_solver.cpp:138] Iteration 30300, lr = 0.0001
I0412 18:37:33.564764 21842 solver.cpp:243] Iteration 30400, loss = 2.5853
I0412 18:37:33.564929 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.90806 (* 1 = 2.90806 loss)
I0412 18:37:33.564962 21842 sgd_solver.cpp:138] Iteration 30400, lr = 0.0001
I0412 18:41:52.433094 21842 solver.cpp:243] Iteration 30500, loss = 2.49948
I0412 18:41:52.433243 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.42714 (* 1 = 2.42714 loss)
I0412 18:41:52.433279 21842 sgd_solver.cpp:138] Iteration 30500, lr = 0.0001
I0412 18:46:17.861982 21842 solver.cpp:243] Iteration 30600, loss = 2.51875
I0412 18:46:17.862118 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27795 (* 1 = 2.27795 loss)
I0412 18:46:18.622865 21842 sgd_solver.cpp:138] Iteration 30600, lr = 0.0001
I0412 18:50:37.160616 21842 solver.cpp:243] Iteration 30700, loss = 2.54001
I0412 18:50:37.160778 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.3167 (* 1 = 2.3167 loss)
I0412 18:50:37.807368 21842 sgd_solver.cpp:138] Iteration 30700, lr = 0.0001
I0412 18:54:56.062124 21842 solver.cpp:243] Iteration 30800, loss = 2.57925
I0412 18:54:56.062288 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91614 (* 1 = 1.91614 loss)
I0412 18:54:56.690379 21842 sgd_solver.cpp:138] Iteration 30800, lr = 0.0001
I0412 18:59:17.105332 21842 solver.cpp:243] Iteration 30900, loss = 2.49374
I0412 18:59:17.105518 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34107 (* 1 = 2.34107 loss)
I0412 18:59:17.105638 21842 sgd_solver.cpp:138] Iteration 30900, lr = 0.0001
I0412 19:03:39.180627 21842 solver.cpp:243] Iteration 31000, loss = 2.51863
I0412 19:03:39.180776 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51347 (* 1 = 2.51347 loss)
I0412 19:03:40.012147 21842 sgd_solver.cpp:138] Iteration 31000, lr = 0.0001
I0412 19:08:09.667452 21842 solver.cpp:243] Iteration 31100, loss = 2.5589
I0412 19:08:09.667629 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.07955 (* 1 = 3.07955 loss)
I0412 19:08:09.667731 21842 sgd_solver.cpp:138] Iteration 31100, lr = 0.0001
I0412 19:12:28.003592 21842 solver.cpp:243] Iteration 31200, loss = 2.45884
I0412 19:12:28.003711 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51281 (* 1 = 2.51281 loss)
I0412 19:12:28.618774 21842 sgd_solver.cpp:138] Iteration 31200, lr = 0.0001
I0412 19:16:49.737473 21842 solver.cpp:243] Iteration 31300, loss = 2.57721
I0412 19:16:49.737601 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26286 (* 1 = 2.26286 loss)
I0412 19:16:49.737634 21842 sgd_solver.cpp:138] Iteration 31300, lr = 0.0001
I0412 19:21:13.441532 21842 solver.cpp:243] Iteration 31400, loss = 2.51109
I0412 19:21:13.441658 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2945 (* 1 = 2.2945 loss)
I0412 19:21:13.441691 21842 sgd_solver.cpp:138] Iteration 31400, lr = 0.0001
I0412 19:25:30.100057 21842 solver.cpp:243] Iteration 31500, loss = 2.57095
I0412 19:25:30.100224 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09291 (* 1 = 2.09291 loss)
I0412 19:25:31.583425 21842 sgd_solver.cpp:138] Iteration 31500, lr = 0.0001
I0412 19:29:53.283347 21842 solver.cpp:243] Iteration 31600, loss = 2.49626
I0412 19:29:53.283514 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4021 (* 1 = 2.4021 loss)
I0412 19:29:54.732199 21842 sgd_solver.cpp:138] Iteration 31600, lr = 0.0001
I0412 19:34:28.726622 21842 solver.cpp:243] Iteration 31700, loss = 2.55541
I0412 19:34:28.726824 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6498 (* 1 = 2.6498 loss)
I0412 19:34:28.726882 21842 sgd_solver.cpp:138] Iteration 31700, lr = 0.0001
I0412 19:38:52.814193 21842 solver.cpp:243] Iteration 31800, loss = 2.54331
I0412 19:38:52.814328 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.61621 (* 1 = 2.61621 loss)
I0412 19:38:52.814373 21842 sgd_solver.cpp:138] Iteration 31800, lr = 0.0001
I0412 19:43:11.385789 21842 solver.cpp:243] Iteration 31900, loss = 2.55246
I0412 19:43:11.385957 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12019 (* 1 = 2.12019 loss)
I0412 19:43:11.385993 21842 sgd_solver.cpp:138] Iteration 31900, lr = 0.0001
I0412 19:47:36.593709 21842 solver.cpp:243] Iteration 32000, loss = 2.48758
I0412 19:47:36.593857 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57779 (* 1 = 2.57779 loss)
I0412 19:47:37.349706 21842 sgd_solver.cpp:138] Iteration 32000, lr = 0.0001
I0412 19:52:03.203346 21842 solver.cpp:243] Iteration 32100, loss = 2.52448
I0412 19:52:03.203536 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07398 (* 1 = 2.07398 loss)
I0412 19:52:03.828511 21842 sgd_solver.cpp:138] Iteration 32100, lr = 0.0001
I0412 19:56:26.238574 21842 solver.cpp:243] Iteration 32200, loss = 2.45703
I0412 19:56:26.238740 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22318 (* 1 = 2.22318 loss)
I0412 19:56:26.921792 21842 sgd_solver.cpp:138] Iteration 32200, lr = 0.0001
I0412 20:00:49.530860 21842 solver.cpp:243] Iteration 32300, loss = 2.46594
I0412 20:00:49.531033 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6853 (* 1 = 2.6853 loss)
I0412 20:00:49.531128 21842 sgd_solver.cpp:138] Iteration 32300, lr = 0.0001
I0412 20:05:10.890089 21842 solver.cpp:243] Iteration 32400, loss = 2.56636
I0412 20:05:10.890274 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.40363 (* 1 = 2.40363 loss)
I0412 20:05:10.890374 21842 sgd_solver.cpp:138] Iteration 32400, lr = 0.0001
I0412 20:09:33.744261 21842 solver.cpp:243] Iteration 32500, loss = 2.48609
I0412 20:09:33.744441 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.90252 (* 1 = 1.90252 loss)
I0412 20:09:34.364267 21842 sgd_solver.cpp:138] Iteration 32500, lr = 0.0001
I0412 20:13:51.773571 21842 solver.cpp:243] Iteration 32600, loss = 2.48935
I0412 20:13:51.773710 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55079 (* 1 = 2.55079 loss)
I0412 20:13:51.773742 21842 sgd_solver.cpp:138] Iteration 32600, lr = 0.0001
I0412 20:18:11.247151 21842 solver.cpp:243] Iteration 32700, loss = 2.57317
I0412 20:18:11.247354 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.76834 (* 1 = 2.76834 loss)
I0412 20:18:11.889681 21842 sgd_solver.cpp:138] Iteration 32700, lr = 0.0001
I0412 20:22:33.949494 21842 solver.cpp:243] Iteration 32800, loss = 2.46578
I0412 20:22:33.949656 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08424 (* 1 = 2.08424 loss)
I0412 20:22:35.448674 21842 sgd_solver.cpp:138] Iteration 32800, lr = 0.0001
I0412 20:26:52.496654 21842 solver.cpp:243] Iteration 32900, loss = 2.54808
I0412 20:26:52.496824 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.3024 (* 1 = 2.3024 loss)
I0412 20:26:53.954264 21842 sgd_solver.cpp:138] Iteration 32900, lr = 0.0001
I0412 20:31:16.911685 21842 solver.cpp:243] Iteration 33000, loss = 2.48649
I0412 20:31:16.911819 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56588 (* 1 = 2.56588 loss)
I0412 20:31:16.911880 21842 sgd_solver.cpp:138] Iteration 33000, lr = 0.0001
I0412 20:35:41.810227 21842 solver.cpp:243] Iteration 33100, loss = 2.52299
I0412 20:35:41.810362 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50387 (* 1 = 2.50387 loss)
I0412 20:35:41.810400 21842 sgd_solver.cpp:138] Iteration 33100, lr = 0.0001
I0412 20:40:00.976450 21842 solver.cpp:243] Iteration 33200, loss = 2.46579
I0412 20:40:00.976603 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41242 (* 1 = 2.41242 loss)
I0412 20:40:01.741909 21842 sgd_solver.cpp:138] Iteration 33200, lr = 0.0001
I0412 20:44:17.055150 21842 solver.cpp:243] Iteration 33300, loss = 2.55165
I0412 20:44:17.055317 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37844 (* 1 = 2.37844 loss)
I0412 20:44:17.055413 21842 sgd_solver.cpp:138] Iteration 33300, lr = 0.0001
I0412 20:48:43.143713 21842 solver.cpp:243] Iteration 33400, loss = 2.45985
I0412 20:48:43.144407 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.7815 (* 1 = 2.7815 loss)
I0412 20:48:43.945504 21842 sgd_solver.cpp:138] Iteration 33400, lr = 0.0001
I0412 20:53:06.232403 21842 solver.cpp:243] Iteration 33500, loss = 2.56127
I0412 20:53:06.232607 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.70332 (* 1 = 2.70332 loss)
I0412 20:53:07.657008 21842 sgd_solver.cpp:138] Iteration 33500, lr = 0.0001
I0412 20:57:33.737102 21842 solver.cpp:243] Iteration 33600, loss = 2.52305
I0412 20:57:33.737243 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28354 (* 1 = 2.28354 loss)
I0412 20:57:35.198882 21842 sgd_solver.cpp:138] Iteration 33600, lr = 0.0001
I0412 21:01:57.955590 21842 solver.cpp:243] Iteration 33700, loss = 2.4189
I0412 21:01:57.955725 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.91071 (* 1 = 2.91071 loss)
I0412 21:01:59.427618 21842 sgd_solver.cpp:138] Iteration 33700, lr = 0.0001
I0412 21:06:19.433219 21842 solver.cpp:243] Iteration 33800, loss = 2.54057
I0412 21:06:19.433382 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.40308 (* 1 = 2.40308 loss)
I0412 21:06:19.433423 21842 sgd_solver.cpp:138] Iteration 33800, lr = 0.0001
I0412 21:10:39.932704 21842 solver.cpp:243] Iteration 33900, loss = 2.48884
I0412 21:10:39.932873 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09754 (* 1 = 2.09754 loss)
I0412 21:10:41.371870 21842 sgd_solver.cpp:138] Iteration 33900, lr = 0.0001
I0412 21:14:55.205432 21842 solver.cpp:243] Iteration 34000, loss = 2.52391
I0412 21:14:55.205586 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57029 (* 1 = 2.57029 loss)
I0412 21:14:55.205628 21842 sgd_solver.cpp:138] Iteration 34000, lr = 0.0001
I0412 21:19:14.711289 21842 solver.cpp:243] Iteration 34100, loss = 2.4957
I0412 21:19:14.711429 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13996 (* 1 = 2.13996 loss)
I0412 21:19:14.711465 21842 sgd_solver.cpp:138] Iteration 34100, lr = 0.0001
I0412 21:23:37.813952 21842 solver.cpp:243] Iteration 34200, loss = 2.51346
I0412 21:23:37.814097 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.82123 (* 1 = 2.82123 loss)
I0412 21:23:38.547791 21842 sgd_solver.cpp:138] Iteration 34200, lr = 0.0001
I0412 21:28:01.657045 21842 solver.cpp:243] Iteration 34300, loss = 2.57536
I0412 21:28:01.657176 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65881 (* 1 = 2.65881 loss)
I0412 21:28:02.373019 21842 sgd_solver.cpp:138] Iteration 34300, lr = 0.0001
I0412 21:32:20.566277 21842 solver.cpp:243] Iteration 34400, loss = 2.56746
I0412 21:32:20.566423 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.55446 (* 1 = 3.55446 loss)
I0412 21:32:21.350330 21842 sgd_solver.cpp:138] Iteration 34400, lr = 0.0001
I0412 21:36:45.383085 21842 solver.cpp:243] Iteration 34500, loss = 2.47604
I0412 21:36:45.383224 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07689 (* 1 = 2.07689 loss)
I0412 21:36:45.383260 21842 sgd_solver.cpp:138] Iteration 34500, lr = 0.0001
I0412 21:41:09.241873 21842 solver.cpp:243] Iteration 34600, loss = 2.50317
I0412 21:41:09.242112 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51671 (* 1 = 2.51671 loss)
I0412 21:41:10.709972 21842 sgd_solver.cpp:138] Iteration 34600, lr = 0.0001
I0412 21:45:31.755971 21842 solver.cpp:243] Iteration 34700, loss = 2.56405
I0412 21:45:31.756105 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.76546 (* 1 = 2.76546 loss)
I0412 21:45:31.756145 21842 sgd_solver.cpp:138] Iteration 34700, lr = 0.0001
I0412 21:49:55.618938 21842 solver.cpp:243] Iteration 34800, loss = 2.46611
I0412 21:49:55.619839 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51251 (* 1 = 2.51251 loss)
I0412 21:49:56.446460 21842 sgd_solver.cpp:138] Iteration 34800, lr = 0.0001
I0412 21:54:15.510653 21842 solver.cpp:243] Iteration 34900, loss = 2.57408
I0412 21:54:15.510793 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37394 (* 1 = 2.37394 loss)
I0412 21:54:15.510828 21842 sgd_solver.cpp:138] Iteration 34900, lr = 0.0001
I0412 21:58:38.035018 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_35000.caffemodel
I0412 21:58:39.167897 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_35000.solverstate
I0412 21:58:39.538288 21842 solver.cpp:433] Iteration 35000, Testing net (#0)
I0412 21:58:39.538373 21842 net.cpp:693] Ignoring source layer mbox_loss
I0412 21:59:05.176103 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.493891
I0412 21:59:07.292601 21842 solver.cpp:243] Iteration 35000, loss = 2.48638
I0412 21:59:07.292661 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1036 (* 1 = 2.1036 loss)
I0412 21:59:07.292690 21842 sgd_solver.cpp:138] Iteration 35000, lr = 0.0001
I0412 22:03:25.587015 21842 solver.cpp:243] Iteration 35100, loss = 2.50456
I0412 22:03:25.587183 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25596 (* 1 = 2.25596 loss)
I0412 22:03:25.587227 21842 sgd_solver.cpp:138] Iteration 35100, lr = 0.0001
I0412 22:07:48.604360 21842 solver.cpp:243] Iteration 35200, loss = 2.55706
I0412 22:07:48.604521 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51974 (* 1 = 2.51974 loss)
I0412 22:07:49.366516 21842 sgd_solver.cpp:138] Iteration 35200, lr = 0.0001
I0412 22:12:13.630125 21842 solver.cpp:243] Iteration 35300, loss = 2.50594
I0412 22:12:13.630286 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.86754 (* 1 = 2.86754 loss)
I0412 22:12:13.630321 21842 sgd_solver.cpp:138] Iteration 35300, lr = 0.0001
I0412 22:16:31.114408 21842 solver.cpp:243] Iteration 35400, loss = 2.54964
I0412 22:16:31.114543 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.9157 (* 1 = 2.9157 loss)
I0412 22:16:31.114588 21842 sgd_solver.cpp:138] Iteration 35400, lr = 0.0001
I0412 22:20:57.351759 21842 solver.cpp:243] Iteration 35500, loss = 2.51942
I0412 22:20:57.351907 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.62282 (* 1 = 3.62282 loss)
I0412 22:20:57.352028 21842 sgd_solver.cpp:138] Iteration 35500, lr = 0.0001
I0412 22:25:23.908432 21842 solver.cpp:243] Iteration 35600, loss = 2.48939
I0412 22:25:23.908673 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0542 (* 1 = 2.0542 loss)
I0412 22:25:23.908782 21842 sgd_solver.cpp:138] Iteration 35600, lr = 0.0001
I0412 22:29:42.013947 21842 solver.cpp:243] Iteration 35700, loss = 2.48259
I0412 22:29:42.014089 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.47975 (* 1 = 2.47975 loss)
I0412 22:29:43.501871 21842 sgd_solver.cpp:138] Iteration 35700, lr = 0.0001
I0412 22:34:00.707532 21842 solver.cpp:243] Iteration 35800, loss = 2.5268
I0412 22:34:00.707675 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24154 (* 1 = 2.24154 loss)
I0412 22:34:01.425621 21842 sgd_solver.cpp:138] Iteration 35800, lr = 0.0001
I0412 22:38:22.176671 21842 solver.cpp:243] Iteration 35900, loss = 2.4176
I0412 22:38:22.176831 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31504 (* 1 = 2.31504 loss)
I0412 22:38:23.618768 21842 sgd_solver.cpp:138] Iteration 35900, lr = 0.0001
I0412 22:42:44.304380 21842 solver.cpp:243] Iteration 36000, loss = 2.54227
I0412 22:42:44.304515 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.64473 (* 1 = 2.64473 loss)
I0412 22:42:45.761335 21842 sgd_solver.cpp:138] Iteration 36000, lr = 0.0001
I0412 22:47:11.251054 21842 solver.cpp:243] Iteration 36100, loss = 2.50044
I0412 22:47:11.251260 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.94649 (* 1 = 1.94649 loss)
I0412 22:47:11.999615 21842 sgd_solver.cpp:138] Iteration 36100, lr = 0.0001
I0412 22:51:29.947027 21842 solver.cpp:243] Iteration 36200, loss = 2.47644
I0412 22:51:29.947244 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41553 (* 1 = 2.41553 loss)
I0412 22:51:29.947296 21842 sgd_solver.cpp:138] Iteration 36200, lr = 0.0001
I0412 22:55:54.058343 21842 solver.cpp:243] Iteration 36300, loss = 2.50166
I0412 22:55:54.058502 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.78916 (* 1 = 2.78916 loss)
I0412 22:55:54.752163 21842 sgd_solver.cpp:138] Iteration 36300, lr = 0.0001
I0412 23:00:21.915817 21842 solver.cpp:243] Iteration 36400, loss = 2.45789
I0412 23:00:21.915979 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59751 (* 1 = 2.59751 loss)
I0412 23:00:23.331950 21842 sgd_solver.cpp:138] Iteration 36400, lr = 0.0001
I0412 23:04:46.226231 21842 solver.cpp:243] Iteration 36500, loss = 2.53793
I0412 23:04:46.226423 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25704 (* 1 = 2.25704 loss)
I0412 23:04:46.865568 21842 sgd_solver.cpp:138] Iteration 36500, lr = 0.0001
I0412 23:09:10.066882 21842 solver.cpp:243] Iteration 36600, loss = 2.56759
I0412 23:09:10.067023 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50194 (* 1 = 2.50194 loss)
I0412 23:09:11.547581 21842 sgd_solver.cpp:138] Iteration 36600, lr = 0.0001
I0412 23:13:34.049543 21842 solver.cpp:243] Iteration 36700, loss = 2.43972
I0412 23:13:34.049715 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36449 (* 1 = 2.36449 loss)
I0412 23:13:34.746928 21842 sgd_solver.cpp:138] Iteration 36700, lr = 0.0001
I0412 23:17:58.199136 21842 solver.cpp:243] Iteration 36800, loss = 2.50959
I0412 23:17:58.199332 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1098 (* 1 = 2.1098 loss)
I0412 23:17:59.690331 21842 sgd_solver.cpp:138] Iteration 36800, lr = 0.0001
I0412 23:22:25.147974 21842 solver.cpp:243] Iteration 36900, loss = 2.53171
I0412 23:22:25.148129 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.14977 (* 1 = 2.14977 loss)
I0412 23:22:26.589570 21842 sgd_solver.cpp:138] Iteration 36900, lr = 0.0001
I0412 23:26:55.591855 21842 solver.cpp:243] Iteration 37000, loss = 2.48518
I0412 23:26:55.591985 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.46488 (* 1 = 2.46488 loss)
I0412 23:26:55.592018 21842 sgd_solver.cpp:138] Iteration 37000, lr = 0.0001
I0412 23:31:20.990566 21842 solver.cpp:243] Iteration 37100, loss = 2.52347
I0412 23:31:20.990696 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.75065 (* 1 = 2.75065 loss)
I0412 23:31:20.990728 21842 sgd_solver.cpp:138] Iteration 37100, lr = 0.0001
I0412 23:35:46.323251 21842 solver.cpp:243] Iteration 37200, loss = 2.51429
I0412 23:35:46.323396 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32509 (* 1 = 2.32509 loss)
I0412 23:35:46.323437 21842 sgd_solver.cpp:138] Iteration 37200, lr = 0.0001
I0412 23:40:10.674535 21842 solver.cpp:243] Iteration 37300, loss = 2.46678
I0412 23:40:10.674718 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2887 (* 1 = 2.2887 loss)
I0412 23:40:10.674829 21842 sgd_solver.cpp:138] Iteration 37300, lr = 0.0001
I0412 23:44:33.801497 21842 solver.cpp:243] Iteration 37400, loss = 2.52294
I0412 23:44:33.801668 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12394 (* 1 = 2.12394 loss)
I0412 23:44:33.801761 21842 sgd_solver.cpp:138] Iteration 37400, lr = 0.0001
I0412 23:49:01.874487 21842 solver.cpp:243] Iteration 37500, loss = 2.50601
I0412 23:49:01.874626 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68607 (* 1 = 2.68607 loss)
I0412 23:49:01.874662 21842 sgd_solver.cpp:138] Iteration 37500, lr = 0.0001
I0412 23:53:24.304852 21842 solver.cpp:243] Iteration 37600, loss = 2.47885
I0412 23:53:24.305030 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49601 (* 1 = 2.49601 loss)
I0412 23:53:24.305132 21842 sgd_solver.cpp:138] Iteration 37600, lr = 0.0001
I0412 23:57:46.413012 21842 solver.cpp:243] Iteration 37700, loss = 2.54644
I0412 23:57:46.413179 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.3741 (* 1 = 2.3741 loss)
I0412 23:57:47.869413 21842 sgd_solver.cpp:138] Iteration 37700, lr = 0.0001
I0413 00:02:18.173128 21842 solver.cpp:243] Iteration 37800, loss = 2.48656
I0413 00:02:18.173310 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08211 (* 1 = 2.08211 loss)
I0413 00:02:19.603188 21842 sgd_solver.cpp:138] Iteration 37800, lr = 0.0001
I0413 00:06:35.806190 21842 solver.cpp:243] Iteration 37900, loss = 2.54435
I0413 00:06:35.806376 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06388 (* 1 = 2.06388 loss)
I0413 00:06:37.326843 21842 sgd_solver.cpp:138] Iteration 37900, lr = 0.0001
I0413 00:11:03.604578 21842 solver.cpp:243] Iteration 38000, loss = 2.46599
I0413 00:11:03.604727 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.46579 (* 1 = 2.46579 loss)
I0413 00:11:03.604765 21842 sgd_solver.cpp:138] Iteration 38000, lr = 0.0001
I0413 00:15:25.577448 21842 solver.cpp:243] Iteration 38100, loss = 2.46607
I0413 00:15:25.577623 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.01817 (* 1 = 2.01817 loss)
I0413 00:15:27.054579 21842 sgd_solver.cpp:138] Iteration 38100, lr = 0.0001
I0413 00:19:44.845255 21842 solver.cpp:243] Iteration 38200, loss = 2.50096
I0413 00:19:44.845427 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.72678 (* 1 = 2.72678 loss)
I0413 00:19:44.845541 21842 sgd_solver.cpp:138] Iteration 38200, lr = 0.0001
I0413 00:24:05.047559 21842 solver.cpp:243] Iteration 38300, loss = 2.52483
I0413 00:24:05.047720 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34961 (* 1 = 2.34961 loss)
I0413 00:24:05.766361 21842 sgd_solver.cpp:138] Iteration 38300, lr = 0.0001
I0413 00:28:30.706852 21842 solver.cpp:243] Iteration 38400, loss = 2.4643
I0413 00:28:30.707048 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.96391 (* 1 = 2.96391 loss)
I0413 00:28:32.211539 21842 sgd_solver.cpp:138] Iteration 38400, lr = 0.0001
I0413 00:32:52.545737 21842 solver.cpp:243] Iteration 38500, loss = 2.54825
I0413 00:32:52.545855 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.92108 (* 1 = 2.92108 loss)
I0413 00:32:52.545886 21842 sgd_solver.cpp:138] Iteration 38500, lr = 0.0001
I0413 00:37:18.274513 21842 solver.cpp:243] Iteration 38600, loss = 2.52966
I0413 00:37:18.274727 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.5332 (* 1 = 2.5332 loss)
I0413 00:37:18.274768 21842 sgd_solver.cpp:138] Iteration 38600, lr = 0.0001
I0413 00:41:32.925472 21842 solver.cpp:243] Iteration 38700, loss = 2.4868
I0413 00:41:32.925617 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.8252 (* 1 = 2.8252 loss)
I0413 00:41:33.643123 21842 sgd_solver.cpp:138] Iteration 38700, lr = 0.0001
I0413 00:45:58.683467 21842 solver.cpp:243] Iteration 38800, loss = 2.5644
I0413 00:45:58.683615 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65617 (* 1 = 2.65617 loss)
I0413 00:45:58.683660 21842 sgd_solver.cpp:138] Iteration 38800, lr = 0.0001
I0413 00:50:23.103431 21842 solver.cpp:243] Iteration 38900, loss = 2.45443
I0413 00:50:23.103603 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.87648 (* 1 = 1.87648 loss)
I0413 00:50:24.580835 21842 sgd_solver.cpp:138] Iteration 38900, lr = 0.0001
I0413 00:54:47.134032 21842 solver.cpp:243] Iteration 39000, loss = 2.50072
I0413 00:54:47.134210 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73222 (* 1 = 2.73222 loss)
I0413 00:54:47.946362 21842 sgd_solver.cpp:138] Iteration 39000, lr = 0.0001
I0413 00:59:04.826269 21842 solver.cpp:243] Iteration 39100, loss = 2.52141
I0413 00:59:04.826406 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55096 (* 1 = 2.55096 loss)
I0413 00:59:04.826441 21842 sgd_solver.cpp:138] Iteration 39100, lr = 0.0001
I0413 01:03:27.364722 21842 solver.cpp:243] Iteration 39200, loss = 2.46883
I0413 01:03:27.364892 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.89438 (* 1 = 2.89438 loss)
I0413 01:03:27.364931 21842 sgd_solver.cpp:138] Iteration 39200, lr = 0.0001
I0413 01:07:48.489333 21842 solver.cpp:243] Iteration 39300, loss = 2.481
I0413 01:07:48.489528 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.92811 (* 1 = 2.92811 loss)
I0413 01:07:48.489565 21842 sgd_solver.cpp:138] Iteration 39300, lr = 0.0001
I0413 01:12:11.104526 21842 solver.cpp:243] Iteration 39400, loss = 2.50206
I0413 01:12:11.104655 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09869 (* 1 = 2.09869 loss)
I0413 01:12:12.575371 21842 sgd_solver.cpp:138] Iteration 39400, lr = 0.0001
I0413 01:16:38.405071 21842 solver.cpp:243] Iteration 39500, loss = 2.44952
I0413 01:16:38.405256 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65564 (* 1 = 2.65564 loss)
I0413 01:16:39.079530 21842 sgd_solver.cpp:138] Iteration 39500, lr = 0.0001
I0413 01:21:01.210327 21842 solver.cpp:243] Iteration 39600, loss = 2.55994
I0413 01:21:01.210494 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59349 (* 1 = 2.59349 loss)
I0413 01:21:01.859619 21842 sgd_solver.cpp:138] Iteration 39600, lr = 0.0001
I0413 01:25:26.899956 21842 solver.cpp:243] Iteration 39700, loss = 2.54453
I0413 01:25:26.900081 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93182 (* 1 = 2.93182 loss)
I0413 01:25:26.900128 21842 sgd_solver.cpp:138] Iteration 39700, lr = 0.0001
I0413 01:29:42.076210 21842 solver.cpp:243] Iteration 39800, loss = 2.4888
I0413 01:29:42.076355 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34401 (* 1 = 2.34401 loss)
I0413 01:29:42.780848 21842 sgd_solver.cpp:138] Iteration 39800, lr = 0.0001
I0413 01:34:06.613780 21842 solver.cpp:243] Iteration 39900, loss = 2.54916
I0413 01:34:06.613978 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0279 (* 1 = 2.0279 loss)
I0413 01:34:06.614079 21842 sgd_solver.cpp:138] Iteration 39900, lr = 0.0001
I0413 01:38:34.725042 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_40000.caffemodel
I0413 01:38:35.366721 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_40000.solverstate
I0413 01:38:35.853369 21842 solver.cpp:433] Iteration 40000, Testing net (#0)
I0413 01:38:35.853498 21842 net.cpp:693] Ignoring source layer mbox_loss
I0413 01:39:00.395817 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.507685
I0413 01:39:01.910574 21842 solver.cpp:243] Iteration 40000, loss = 2.44926
I0413 01:39:01.910635 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.38114 (* 1 = 2.38114 loss)
I0413 01:39:03.359133 21842 sgd_solver.cpp:47] MultiStep Status: Iteration 40000, step = 1
I0413 01:39:03.359166 21842 sgd_solver.cpp:138] Iteration 40000, lr = 1e-05
I0413 01:43:21.662082 21842 solver.cpp:243] Iteration 40100, loss = 2.46568
I0413 01:43:21.662226 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35278 (* 1 = 2.35278 loss)
I0413 01:43:22.409840 21842 sgd_solver.cpp:138] Iteration 40100, lr = 1e-05
I0413 01:47:41.303274 21842 solver.cpp:243] Iteration 40200, loss = 2.36897
I0413 01:47:41.303447 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.16348 (* 1 = 2.16348 loss)
I0413 01:47:41.303524 21842 sgd_solver.cpp:138] Iteration 40200, lr = 1e-05
I0413 01:52:03.797680 21842 solver.cpp:243] Iteration 40300, loss = 2.358
I0413 01:52:03.797832 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30693 (* 1 = 2.30693 loss)
I0413 01:52:03.797876 21842 sgd_solver.cpp:138] Iteration 40300, lr = 1e-05
I0413 01:56:19.262583 21842 solver.cpp:243] Iteration 40400, loss = 2.37173
I0413 01:56:19.262715 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.18766 (* 1 = 2.18766 loss)
I0413 01:56:19.262758 21842 sgd_solver.cpp:138] Iteration 40400, lr = 1e-05
I0413 02:00:44.638016 21842 solver.cpp:243] Iteration 40500, loss = 2.38358
I0413 02:00:44.638145 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.8914 (* 1 = 1.8914 loss)
I0413 02:00:44.638190 21842 sgd_solver.cpp:138] Iteration 40500, lr = 1e-05
I0413 02:05:15.129446 21842 solver.cpp:243] Iteration 40600, loss = 2.31476
I0413 02:05:15.129573 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.76045 (* 1 = 1.76045 loss)
I0413 02:05:16.593813 21842 sgd_solver.cpp:138] Iteration 40600, lr = 1e-05
I0413 02:09:39.165693 21842 solver.cpp:243] Iteration 40700, loss = 2.32515
I0413 02:09:39.165827 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.21157 (* 1 = 2.21157 loss)
I0413 02:09:40.650400 21842 sgd_solver.cpp:138] Iteration 40700, lr = 1e-05
I0413 02:14:03.169267 21842 solver.cpp:243] Iteration 40800, loss = 2.35525
I0413 02:14:03.169446 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.40477 (* 1 = 2.40477 loss)
I0413 02:14:04.656852 21842 sgd_solver.cpp:138] Iteration 40800, lr = 1e-05
I0413 02:18:22.246882 21842 solver.cpp:243] Iteration 40900, loss = 2.35323
I0413 02:18:22.247042 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.86446 (* 1 = 2.86446 loss)
I0413 02:18:22.247076 21842 sgd_solver.cpp:138] Iteration 40900, lr = 1e-05
I0413 02:22:41.858074 21842 solver.cpp:243] Iteration 41000, loss = 2.41472
I0413 02:22:41.858206 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.87855 (* 1 = 2.87855 loss)
I0413 02:22:41.858242 21842 sgd_solver.cpp:138] Iteration 41000, lr = 1e-05
I0413 02:27:08.725559 21842 solver.cpp:243] Iteration 41100, loss = 2.37668
I0413 02:27:08.725693 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.29591 (* 1 = 2.29591 loss)
I0413 02:27:08.725725 21842 sgd_solver.cpp:138] Iteration 41100, lr = 1e-05
I0413 02:31:31.554873 21842 solver.cpp:243] Iteration 41200, loss = 2.37455
I0413 02:31:31.555096 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.5606 (* 1 = 2.5606 loss)
I0413 02:31:31.555199 21842 sgd_solver.cpp:138] Iteration 41200, lr = 1e-05
I0413 02:35:52.981330 21842 solver.cpp:243] Iteration 41300, loss = 2.34352
I0413 02:35:52.981503 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27515 (* 1 = 2.27515 loss)
I0413 02:35:54.405210 21842 sgd_solver.cpp:138] Iteration 41300, lr = 1e-05
I0413 02:40:26.471292 21842 solver.cpp:243] Iteration 41400, loss = 2.29628
I0413 02:40:26.471427 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1419 (* 1 = 2.1419 loss)
I0413 02:40:26.471463 21842 sgd_solver.cpp:138] Iteration 41400, lr = 1e-05
I0413 02:44:48.630759 21842 solver.cpp:243] Iteration 41500, loss = 2.38908
I0413 02:44:48.630914 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.40491 (* 1 = 2.40491 loss)
I0413 02:44:48.630954 21842 sgd_solver.cpp:138] Iteration 41500, lr = 1e-05
I0413 02:49:14.030673 21842 solver.cpp:243] Iteration 41600, loss = 2.39415
I0413 02:49:14.030812 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15167 (* 1 = 2.15167 loss)
I0413 02:49:14.030963 21842 sgd_solver.cpp:138] Iteration 41600, lr = 1e-05
I0413 02:53:38.518829 21842 solver.cpp:243] Iteration 41700, loss = 2.3192
I0413 02:53:38.519008 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17922 (* 1 = 2.17922 loss)
I0413 02:53:38.519057 21842 sgd_solver.cpp:138] Iteration 41700, lr = 1e-05
I0413 02:57:57.168608 21842 solver.cpp:243] Iteration 41800, loss = 2.35602
I0413 02:57:57.168752 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26224 (* 1 = 2.26224 loss)
I0413 02:57:57.863440 21842 sgd_solver.cpp:138] Iteration 41800, lr = 1e-05
I0413 03:02:18.614279 21842 solver.cpp:243] Iteration 41900, loss = 2.37364
I0413 03:02:18.614408 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06838 (* 1 = 2.06838 loss)
I0413 03:02:19.363495 21842 sgd_solver.cpp:138] Iteration 41900, lr = 1e-05
I0413 03:06:39.570617 21842 solver.cpp:243] Iteration 42000, loss = 2.27702
I0413 03:06:39.570822 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50803 (* 1 = 2.50803 loss)
I0413 03:06:40.241999 21842 sgd_solver.cpp:138] Iteration 42000, lr = 1e-05
I0413 03:11:01.227815 21842 solver.cpp:243] Iteration 42100, loss = 2.34549
I0413 03:11:01.227977 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36918 (* 1 = 2.36918 loss)
I0413 03:11:01.896304 21842 sgd_solver.cpp:138] Iteration 42100, lr = 1e-05
I0413 03:15:25.900301 21842 solver.cpp:243] Iteration 42200, loss = 2.33077
I0413 03:15:25.900427 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17848 (* 1 = 2.17848 loss)
I0413 03:15:25.900470 21842 sgd_solver.cpp:138] Iteration 42200, lr = 1e-05
I0413 03:19:44.874305 21842 solver.cpp:243] Iteration 42300, loss = 2.32362
I0413 03:19:44.874470 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.84999 (* 1 = 2.84999 loss)
I0413 03:19:46.327935 21842 sgd_solver.cpp:138] Iteration 42300, lr = 1e-05
I0413 03:24:04.309391 21842 solver.cpp:243] Iteration 42400, loss = 2.39768
I0413 03:24:04.309547 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13192 (* 1 = 2.13192 loss)
I0413 03:24:04.936684 21842 sgd_solver.cpp:138] Iteration 42400, lr = 1e-05
I0413 03:28:34.255308 21842 solver.cpp:243] Iteration 42500, loss = 2.29066
I0413 03:28:34.255439 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09784 (* 1 = 2.09784 loss)
I0413 03:28:34.255471 21842 sgd_solver.cpp:138] Iteration 42500, lr = 1e-05
I0413 03:32:57.348860 21842 solver.cpp:243] Iteration 42600, loss = 2.3517
I0413 03:32:57.349066 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.576 (* 1 = 3.576 loss)
I0413 03:32:57.349123 21842 sgd_solver.cpp:138] Iteration 42600, lr = 1e-05
I0413 03:37:21.041595 21842 solver.cpp:243] Iteration 42700, loss = 2.34853
I0413 03:37:21.041764 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2095 (* 1 = 2.2095 loss)
I0413 03:37:21.041857 21842 sgd_solver.cpp:138] Iteration 42700, lr = 1e-05
I0413 03:41:52.696631 21842 solver.cpp:243] Iteration 42800, loss = 2.2892
I0413 03:41:52.696823 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12649 (* 1 = 2.12649 loss)
I0413 03:41:52.696858 21842 sgd_solver.cpp:138] Iteration 42800, lr = 1e-05
I0413 03:46:13.466599 21842 solver.cpp:243] Iteration 42900, loss = 2.35239
I0413 03:46:13.466737 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09419 (* 1 = 2.09419 loss)
I0413 03:46:14.945606 21842 sgd_solver.cpp:138] Iteration 42900, lr = 1e-05
I0413 03:50:33.422293 21842 solver.cpp:243] Iteration 43000, loss = 2.36457
I0413 03:50:33.422451 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26286 (* 1 = 2.26286 loss)
I0413 03:50:33.422580 21842 sgd_solver.cpp:138] Iteration 43000, lr = 1e-05
I0413 03:54:58.835646 21842 solver.cpp:243] Iteration 43100, loss = 2.29154
I0413 03:54:58.835755 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08043 (* 1 = 2.08043 loss)
I0413 03:54:58.835800 21842 sgd_solver.cpp:138] Iteration 43100, lr = 1e-05
I0413 03:59:19.403245 21842 solver.cpp:243] Iteration 43200, loss = 2.31879
I0413 03:59:19.403384 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1229 (* 1 = 2.1229 loss)
I0413 03:59:19.403424 21842 sgd_solver.cpp:138] Iteration 43200, lr = 1e-05
I0413 04:03:42.851486 21842 solver.cpp:243] Iteration 43300, loss = 2.31444
I0413 04:03:42.851636 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.92992 (* 1 = 1.92992 loss)
I0413 04:03:42.851670 21842 sgd_solver.cpp:138] Iteration 43300, lr = 1e-05
I0413 04:08:04.333117 21842 solver.cpp:243] Iteration 43400, loss = 2.2864
I0413 04:08:04.334565 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30276 (* 1 = 2.30276 loss)
I0413 04:08:04.334609 21842 sgd_solver.cpp:138] Iteration 43400, lr = 1e-05
I0413 04:12:24.992189 21842 solver.cpp:243] Iteration 43500, loss = 2.36443
I0413 04:12:24.992346 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06475 (* 1 = 2.06475 loss)
I0413 04:12:25.809792 21842 sgd_solver.cpp:138] Iteration 43500, lr = 1e-05
I0413 04:16:52.854239 21842 solver.cpp:243] Iteration 43600, loss = 2.31934
I0413 04:16:52.854393 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31095 (* 1 = 2.31095 loss)
I0413 04:16:53.491410 21842 sgd_solver.cpp:138] Iteration 43600, lr = 1e-05
I0413 04:21:13.215176 21842 solver.cpp:243] Iteration 43700, loss = 2.31947
I0413 04:21:13.215315 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10251 (* 1 = 2.10251 loss)
I0413 04:21:14.666558 21842 sgd_solver.cpp:138] Iteration 43700, lr = 1e-05
I0413 04:25:34.651525 21842 solver.cpp:243] Iteration 43800, loss = 2.3754
I0413 04:25:34.651685 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.99951 (* 1 = 1.99951 loss)
I0413 04:25:35.424031 21842 sgd_solver.cpp:138] Iteration 43800, lr = 1e-05
I0413 04:29:59.396670 21842 solver.cpp:243] Iteration 43900, loss = 2.36405
I0413 04:29:59.396821 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.61276 (* 1 = 2.61276 loss)
I0413 04:29:59.396857 21842 sgd_solver.cpp:138] Iteration 43900, lr = 1e-05
I0413 04:34:18.006285 21842 solver.cpp:243] Iteration 44000, loss = 2.35494
I0413 04:34:18.006408 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03863 (* 1 = 2.03863 loss)
I0413 04:34:18.006453 21842 sgd_solver.cpp:138] Iteration 44000, lr = 1e-05
I0413 04:38:36.247187 21842 solver.cpp:243] Iteration 44100, loss = 2.29174
I0413 04:38:36.247352 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32264 (* 1 = 2.32264 loss)
I0413 04:38:36.247437 21842 sgd_solver.cpp:138] Iteration 44100, lr = 1e-05
I0413 04:42:57.907551 21842 solver.cpp:243] Iteration 44200, loss = 2.27374
I0413 04:42:57.914233 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.819 (* 1 = 1.819 loss)
I0413 04:42:57.914281 21842 sgd_solver.cpp:138] Iteration 44200, lr = 1e-05
I0413 04:47:19.896142 21842 solver.cpp:243] Iteration 44300, loss = 2.30419
I0413 04:47:19.896322 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49359 (* 1 = 2.49359 loss)
I0413 04:47:19.896453 21842 sgd_solver.cpp:138] Iteration 44300, lr = 1e-05
I0413 04:51:46.872912 21842 solver.cpp:243] Iteration 44400, loss = 2.37145
I0413 04:51:46.873088 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.83454 (* 1 = 1.83454 loss)
I0413 04:51:46.873126 21842 sgd_solver.cpp:138] Iteration 44400, lr = 1e-05
I0413 04:56:06.871012 21842 solver.cpp:243] Iteration 44500, loss = 2.28709
I0413 04:56:06.871161 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11397 (* 1 = 2.11397 loss)
I0413 04:56:08.333052 21842 sgd_solver.cpp:138] Iteration 44500, lr = 1e-05
I0413 05:00:28.285584 21842 solver.cpp:243] Iteration 44600, loss = 2.34849
I0413 05:00:28.285723 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2048 (* 1 = 2.2048 loss)
I0413 05:00:28.285760 21842 sgd_solver.cpp:138] Iteration 44600, lr = 1e-05
I0413 05:04:56.957820 21842 solver.cpp:243] Iteration 44700, loss = 2.27643
I0413 05:04:56.958003 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.92388 (* 1 = 1.92388 loss)
I0413 05:04:57.733400 21842 sgd_solver.cpp:138] Iteration 44700, lr = 1e-05
I0413 05:09:16.795374 21842 solver.cpp:243] Iteration 44800, loss = 2.34604
I0413 05:09:16.795526 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.02319 (* 1 = 3.02319 loss)
I0413 05:09:18.252709 21842 sgd_solver.cpp:138] Iteration 44800, lr = 1e-05
I0413 05:13:39.115367 21842 solver.cpp:243] Iteration 44900, loss = 2.34178
I0413 05:13:39.115553 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.21361 (* 1 = 2.21361 loss)
I0413 05:13:39.115639 21842 sgd_solver.cpp:138] Iteration 44900, lr = 1e-05
I0413 05:17:58.581737 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_45000.caffemodel
I0413 05:17:59.130019 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_45000.solverstate
I0413 05:17:59.496541 21842 solver.cpp:433] Iteration 45000, Testing net (#0)
I0413 05:17:59.496623 21842 net.cpp:693] Ignoring source layer mbox_loss
I0413 05:18:25.181269 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.51212
I0413 05:18:26.394665 21842 solver.cpp:243] Iteration 45000, loss = 2.28466
I0413 05:18:26.394722 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.95583 (* 1 = 1.95583 loss)
I0413 05:18:27.210616 21842 sgd_solver.cpp:138] Iteration 45000, lr = 1e-05
I0413 05:22:46.946557 21842 solver.cpp:243] Iteration 45100, loss = 2.38261
I0413 05:22:46.946724 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.7335 (* 1 = 2.7335 loss)
I0413 05:22:46.946811 21842 sgd_solver.cpp:138] Iteration 45100, lr = 1e-05
I0413 05:27:09.603287 21842 solver.cpp:243] Iteration 45200, loss = 2.33767
I0413 05:27:09.603433 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0204 (* 1 = 2.0204 loss)
I0413 05:27:09.603476 21842 sgd_solver.cpp:138] Iteration 45200, lr = 1e-05
I0413 05:31:35.508632 21842 solver.cpp:243] Iteration 45300, loss = 2.32975
I0413 05:31:35.508860 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32633 (* 1 = 2.32633 loss)
I0413 05:31:35.508955 21842 sgd_solver.cpp:138] Iteration 45300, lr = 1e-05
I0413 05:35:54.372789 21842 solver.cpp:243] Iteration 45400, loss = 2.34906
I0413 05:35:54.372928 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10439 (* 1 = 2.10439 loss)
I0413 05:35:54.372962 21842 sgd_solver.cpp:138] Iteration 45400, lr = 1e-05
I0413 05:40:11.781188 21842 solver.cpp:243] Iteration 45500, loss = 2.33483
I0413 05:40:11.781332 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.46092 (* 1 = 2.46092 loss)
I0413 05:40:11.781375 21842 sgd_solver.cpp:138] Iteration 45500, lr = 1e-05
I0413 05:44:35.052157 21842 solver.cpp:243] Iteration 45600, loss = 2.26959
I0413 05:44:35.052335 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08713 (* 1 = 2.08713 loss)
I0413 05:44:35.052455 21842 sgd_solver.cpp:138] Iteration 45600, lr = 1e-05
I0413 05:49:01.193464 21842 solver.cpp:243] Iteration 45700, loss = 2.40227
I0413 05:49:01.193619 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49411 (* 1 = 2.49411 loss)
I0413 05:49:01.193660 21842 sgd_solver.cpp:138] Iteration 45700, lr = 1e-05
I0413 05:53:26.096401 21842 solver.cpp:243] Iteration 45800, loss = 2.31985
I0413 05:53:26.096554 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49976 (* 1 = 2.49976 loss)
I0413 05:53:26.954262 21842 sgd_solver.cpp:138] Iteration 45800, lr = 1e-05
I0413 05:57:47.603371 21842 solver.cpp:243] Iteration 45900, loss = 2.26741
I0413 05:57:47.603534 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.71504 (* 1 = 2.71504 loss)
I0413 05:57:47.603588 21842 sgd_solver.cpp:138] Iteration 45900, lr = 1e-05
I0413 06:02:09.672420 21842 solver.cpp:243] Iteration 46000, loss = 2.36446
I0413 06:02:09.672582 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51173 (* 1 = 2.51173 loss)
I0413 06:02:09.672636 21842 sgd_solver.cpp:138] Iteration 46000, lr = 1e-05
I0413 06:06:32.112695 21842 solver.cpp:243] Iteration 46100, loss = 2.30633
I0413 06:06:32.112825 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07116 (* 1 = 2.07116 loss)
I0413 06:06:32.112862 21842 sgd_solver.cpp:138] Iteration 46100, lr = 1e-05
I0413 06:10:53.482687 21842 solver.cpp:243] Iteration 46200, loss = 2.34029
I0413 06:10:53.482825 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.66597 (* 1 = 2.66597 loss)
I0413 06:10:54.259161 21842 sgd_solver.cpp:138] Iteration 46200, lr = 1e-05
I0413 06:15:14.315574 21842 solver.cpp:243] Iteration 46300, loss = 2.345
I0413 06:15:14.315691 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.48312 (* 1 = 2.48312 loss)
I0413 06:15:14.315722 21842 sgd_solver.cpp:138] Iteration 46300, lr = 1e-05
I0413 06:19:37.322273 21842 solver.cpp:243] Iteration 46400, loss = 2.27872
I0413 06:19:37.322443 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.60929 (* 1 = 2.60929 loss)
I0413 06:19:37.985486 21842 sgd_solver.cpp:138] Iteration 46400, lr = 1e-05
I0413 06:23:59.416409 21842 solver.cpp:243] Iteration 46500, loss = 2.32485
I0413 06:23:59.416544 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30605 (* 1 = 2.30605 loss)
I0413 06:24:00.168172 21842 sgd_solver.cpp:138] Iteration 46500, lr = 1e-05
I0413 06:28:17.601279 21842 solver.cpp:243] Iteration 46600, loss = 2.34834
I0413 06:28:17.601413 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.278 (* 1 = 2.278 loss)
I0413 06:28:19.091995 21842 sgd_solver.cpp:138] Iteration 46600, lr = 1e-05
I0413 06:32:37.690739 21842 solver.cpp:243] Iteration 46700, loss = 2.26853
I0413 06:32:37.690912 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.67182 (* 1 = 2.67182 loss)
I0413 06:32:38.506384 21842 sgd_solver.cpp:138] Iteration 46700, lr = 1e-05
I0413 06:37:00.840139 21842 solver.cpp:243] Iteration 46800, loss = 2.28007
I0413 06:37:00.840309 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28822 (* 1 = 2.28822 loss)
I0413 06:37:02.317404 21842 sgd_solver.cpp:138] Iteration 46800, lr = 1e-05
I0413 06:41:17.437702 21842 solver.cpp:243] Iteration 46900, loss = 2.36633
I0413 06:41:17.437876 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56913 (* 1 = 2.56913 loss)
I0413 06:41:18.857971 21842 sgd_solver.cpp:138] Iteration 46900, lr = 1e-05
I0413 06:45:25.543017 21842 solver.cpp:243] Iteration 47000, loss = 2.25677
I0413 06:45:25.543207 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.52139 (* 1 = 2.52139 loss)
I0413 06:45:25.543239 21842 sgd_solver.cpp:138] Iteration 47000, lr = 1e-05
I0413 06:49:31.452545 21842 solver.cpp:243] Iteration 47100, loss = 2.33158
I0413 06:49:31.452713 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28552 (* 1 = 2.28552 loss)
I0413 06:49:32.077234 21842 sgd_solver.cpp:138] Iteration 47100, lr = 1e-05
I0413 06:53:39.479424 21842 solver.cpp:243] Iteration 47200, loss = 2.29678
I0413 06:53:39.479619 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.47904 (* 1 = 2.47904 loss)
I0413 06:53:39.479653 21842 sgd_solver.cpp:138] Iteration 47200, lr = 1e-05
I0413 06:57:47.562899 21842 solver.cpp:243] Iteration 47300, loss = 2.29068
I0413 06:57:47.563127 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65562 (* 1 = 2.65562 loss)
I0413 06:57:47.563161 21842 sgd_solver.cpp:138] Iteration 47300, lr = 1e-05
I0413 07:02:00.239307 21842 solver.cpp:243] Iteration 47400, loss = 2.34048
I0413 07:02:00.239492 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32837 (* 1 = 2.32837 loss)
I0413 07:02:00.239527 21842 sgd_solver.cpp:138] Iteration 47400, lr = 1e-05
I0413 07:06:14.383632 21842 solver.cpp:243] Iteration 47500, loss = 2.21041
I0413 07:06:14.383834 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.80386 (* 1 = 1.80386 loss)
I0413 07:06:14.383945 21842 sgd_solver.cpp:138] Iteration 47500, lr = 1e-05
I0413 07:10:21.928009 21842 solver.cpp:243] Iteration 47600, loss = 2.30139
I0413 07:10:21.928186 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6407 (* 1 = 2.6407 loss)
I0413 07:10:22.761628 21842 sgd_solver.cpp:138] Iteration 47600, lr = 1e-05
I0413 07:14:27.726147 21842 solver.cpp:243] Iteration 47700, loss = 2.29986
I0413 07:14:27.726307 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98795 (* 1 = 1.98795 loss)
I0413 07:14:27.726341 21842 sgd_solver.cpp:138] Iteration 47700, lr = 1e-05
I0413 07:18:38.718171 21842 solver.cpp:243] Iteration 47800, loss = 2.27672
I0413 07:18:38.718338 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37361 (* 1 = 2.37361 loss)
I0413 07:18:38.718370 21842 sgd_solver.cpp:138] Iteration 47800, lr = 1e-05
I0413 07:22:45.951310 21842 solver.cpp:243] Iteration 47900, loss = 2.30107
I0413 07:22:45.951498 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.19134 (* 1 = 2.19134 loss)
I0413 07:22:45.951531 21842 sgd_solver.cpp:138] Iteration 47900, lr = 1e-05
I0413 07:26:55.145581 21842 solver.cpp:243] Iteration 48000, loss = 2.30563
I0413 07:26:55.145750 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.14785 (* 1 = 2.14785 loss)
I0413 07:26:55.145786 21842 sgd_solver.cpp:138] Iteration 48000, lr = 1e-05
I0413 07:31:05.473870 21842 solver.cpp:243] Iteration 48100, loss = 2.2407
I0413 07:31:05.474052 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31551 (* 1 = 2.31551 loss)
I0413 07:31:05.474086 21842 sgd_solver.cpp:138] Iteration 48100, lr = 1e-05
I0413 07:35:12.241538 21842 solver.cpp:243] Iteration 48200, loss = 2.36627
I0413 07:35:12.241691 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15947 (* 1 = 2.15947 loss)
I0413 07:35:13.645539 21842 sgd_solver.cpp:138] Iteration 48200, lr = 1e-05
I0413 07:39:25.597928 21842 solver.cpp:243] Iteration 48300, loss = 2.30961
I0413 07:39:25.598099 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.125 (* 1 = 2.125 loss)
I0413 07:39:25.598147 21842 sgd_solver.cpp:138] Iteration 48300, lr = 1e-05
I0413 07:43:26.716032 21842 solver.cpp:243] Iteration 48400, loss = 2.26073
I0413 07:43:26.716187 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6753 (* 1 = 2.6753 loss)
I0413 07:43:26.716222 21842 sgd_solver.cpp:138] Iteration 48400, lr = 1e-05
I0413 07:47:42.023687 21842 solver.cpp:243] Iteration 48500, loss = 2.26746
I0413 07:47:42.023885 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31556 (* 1 = 2.31556 loss)
I0413 07:47:42.023921 21842 sgd_solver.cpp:138] Iteration 48500, lr = 1e-05
I0413 07:51:53.981649 21842 solver.cpp:243] Iteration 48600, loss = 2.30573
I0413 07:51:53.981824 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03669 (* 1 = 2.03669 loss)
I0413 07:51:54.728092 21842 sgd_solver.cpp:138] Iteration 48600, lr = 1e-05
I0413 07:55:57.425258 21842 solver.cpp:243] Iteration 48700, loss = 2.31304
I0413 07:55:57.425448 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.88829 (* 1 = 1.88829 loss)
I0413 07:55:58.837836 21842 sgd_solver.cpp:138] Iteration 48700, lr = 1e-05
I0413 08:00:00.714371 21842 solver.cpp:243] Iteration 48800, loss = 2.28487
I0413 08:00:00.714597 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34163 (* 1 = 2.34163 loss)
I0413 08:00:02.143071 21842 sgd_solver.cpp:138] Iteration 48800, lr = 1e-05
I0413 08:04:11.821508 21842 solver.cpp:243] Iteration 48900, loss = 2.3155
I0413 08:04:11.821696 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.44112 (* 1 = 2.44112 loss)
I0413 08:04:11.821728 21842 sgd_solver.cpp:138] Iteration 48900, lr = 1e-05
I0413 08:08:11.737999 21842 solver.cpp:243] Iteration 49000, loss = 2.3127
I0413 08:08:11.738184 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26056 (* 1 = 2.26056 loss)
I0413 08:08:13.142683 21842 sgd_solver.cpp:138] Iteration 49000, lr = 1e-05
I0413 08:12:19.371361 21842 solver.cpp:243] Iteration 49100, loss = 2.284
I0413 08:12:19.371538 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.60314 (* 1 = 2.60314 loss)
I0413 08:12:19.371587 21842 sgd_solver.cpp:138] Iteration 49100, lr = 1e-05
I0413 08:16:29.786159 21842 solver.cpp:243] Iteration 49200, loss = 2.24129
I0413 08:16:29.786370 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.8898 (* 1 = 1.8898 loss)
I0413 08:16:30.612114 21842 sgd_solver.cpp:138] Iteration 49200, lr = 1e-05
I0413 08:20:43.268944 21842 solver.cpp:243] Iteration 49300, loss = 2.25219
I0413 08:20:43.269127 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34733 (* 1 = 2.34733 loss)
I0413 08:20:43.269161 21842 sgd_solver.cpp:138] Iteration 49300, lr = 1e-05
I0413 08:24:47.975070 21842 solver.cpp:243] Iteration 49400, loss = 2.32808
I0413 08:24:47.975253 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26304 (* 1 = 2.26304 loss)
I0413 08:24:47.975288 21842 sgd_solver.cpp:138] Iteration 49400, lr = 1e-05
I0413 08:28:55.551266 21842 solver.cpp:243] Iteration 49500, loss = 2.26095
I0413 08:28:55.551448 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.99371 (* 1 = 2.99371 loss)
I0413 08:28:55.551489 21842 sgd_solver.cpp:138] Iteration 49500, lr = 1e-05
I0413 08:33:00.838601 21842 solver.cpp:243] Iteration 49600, loss = 2.28095
I0413 08:33:00.838764 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.74226 (* 1 = 2.74226 loss)
I0413 08:33:01.472167 21842 sgd_solver.cpp:138] Iteration 49600, lr = 1e-05
I0413 08:37:13.218176 21842 solver.cpp:243] Iteration 49700, loss = 2.31258
I0413 08:37:13.218359 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31836 (* 1 = 2.31836 loss)
I0413 08:37:13.218394 21842 sgd_solver.cpp:138] Iteration 49700, lr = 1e-05
I0413 08:41:18.005450 21842 solver.cpp:243] Iteration 49800, loss = 2.29675
I0413 08:41:18.005597 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43338 (* 1 = 2.43338 loss)
I0413 08:41:18.005631 21842 sgd_solver.cpp:138] Iteration 49800, lr = 1e-05
I0413 08:45:26.100378 21842 solver.cpp:243] Iteration 49900, loss = 2.30099
I0413 08:45:26.100566 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.90111 (* 1 = 1.90111 loss)
I0413 08:45:27.505710 21842 sgd_solver.cpp:138] Iteration 49900, lr = 1e-05
I0413 08:49:31.463974 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_50000.caffemodel
I0413 08:49:32.075542 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_50000.solverstate
I0413 08:49:32.432132 21842 solver.cpp:433] Iteration 50000, Testing net (#0)
I0413 08:49:32.432206 21842 net.cpp:693] Ignoring source layer mbox_loss
I0413 08:49:56.467545 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.523374
I0413 08:49:58.728078 21842 solver.cpp:243] Iteration 50000, loss = 2.29328
I0413 08:49:58.728132 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.97577 (* 1 = 1.97577 loss)
I0413 08:49:58.728168 21842 sgd_solver.cpp:138] Iteration 50000, lr = 1e-05
I0413 08:54:09.345542 21842 solver.cpp:243] Iteration 50100, loss = 2.33681
I0413 08:54:09.345763 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.45392 (* 1 = 2.45392 loss)
I0413 08:54:10.165786 21842 sgd_solver.cpp:138] Iteration 50100, lr = 1e-05
I0413 08:58:21.339334 21842 solver.cpp:243] Iteration 50200, loss = 2.29209
I0413 08:58:21.339529 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.61262 (* 1 = 2.61262 loss)
I0413 08:58:22.009167 21842 sgd_solver.cpp:138] Iteration 50200, lr = 1e-05
I0413 09:02:33.536118 21842 solver.cpp:243] Iteration 50300, loss = 2.26026
I0413 09:02:33.536291 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04123 (* 1 = 2.04123 loss)
I0413 09:02:33.536324 21842 sgd_solver.cpp:138] Iteration 50300, lr = 1e-05
I0413 09:06:39.193482 21842 solver.cpp:243] Iteration 50400, loss = 2.37284
I0413 09:06:39.193634 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23763 (* 1 = 2.23763 loss)
I0413 09:06:40.005157 21842 sgd_solver.cpp:138] Iteration 50400, lr = 1e-05
I0413 09:10:46.592087 21842 solver.cpp:243] Iteration 50500, loss = 2.34418
I0413 09:10:46.592321 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.01293 (* 1 = 2.01293 loss)
I0413 09:10:47.977538 21842 sgd_solver.cpp:138] Iteration 50500, lr = 1e-05
I0413 09:14:52.598634 21842 solver.cpp:243] Iteration 50600, loss = 2.25158
I0413 09:14:52.598881 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.8968 (* 1 = 1.8968 loss)
I0413 09:14:52.598994 21842 sgd_solver.cpp:138] Iteration 50600, lr = 1e-05
I0413 09:18:59.998235 21842 solver.cpp:243] Iteration 50700, loss = 2.30955
I0413 09:18:59.998518 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25512 (* 1 = 2.25512 loss)
I0413 09:18:59.998674 21842 sgd_solver.cpp:138] Iteration 50700, lr = 1e-05
I0413 09:23:08.017410 21842 solver.cpp:243] Iteration 50800, loss = 2.28169
I0413 09:23:08.017657 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.40305 (* 1 = 2.40305 loss)
I0413 09:23:09.436055 21842 sgd_solver.cpp:138] Iteration 50800, lr = 1e-05
I0413 09:27:11.095276 21842 solver.cpp:243] Iteration 50900, loss = 2.2722
I0413 09:27:11.095546 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.62188 (* 1 = 2.62188 loss)
I0413 09:27:11.742689 21842 sgd_solver.cpp:138] Iteration 50900, lr = 1e-05
I0413 09:31:21.628108 21842 solver.cpp:243] Iteration 51000, loss = 2.29163
I0413 09:31:21.629848 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27278 (* 1 = 2.27278 loss)
I0413 09:31:21.629997 21842 sgd_solver.cpp:138] Iteration 51000, lr = 1e-05
I0413 09:35:33.360591 21842 solver.cpp:243] Iteration 51100, loss = 2.27925
I0413 09:35:33.360853 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24982 (* 1 = 2.24982 loss)
I0413 09:35:33.360972 21842 sgd_solver.cpp:138] Iteration 51100, lr = 1e-05
I0413 09:39:40.587687 21842 solver.cpp:243] Iteration 51200, loss = 2.33533
I0413 09:39:40.587908 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.46246 (* 1 = 3.46246 loss)
I0413 09:39:40.588027 21842 sgd_solver.cpp:138] Iteration 51200, lr = 1e-05
I0413 09:43:45.553125 21842 solver.cpp:243] Iteration 51300, loss = 2.29378
I0413 09:43:45.553341 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.04965 (* 1 = 3.04965 loss)
I0413 09:43:45.553467 21842 sgd_solver.cpp:138] Iteration 51300, lr = 1e-05
I0413 09:47:51.902603 21842 solver.cpp:243] Iteration 51400, loss = 2.28692
I0413 09:47:51.902855 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.76741 (* 1 = 2.76741 loss)
I0413 09:47:52.661882 21842 sgd_solver.cpp:138] Iteration 51400, lr = 1e-05
I0413 09:52:00.581264 21842 solver.cpp:243] Iteration 51500, loss = 2.29496
I0413 09:52:00.581528 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.71154 (* 1 = 1.71154 loss)
I0413 09:52:01.985244 21842 sgd_solver.cpp:138] Iteration 51500, lr = 1e-05
I0413 09:56:09.700958 21842 solver.cpp:243] Iteration 51600, loss = 2.3101
I0413 09:56:09.701201 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.80811 (* 1 = 2.80811 loss)
I0413 09:56:09.701325 21842 sgd_solver.cpp:138] Iteration 51600, lr = 1e-05
I0413 10:00:19.283546 21842 solver.cpp:243] Iteration 51700, loss = 2.24629
I0413 10:00:19.283753 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37649 (* 1 = 2.37649 loss)
I0413 10:00:19.283787 21842 sgd_solver.cpp:138] Iteration 51700, lr = 1e-05
I0413 10:04:25.663393 21842 solver.cpp:243] Iteration 51800, loss = 2.31334
I0413 10:04:25.663611 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1257 (* 1 = 2.1257 loss)
I0413 10:04:25.663753 21842 sgd_solver.cpp:138] Iteration 51800, lr = 1e-05
I0413 10:08:31.939718 21842 solver.cpp:243] Iteration 51900, loss = 2.29187
I0413 10:08:31.939954 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.85584 (* 1 = 1.85584 loss)
I0413 10:08:32.554385 21842 sgd_solver.cpp:138] Iteration 51900, lr = 1e-05
I0413 10:12:34.687650 21842 solver.cpp:243] Iteration 52000, loss = 2.24833
I0413 10:12:34.687912 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13372 (* 1 = 2.13372 loss)
I0413 10:12:35.296510 21842 sgd_solver.cpp:138] Iteration 52000, lr = 1e-05
I0413 10:16:39.903367 21842 solver.cpp:243] Iteration 52100, loss = 2.31967
I0413 10:16:39.903601 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.54137 (* 1 = 2.54137 loss)
I0413 10:16:39.903728 21842 sgd_solver.cpp:138] Iteration 52100, lr = 1e-05
I0413 10:20:46.803817 21842 solver.cpp:243] Iteration 52200, loss = 2.30718
I0413 10:20:46.804049 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13652 (* 1 = 2.13652 loss)
I0413 10:20:47.445117 21842 sgd_solver.cpp:138] Iteration 52200, lr = 1e-05
I0413 10:24:55.947492 21842 solver.cpp:243] Iteration 52300, loss = 2.28298
I0413 10:24:55.947731 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93577 (* 1 = 2.93577 loss)
I0413 10:24:55.947862 21842 sgd_solver.cpp:138] Iteration 52300, lr = 1e-05
I0413 10:28:57.185636 21842 solver.cpp:243] Iteration 52400, loss = 2.29043
I0413 10:28:57.185858 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26833 (* 1 = 2.26833 loss)
I0413 10:28:57.185946 21842 sgd_solver.cpp:138] Iteration 52400, lr = 1e-05
I0413 10:33:08.800554 21842 solver.cpp:243] Iteration 52500, loss = 2.25706
I0413 10:33:08.800985 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22452 (* 1 = 2.22452 loss)
I0413 10:33:09.543694 21842 sgd_solver.cpp:138] Iteration 52500, lr = 1e-05
I0413 10:37:17.635510 21842 solver.cpp:243] Iteration 52600, loss = 2.29298
I0413 10:37:17.635759 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.21574 (* 1 = 2.21574 loss)
I0413 10:37:18.322558 21842 sgd_solver.cpp:138] Iteration 52600, lr = 1e-05
I0413 10:41:23.794031 21842 solver.cpp:243] Iteration 52700, loss = 2.30349
I0413 10:41:23.794308 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37771 (* 1 = 2.37771 loss)
I0413 10:41:23.794481 21842 sgd_solver.cpp:138] Iteration 52700, lr = 1e-05
I0413 10:45:31.928725 21842 solver.cpp:243] Iteration 52800, loss = 2.28832
I0413 10:45:31.928995 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41987 (* 1 = 2.41987 loss)
I0413 10:45:31.929136 21842 sgd_solver.cpp:138] Iteration 52800, lr = 1e-05
I0413 10:49:36.564123 21842 solver.cpp:243] Iteration 52900, loss = 2.28721
I0413 10:49:36.564343 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11334 (* 1 = 2.11334 loss)
I0413 10:49:36.564462 21842 sgd_solver.cpp:138] Iteration 52900, lr = 1e-05
I0413 10:53:42.992269 21842 solver.cpp:243] Iteration 53000, loss = 2.3118
I0413 10:53:42.992511 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08602 (* 1 = 2.08602 loss)
I0413 10:53:42.992643 21842 sgd_solver.cpp:138] Iteration 53000, lr = 1e-05
I0413 10:57:51.302713 21842 solver.cpp:243] Iteration 53100, loss = 2.23424
I0413 10:57:51.302984 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2791 (* 1 = 2.2791 loss)
I0413 10:57:51.971253 21842 sgd_solver.cpp:138] Iteration 53100, lr = 1e-05
I0413 11:02:02.023180 21842 solver.cpp:243] Iteration 53200, loss = 2.26793
I0413 11:02:02.023483 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51302 (* 1 = 2.51302 loss)
I0413 11:02:02.023605 21842 sgd_solver.cpp:138] Iteration 53200, lr = 1e-05
I0413 11:06:22.007717 21842 solver.cpp:243] Iteration 53300, loss = 2.27775
I0413 11:06:22.007978 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.80252 (* 1 = 1.80252 loss)
I0413 11:06:23.452963 21842 sgd_solver.cpp:138] Iteration 53300, lr = 1e-05
I0413 11:10:25.125056 21842 solver.cpp:243] Iteration 53400, loss = 2.30143
I0413 11:10:25.125229 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26249 (* 1 = 2.26249 loss)
I0413 11:10:25.125273 21842 sgd_solver.cpp:138] Iteration 53400, lr = 1e-05
I0413 11:14:31.620280 21842 solver.cpp:243] Iteration 53500, loss = 2.36544
I0413 11:14:31.620520 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43222 (* 1 = 2.43222 loss)
I0413 11:14:32.270858 21842 sgd_solver.cpp:138] Iteration 53500, lr = 1e-05
I0413 11:18:43.047695 21842 solver.cpp:243] Iteration 53600, loss = 2.274
I0413 11:18:43.047921 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31303 (* 1 = 2.31303 loss)
I0413 11:18:43.735627 21842 sgd_solver.cpp:138] Iteration 53600, lr = 1e-05
I0413 11:22:52.121450 21842 solver.cpp:243] Iteration 53700, loss = 2.31089
I0413 11:22:52.121661 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30601 (* 1 = 2.30601 loss)
I0413 11:22:52.121757 21842 sgd_solver.cpp:138] Iteration 53700, lr = 1e-05
I0413 11:26:58.828244 21842 solver.cpp:243] Iteration 53800, loss = 2.27267
I0413 11:26:58.828490 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37344 (* 1 = 2.37344 loss)
I0413 11:26:58.828619 21842 sgd_solver.cpp:138] Iteration 53800, lr = 1e-05
I0413 11:31:08.315132 21842 solver.cpp:243] Iteration 53900, loss = 2.29959
I0413 11:31:08.315388 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49354 (* 1 = 2.49354 loss)
I0413 11:31:08.315510 21842 sgd_solver.cpp:138] Iteration 53900, lr = 1e-05
I0413 11:35:11.731138 21842 solver.cpp:243] Iteration 54000, loss = 2.28447
I0413 11:35:11.731382 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28556 (* 1 = 2.28556 loss)
I0413 11:35:12.350700 21842 sgd_solver.cpp:138] Iteration 54000, lr = 1e-05
I0413 11:39:17.510258 21842 solver.cpp:243] Iteration 54100, loss = 2.32811
I0413 11:39:17.510495 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.06045 (* 1 = 3.06045 loss)
I0413 11:39:17.510610 21842 sgd_solver.cpp:138] Iteration 54100, lr = 1e-05
I0413 11:43:25.088209 21842 solver.cpp:243] Iteration 54200, loss = 2.19467
I0413 11:43:25.088430 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96719 (* 1 = 1.96719 loss)
I0413 11:43:25.088542 21842 sgd_solver.cpp:138] Iteration 54200, lr = 1e-05
I0413 11:47:35.391711 21842 solver.cpp:243] Iteration 54300, loss = 2.31565
I0413 11:47:35.391958 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.83403 (* 1 = 2.83403 loss)
I0413 11:47:35.392074 21842 sgd_solver.cpp:138] Iteration 54300, lr = 1e-05
I0413 11:51:40.853989 21842 solver.cpp:243] Iteration 54400, loss = 2.29714
I0413 11:51:40.854254 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4857 (* 1 = 2.4857 loss)
I0413 11:51:42.285034 21842 sgd_solver.cpp:138] Iteration 54400, lr = 1e-05
I0413 11:55:42.339740 21842 solver.cpp:243] Iteration 54500, loss = 2.23356
I0413 11:55:42.339972 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10597 (* 1 = 2.10597 loss)
I0413 11:55:43.124747 21842 sgd_solver.cpp:138] Iteration 54500, lr = 1e-05
I0413 11:59:52.623677 21842 solver.cpp:243] Iteration 54600, loss = 2.3152
I0413 11:59:52.623935 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.14062 (* 1 = 2.14062 loss)
I0413 11:59:52.624052 21842 sgd_solver.cpp:138] Iteration 54600, lr = 1e-05
I0413 12:04:01.073575 21842 solver.cpp:243] Iteration 54700, loss = 2.2658
I0413 12:04:01.073835 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.14841 (* 1 = 2.14841 loss)
I0413 12:04:01.829529 21842 sgd_solver.cpp:138] Iteration 54700, lr = 1e-05
I0413 12:08:09.285650 21842 solver.cpp:243] Iteration 54800, loss = 2.27182
I0413 12:08:09.285898 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.457 (* 1 = 3.457 loss)
I0413 12:08:09.286015 21842 sgd_solver.cpp:138] Iteration 54800, lr = 1e-05
I0413 12:12:17.611191 21842 solver.cpp:243] Iteration 54900, loss = 2.30353
I0413 12:12:17.611490 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1738 (* 1 = 2.1738 loss)
I0413 12:12:17.611528 21842 sgd_solver.cpp:138] Iteration 54900, lr = 1e-05
I0413 12:16:28.544248 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_55000.caffemodel
I0413 12:16:29.657603 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_55000.solverstate
I0413 12:16:29.967241 21842 solver.cpp:433] Iteration 55000, Testing net (#0)
I0413 12:16:29.967317 21842 net.cpp:693] Ignoring source layer mbox_loss
I0413 12:16:54.670125 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.514192
I0413 12:16:56.078326 21842 solver.cpp:243] Iteration 55000, loss = 2.26467
I0413 12:16:56.078387 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56354 (* 1 = 2.56354 loss)
I0413 12:16:57.470574 21842 sgd_solver.cpp:138] Iteration 55000, lr = 1e-05
I0413 12:21:02.667506 21842 solver.cpp:243] Iteration 55100, loss = 2.28459
I0413 12:21:02.667739 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.81873 (* 1 = 1.81873 loss)
I0413 12:21:02.667878 21842 sgd_solver.cpp:138] Iteration 55100, lr = 1e-05
I0413 12:25:11.597666 21842 solver.cpp:243] Iteration 55200, loss = 2.23825
I0413 12:25:11.597919 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24289 (* 1 = 2.24289 loss)
I0413 12:25:12.301561 21842 sgd_solver.cpp:138] Iteration 55200, lr = 1e-05
I0413 12:29:22.559350 21842 solver.cpp:243] Iteration 55300, loss = 2.23069
I0413 12:29:22.559603 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28891 (* 1 = 2.28891 loss)
I0413 12:29:22.559725 21842 sgd_solver.cpp:138] Iteration 55300, lr = 1e-05
I0413 12:33:26.316228 21842 solver.cpp:243] Iteration 55400, loss = 2.23838
I0413 12:33:26.316481 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4431 (* 1 = 2.4431 loss)
I0413 12:33:27.726339 21842 sgd_solver.cpp:138] Iteration 55400, lr = 1e-05
I0413 12:37:35.422845 21842 solver.cpp:243] Iteration 55500, loss = 2.28728
I0413 12:37:35.423097 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.38554 (* 1 = 2.38554 loss)
I0413 12:37:36.844599 21842 sgd_solver.cpp:138] Iteration 55500, lr = 1e-05
I0413 12:41:44.494357 21842 solver.cpp:243] Iteration 55600, loss = 2.23752
I0413 12:41:44.494616 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.47154 (* 1 = 2.47154 loss)
I0413 12:41:44.494758 21842 sgd_solver.cpp:138] Iteration 55600, lr = 1e-05
I0413 12:45:54.749045 21842 solver.cpp:243] Iteration 55700, loss = 2.3022
I0413 12:45:54.749224 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28475 (* 1 = 2.28475 loss)
I0413 12:45:54.749258 21842 sgd_solver.cpp:138] Iteration 55700, lr = 1e-05
I0413 12:50:04.338626 21842 solver.cpp:243] Iteration 55800, loss = 2.27472
I0413 12:50:04.338796 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13355 (* 1 = 2.13355 loss)
I0413 12:50:05.782272 21842 sgd_solver.cpp:138] Iteration 55800, lr = 1e-05
I0413 12:54:10.757742 21842 solver.cpp:243] Iteration 55900, loss = 2.25982
I0413 12:54:10.757899 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11917 (* 1 = 2.11917 loss)
I0413 12:54:10.757937 21842 sgd_solver.cpp:138] Iteration 55900, lr = 1e-05
I0413 12:58:21.680164 21842 solver.cpp:243] Iteration 56000, loss = 2.25367
I0413 12:58:21.680339 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.18777 (* 1 = 2.18777 loss)
I0413 12:58:21.680371 21842 sgd_solver.cpp:138] Iteration 56000, lr = 1e-05
I0413 13:02:36.036998 21842 solver.cpp:243] Iteration 56100, loss = 2.21839
I0413 13:02:36.037207 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.70068 (* 1 = 2.70068 loss)
I0413 13:02:36.037245 21842 sgd_solver.cpp:138] Iteration 56100, lr = 1e-05
I0413 13:06:47.599629 21842 solver.cpp:243] Iteration 56200, loss = 2.27687
I0413 13:06:47.599818 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.3402 (* 1 = 2.3402 loss)
I0413 13:06:47.599856 21842 sgd_solver.cpp:138] Iteration 56200, lr = 1e-05
I0413 13:10:59.331856 21842 solver.cpp:243] Iteration 56300, loss = 2.2441
I0413 13:10:59.332022 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.86268 (* 1 = 1.86268 loss)
I0413 13:11:00.740952 21842 sgd_solver.cpp:138] Iteration 56300, lr = 1e-05
I0413 13:15:12.541193 21842 solver.cpp:243] Iteration 56400, loss = 2.22714
I0413 13:15:12.543205 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24291 (* 1 = 2.24291 loss)
I0413 13:15:13.210716 21842 sgd_solver.cpp:138] Iteration 56400, lr = 1e-05
I0413 13:19:17.302026 21842 solver.cpp:243] Iteration 56500, loss = 2.26566
I0413 13:19:17.302211 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.62992 (* 1 = 2.62992 loss)
I0413 13:19:17.924994 21842 sgd_solver.cpp:138] Iteration 56500, lr = 1e-05
I0413 13:23:25.482219 21842 solver.cpp:243] Iteration 56600, loss = 2.27943
I0413 13:23:25.482399 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.42618 (* 1 = 2.42618 loss)
I0413 13:23:26.092172 21842 sgd_solver.cpp:138] Iteration 56600, lr = 1e-05
I0413 13:27:35.560814 21842 solver.cpp:243] Iteration 56700, loss = 2.16151
I0413 13:27:35.561000 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.01548 (* 1 = 2.01548 loss)
I0413 13:27:36.296083 21842 sgd_solver.cpp:138] Iteration 56700, lr = 1e-05
I0413 13:31:42.250349 21842 solver.cpp:243] Iteration 56800, loss = 2.34532
I0413 13:31:42.250517 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24169 (* 1 = 2.24169 loss)
I0413 13:31:42.250574 21842 sgd_solver.cpp:138] Iteration 56800, lr = 1e-05
I0413 13:35:58.916882 21842 solver.cpp:243] Iteration 56900, loss = 2.25522
I0413 13:35:58.917022 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59037 (* 1 = 2.59037 loss)
I0413 13:35:58.917054 21842 sgd_solver.cpp:138] Iteration 56900, lr = 1e-05
I0413 13:40:07.663796 21842 solver.cpp:243] Iteration 57000, loss = 2.24063
I0413 13:40:07.663993 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.52415 (* 1 = 2.52415 loss)
I0413 13:40:07.664034 21842 sgd_solver.cpp:138] Iteration 57000, lr = 1e-05
I0413 13:44:14.395964 21842 solver.cpp:243] Iteration 57100, loss = 2.28951
I0413 13:44:14.398810 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53664 (* 1 = 2.53664 loss)
I0413 13:44:15.193660 21842 sgd_solver.cpp:138] Iteration 57100, lr = 1e-05
I0413 13:48:27.264012 21842 solver.cpp:243] Iteration 57200, loss = 2.21288
I0413 13:48:27.264153 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91798 (* 1 = 1.91798 loss)
I0413 13:48:28.655391 21842 sgd_solver.cpp:138] Iteration 57200, lr = 1e-05
I0413 13:52:34.201254 21842 solver.cpp:243] Iteration 57300, loss = 2.24828
I0413 13:52:34.201426 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0524 (* 1 = 2.0524 loss)
I0413 13:52:34.201460 21842 sgd_solver.cpp:138] Iteration 57300, lr = 1e-05
I0413 13:56:43.490820 21842 solver.cpp:243] Iteration 57400, loss = 2.30949
I0413 13:56:43.490969 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.16942 (* 1 = 2.16942 loss)
I0413 13:56:43.491003 21842 sgd_solver.cpp:138] Iteration 57400, lr = 1e-05
I0413 14:00:55.113878 21842 solver.cpp:243] Iteration 57500, loss = 2.23301
I0413 14:00:55.114075 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53596 (* 1 = 2.53596 loss)
I0413 14:00:55.114115 21842 sgd_solver.cpp:138] Iteration 57500, lr = 1e-05
I0413 14:05:02.041352 21842 solver.cpp:243] Iteration 57600, loss = 2.32003
I0413 14:05:02.041527 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11699 (* 1 = 2.11699 loss)
I0413 14:05:02.041560 21842 sgd_solver.cpp:138] Iteration 57600, lr = 1e-05
I0413 14:09:04.909829 21842 solver.cpp:243] Iteration 57700, loss = 2.28828
I0413 14:09:04.910019 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.54485 (* 1 = 2.54485 loss)
I0413 14:09:05.517130 21842 sgd_solver.cpp:138] Iteration 57700, lr = 1e-05
I0413 14:13:09.788950 21842 solver.cpp:243] Iteration 57800, loss = 2.21916
I0413 14:13:09.789139 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09293 (* 1 = 2.09293 loss)
I0413 14:13:11.245901 21842 sgd_solver.cpp:138] Iteration 57800, lr = 1e-05
I0413 14:17:18.062978 21842 solver.cpp:243] Iteration 57900, loss = 2.2536
I0413 14:17:18.063179 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31117 (* 1 = 2.31117 loss)
I0413 14:17:18.063215 21842 sgd_solver.cpp:138] Iteration 57900, lr = 1e-05
I0413 14:21:30.361986 21842 solver.cpp:243] Iteration 58000, loss = 2.27485
I0413 14:21:30.362181 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.60941 (* 1 = 2.60941 loss)
I0413 14:21:30.362222 21842 sgd_solver.cpp:138] Iteration 58000, lr = 1e-05
I0413 14:25:40.389008 21842 solver.cpp:243] Iteration 58100, loss = 2.27065
I0413 14:25:40.389166 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50794 (* 1 = 2.50794 loss)
I0413 14:25:40.389207 21842 sgd_solver.cpp:138] Iteration 58100, lr = 1e-05
I0413 14:29:45.220647 21842 solver.cpp:243] Iteration 58200, loss = 2.29326
I0413 14:29:45.220806 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23318 (* 1 = 2.23318 loss)
I0413 14:29:46.628979 21842 sgd_solver.cpp:138] Iteration 58200, lr = 1e-05
I0413 14:33:59.520056 21842 solver.cpp:243] Iteration 58300, loss = 2.25165
I0413 14:33:59.520237 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08418 (* 1 = 2.08418 loss)
I0413 14:33:59.520272 21842 sgd_solver.cpp:138] Iteration 58300, lr = 1e-05
I0413 14:38:05.555984 21842 solver.cpp:243] Iteration 58400, loss = 2.24909
I0413 14:38:05.556174 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.16513 (* 1 = 2.16513 loss)
I0413 14:38:06.971788 21842 sgd_solver.cpp:138] Iteration 58400, lr = 1e-05
I0413 14:42:17.282825 21842 solver.cpp:243] Iteration 58500, loss = 2.29591
I0413 14:42:17.282979 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49021 (* 1 = 2.49021 loss)
I0413 14:42:17.888403 21842 sgd_solver.cpp:138] Iteration 58500, lr = 1e-05
I0413 14:46:35.162694 21842 solver.cpp:243] Iteration 58600, loss = 2.25443
I0413 14:46:35.162897 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.80539 (* 1 = 2.80539 loss)
I0413 14:46:35.162982 21842 sgd_solver.cpp:138] Iteration 58600, lr = 1e-05
I0413 14:50:52.963033 21842 solver.cpp:243] Iteration 58700, loss = 2.27046
I0413 14:50:52.963176 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30173 (* 1 = 2.30173 loss)
I0413 14:50:53.658620 21842 sgd_solver.cpp:138] Iteration 58700, lr = 1e-05
I0413 14:55:26.325479 21842 solver.cpp:243] Iteration 58800, loss = 2.27535
I0413 14:55:26.325635 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98297 (* 1 = 1.98297 loss)
I0413 14:55:27.786830 21842 sgd_solver.cpp:138] Iteration 58800, lr = 1e-05
I0413 14:59:59.731045 21842 solver.cpp:243] Iteration 58900, loss = 2.24638
I0413 14:59:59.731178 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24806 (* 1 = 2.24806 loss)
I0413 14:59:59.731211 21842 sgd_solver.cpp:138] Iteration 58900, lr = 1e-05
I0413 15:04:24.025888 21842 solver.cpp:243] Iteration 59000, loss = 2.25071
I0413 15:04:24.026028 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09899 (* 1 = 2.09899 loss)
I0413 15:04:24.026074 21842 sgd_solver.cpp:138] Iteration 59000, lr = 1e-05
I0413 15:08:49.841874 21842 solver.cpp:243] Iteration 59100, loss = 2.31079
I0413 15:08:49.842037 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96799 (* 1 = 1.96799 loss)
I0413 15:08:51.312034 21842 sgd_solver.cpp:138] Iteration 59100, lr = 1e-05
I0413 15:13:13.821235 21842 solver.cpp:243] Iteration 59200, loss = 2.17566
I0413 15:13:13.821436 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.18253 (* 1 = 2.18253 loss)
I0413 15:13:15.345494 21842 sgd_solver.cpp:138] Iteration 59200, lr = 1e-05
I0413 15:17:40.038427 21842 solver.cpp:243] Iteration 59300, loss = 2.2741
I0413 15:17:40.038578 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.71269 (* 1 = 1.71269 loss)
I0413 15:17:40.829814 21842 sgd_solver.cpp:138] Iteration 59300, lr = 1e-05
I0413 15:22:13.149149 21842 solver.cpp:243] Iteration 59400, loss = 2.29832
I0413 15:22:13.149297 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10381 (* 1 = 2.10381 loss)
I0413 15:22:14.662493 21842 sgd_solver.cpp:138] Iteration 59400, lr = 1e-05
I0413 15:26:32.516276 21842 solver.cpp:243] Iteration 59500, loss = 2.25291
I0413 15:26:32.516486 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04022 (* 1 = 2.04022 loss)
I0413 15:26:33.978072 21842 sgd_solver.cpp:138] Iteration 59500, lr = 1e-05
I0413 15:30:54.587049 21842 solver.cpp:243] Iteration 59600, loss = 2.32658
I0413 15:30:54.587230 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.56018 (* 1 = 2.56018 loss)
I0413 15:30:56.039355 21842 sgd_solver.cpp:138] Iteration 59600, lr = 1e-05
I0413 15:35:20.588989 21842 solver.cpp:243] Iteration 59700, loss = 2.20454
I0413 15:35:20.589129 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04758 (* 1 = 2.04758 loss)
I0413 15:35:20.589175 21842 sgd_solver.cpp:138] Iteration 59700, lr = 1e-05
I0413 15:39:44.860399 21842 solver.cpp:243] Iteration 59800, loss = 2.31103
I0413 15:39:44.860534 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03744 (* 1 = 2.03744 loss)
I0413 15:39:45.587507 21842 sgd_solver.cpp:138] Iteration 59800, lr = 1e-05
I0413 15:44:08.034343 21842 solver.cpp:243] Iteration 59900, loss = 2.2758
I0413 15:44:08.034669 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6084 (* 1 = 2.6084 loss)
I0413 15:44:08.685278 21842 sgd_solver.cpp:138] Iteration 59900, lr = 1e-05
I0413 15:48:36.203440 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_60000.caffemodel
I0413 15:48:37.347276 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_60000.solverstate
I0413 15:48:37.719709 21842 solver.cpp:433] Iteration 60000, Testing net (#0)
I0413 15:48:37.719784 21842 net.cpp:693] Ignoring source layer mbox_loss
I0413 15:49:02.457823 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.520174
I0413 15:49:04.096590 21842 solver.cpp:243] Iteration 60000, loss = 2.23179
I0413 15:49:04.096642 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31416 (* 1 = 2.31416 loss)
I0413 15:49:04.846751 21842 sgd_solver.cpp:138] Iteration 60000, lr = 1e-05
I0413 15:53:23.178791 21842 solver.cpp:243] Iteration 60100, loss = 2.28704
I0413 15:53:23.178964 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.80546 (* 1 = 1.80546 loss)
I0413 15:53:23.792706 21842 sgd_solver.cpp:138] Iteration 60100, lr = 1e-05
I0413 15:57:43.515936 21842 solver.cpp:243] Iteration 60200, loss = 2.32671
I0413 15:57:43.516153 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10681 (* 1 = 2.10681 loss)
I0413 15:57:43.516188 21842 sgd_solver.cpp:138] Iteration 60200, lr = 1e-05
I0413 16:02:06.336787 21842 solver.cpp:243] Iteration 60300, loss = 2.22029
I0413 16:02:06.336959 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.81747 (* 1 = 1.81747 loss)
I0413 16:02:08.045889 21842 sgd_solver.cpp:138] Iteration 60300, lr = 1e-05
I0413 16:06:38.615409 21842 solver.cpp:243] Iteration 60400, loss = 2.25208
I0413 16:06:38.615579 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4629 (* 1 = 2.4629 loss)
I0413 16:06:38.615635 21842 sgd_solver.cpp:138] Iteration 60400, lr = 1e-05
I0413 16:11:00.914415 21842 solver.cpp:243] Iteration 60500, loss = 2.29102
I0413 16:11:00.914598 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.19727 (* 1 = 2.19727 loss)
I0413 16:11:02.419397 21842 sgd_solver.cpp:138] Iteration 60500, lr = 1e-05
I0413 16:15:25.278241 21842 solver.cpp:243] Iteration 60600, loss = 2.22804
I0413 16:15:25.278448 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.58575 (* 1 = 2.58575 loss)
I0413 16:15:25.278520 21842 sgd_solver.cpp:138] Iteration 60600, lr = 1e-05
I0413 16:19:48.674824 21842 solver.cpp:243] Iteration 60700, loss = 2.26832
I0413 16:19:48.674996 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13753 (* 1 = 2.13753 loss)
I0413 16:19:49.540683 21842 sgd_solver.cpp:138] Iteration 60700, lr = 1e-05
I0413 16:24:17.364706 21842 solver.cpp:243] Iteration 60800, loss = 2.24734
I0413 16:24:17.364924 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15501 (* 1 = 2.15501 loss)
I0413 16:24:18.857596 21842 sgd_solver.cpp:138] Iteration 60800, lr = 1e-05
I0413 16:28:35.434576 21842 solver.cpp:243] Iteration 60900, loss = 2.24484
I0413 16:28:35.434741 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06562 (* 1 = 2.06562 loss)
I0413 16:28:35.434773 21842 sgd_solver.cpp:138] Iteration 60900, lr = 1e-05
I0413 16:32:58.588414 21842 solver.cpp:243] Iteration 61000, loss = 2.23897
I0413 16:32:58.588559 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68174 (* 1 = 2.68174 loss)
I0413 16:32:58.588593 21842 sgd_solver.cpp:138] Iteration 61000, lr = 1e-05
I0413 16:37:28.176429 21842 solver.cpp:243] Iteration 61100, loss = 2.22771
I0413 16:37:28.176587 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.05754 (* 1 = 2.05754 loss)
I0413 16:37:29.600584 21842 sgd_solver.cpp:138] Iteration 61100, lr = 1e-05
I0413 16:41:49.392699 21842 solver.cpp:243] Iteration 61200, loss = 2.2587
I0413 16:41:49.392838 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.67441 (* 1 = 2.67441 loss)
I0413 16:41:49.392871 21842 sgd_solver.cpp:138] Iteration 61200, lr = 1e-05
I0413 16:46:16.872746 21842 solver.cpp:243] Iteration 61300, loss = 2.27774
I0413 16:46:16.872972 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24898 (* 1 = 2.24898 loss)
I0413 16:46:16.873013 21842 sgd_solver.cpp:138] Iteration 61300, lr = 1e-05
I0413 16:50:45.207244 21842 solver.cpp:243] Iteration 61400, loss = 2.23867
I0413 16:50:45.207401 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.85939 (* 1 = 2.85939 loss)
I0413 16:50:45.207435 21842 sgd_solver.cpp:138] Iteration 61400, lr = 1e-05
I0413 16:55:09.762301 21842 solver.cpp:243] Iteration 61500, loss = 2.25026
I0413 16:55:09.762502 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35411 (* 1 = 2.35411 loss)
I0413 16:55:09.762574 21842 sgd_solver.cpp:138] Iteration 61500, lr = 1e-05
I0413 16:59:37.805472 21842 solver.cpp:243] Iteration 61600, loss = 2.24468
I0413 16:59:37.805610 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51814 (* 1 = 2.51814 loss)
I0413 16:59:37.805644 21842 sgd_solver.cpp:138] Iteration 61600, lr = 1e-05
I0413 17:03:57.562788 21842 solver.cpp:243] Iteration 61700, loss = 2.20761
I0413 17:03:57.563110 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.38624 (* 1 = 2.38624 loss)
I0413 17:03:58.234544 21842 sgd_solver.cpp:138] Iteration 61700, lr = 1e-05
I0413 17:08:23.344513 21842 solver.cpp:243] Iteration 61800, loss = 2.27668
I0413 17:08:23.344763 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.58575 (* 1 = 2.58575 loss)
I0413 17:08:24.151955 21842 sgd_solver.cpp:138] Iteration 61800, lr = 1e-05
I0413 17:12:53.616914 21842 solver.cpp:243] Iteration 61900, loss = 2.2923
I0413 17:12:53.617054 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.83288 (* 1 = 1.83288 loss)
I0413 17:12:53.617100 21842 sgd_solver.cpp:138] Iteration 61900, lr = 1e-05
I0413 17:17:10.659641 21842 solver.cpp:243] Iteration 62000, loss = 2.2379
I0413 17:17:10.659799 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49405 (* 1 = 2.49405 loss)
I0413 17:17:10.659835 21842 sgd_solver.cpp:138] Iteration 62000, lr = 1e-05
I0413 17:21:38.401499 21842 solver.cpp:243] Iteration 62100, loss = 2.2255
I0413 17:21:38.401657 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.62979 (* 1 = 1.62979 loss)
I0413 17:21:39.836218 21842 sgd_solver.cpp:138] Iteration 62100, lr = 1e-05
I0413 17:26:06.333163 21842 solver.cpp:243] Iteration 62200, loss = 2.25076
I0413 17:26:06.333312 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55371 (* 1 = 2.55371 loss)
I0413 17:26:06.333350 21842 sgd_solver.cpp:138] Iteration 62200, lr = 1e-05
I0413 17:30:28.287930 21842 solver.cpp:243] Iteration 62300, loss = 2.27732
I0413 17:30:28.288077 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.68554 (* 1 = 2.68554 loss)
I0413 17:30:29.708559 21842 sgd_solver.cpp:138] Iteration 62300, lr = 1e-05
I0413 17:34:48.944316 21842 solver.cpp:243] Iteration 62400, loss = 2.27698
I0413 17:34:48.944524 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10574 (* 1 = 2.10574 loss)
I0413 17:34:48.944625 21842 sgd_solver.cpp:138] Iteration 62400, lr = 1e-05
I0413 17:39:16.212774 21842 solver.cpp:243] Iteration 62500, loss = 2.27427
I0413 17:39:16.212921 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.95354 (* 1 = 1.95354 loss)
I0413 17:39:16.212957 21842 sgd_solver.cpp:138] Iteration 62500, lr = 1e-05
I0413 17:43:34.414012 21842 solver.cpp:243] Iteration 62600, loss = 2.31167
I0413 17:43:34.414219 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.18625 (* 1 = 2.18625 loss)
I0413 17:43:35.856083 21842 sgd_solver.cpp:138] Iteration 62600, lr = 1e-05
I0413 17:48:00.332805 21842 solver.cpp:243] Iteration 62700, loss = 2.3013
I0413 17:48:00.332973 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41074 (* 1 = 2.41074 loss)
I0413 17:48:00.965584 21842 sgd_solver.cpp:138] Iteration 62700, lr = 1e-05
I0413 17:52:24.715176 21842 solver.cpp:243] Iteration 62800, loss = 2.23121
I0413 17:52:24.715309 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17461 (* 1 = 2.17461 loss)
I0413 17:52:26.185907 21842 sgd_solver.cpp:138] Iteration 62800, lr = 1e-05
I0413 17:56:54.150048 21842 solver.cpp:243] Iteration 62900, loss = 2.2379
I0413 17:56:54.150194 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.47137 (* 1 = 2.47137 loss)
I0413 17:56:54.150247 21842 sgd_solver.cpp:138] Iteration 62900, lr = 1e-05
I0413 18:01:22.329674 21842 solver.cpp:243] Iteration 63000, loss = 2.23782
I0413 18:01:22.329895 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.78864 (* 1 = 1.78864 loss)
I0413 18:01:23.139564 21842 sgd_solver.cpp:138] Iteration 63000, lr = 1e-05
I0413 18:05:44.240828 21842 solver.cpp:243] Iteration 63100, loss = 2.23122
I0413 18:05:44.240979 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25317 (* 1 = 2.25317 loss)
I0413 18:05:44.888875 21842 sgd_solver.cpp:138] Iteration 63100, lr = 1e-05
I0413 18:10:08.886586 21842 solver.cpp:243] Iteration 63200, loss = 2.2868
I0413 18:10:08.886732 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.85109 (* 1 = 1.85109 loss)
I0413 18:10:08.886780 21842 sgd_solver.cpp:138] Iteration 63200, lr = 1e-05
I0413 18:14:33.247680 21842 solver.cpp:243] Iteration 63300, loss = 2.23153
I0413 18:14:33.247815 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.01983 (* 1 = 3.01983 loss)
I0413 18:14:34.717311 21842 sgd_solver.cpp:138] Iteration 63300, lr = 1e-05
I0413 18:18:57.916159 21842 solver.cpp:243] Iteration 63400, loss = 2.23275
I0413 18:18:57.916301 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31376 (* 1 = 2.31376 loss)
I0413 18:18:57.916335 21842 sgd_solver.cpp:138] Iteration 63400, lr = 1e-05
I0413 18:23:16.029484 21842 solver.cpp:243] Iteration 63500, loss = 2.2888
I0413 18:23:16.029609 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13687 (* 1 = 2.13687 loss)
I0413 18:23:16.029651 21842 sgd_solver.cpp:138] Iteration 63500, lr = 1e-05
I0413 18:27:46.689788 21842 solver.cpp:243] Iteration 63600, loss = 2.23371
I0413 18:27:46.689926 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.64915 (* 1 = 2.64915 loss)
I0413 18:27:48.108759 21842 sgd_solver.cpp:138] Iteration 63600, lr = 1e-05
I0413 18:32:08.401592 21842 solver.cpp:243] Iteration 63700, loss = 2.22837
I0413 18:32:08.401757 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49597 (* 1 = 2.49597 loss)
I0413 18:32:08.401806 21842 sgd_solver.cpp:138] Iteration 63700, lr = 1e-05
I0413 18:36:29.537863 21842 solver.cpp:243] Iteration 63800, loss = 2.26164
I0413 18:36:29.537997 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23785 (* 1 = 2.23785 loss)
I0413 18:36:29.538031 21842 sgd_solver.cpp:138] Iteration 63800, lr = 1e-05
I0413 18:40:58.675583 21842 solver.cpp:243] Iteration 63900, loss = 2.16681
I0413 18:40:58.675722 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07955 (* 1 = 2.07955 loss)
I0413 18:40:58.675767 21842 sgd_solver.cpp:138] Iteration 63900, lr = 1e-05
I0413 18:45:23.533107 21842 solver.cpp:243] Iteration 64000, loss = 2.26441
I0413 18:45:23.533257 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.62833 (* 1 = 2.62833 loss)
I0413 18:45:23.533293 21842 sgd_solver.cpp:138] Iteration 64000, lr = 1e-05
I0413 18:49:47.605168 21842 solver.cpp:243] Iteration 64100, loss = 2.28097
I0413 18:49:47.605304 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12721 (* 1 = 2.12721 loss)
I0413 18:49:49.084159 21842 sgd_solver.cpp:138] Iteration 64100, lr = 1e-05
I0413 18:54:18.341059 21842 solver.cpp:243] Iteration 64200, loss = 2.2098
I0413 18:54:18.341197 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.99917 (* 1 = 1.99917 loss)
I0413 18:54:19.138222 21842 sgd_solver.cpp:138] Iteration 64200, lr = 1e-05
I0413 18:58:38.437103 21842 solver.cpp:243] Iteration 64300, loss = 2.32645
I0413 18:58:38.437248 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.7569 (* 1 = 2.7569 loss)
I0413 18:58:38.437290 21842 sgd_solver.cpp:138] Iteration 64300, lr = 1e-05
I0413 19:03:05.052536 21842 solver.cpp:243] Iteration 64400, loss = 2.30766
I0413 19:03:05.052737 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.78656 (* 1 = 1.78656 loss)
I0413 19:03:05.052827 21842 sgd_solver.cpp:138] Iteration 64400, lr = 1e-05
I0413 19:07:24.515939 21842 solver.cpp:243] Iteration 64500, loss = 2.26783
I0413 19:07:24.516099 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10124 (* 1 = 2.10124 loss)
I0413 19:07:25.270736 21842 sgd_solver.cpp:138] Iteration 64500, lr = 1e-05
I0413 19:11:49.403367 21842 solver.cpp:243] Iteration 64600, loss = 2.24856
I0413 19:11:49.403509 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65076 (* 1 = 2.65076 loss)
I0413 19:11:50.841092 21842 sgd_solver.cpp:138] Iteration 64600, lr = 1e-05
I0413 19:16:18.893180 21842 solver.cpp:243] Iteration 64700, loss = 2.22928
I0413 19:16:18.893312 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24221 (* 1 = 2.24221 loss)
I0413 19:16:20.365048 21842 sgd_solver.cpp:138] Iteration 64700, lr = 1e-05
I0413 19:20:40.369787 21842 solver.cpp:243] Iteration 64800, loss = 2.24663
I0413 19:20:40.369923 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.18337 (* 1 = 2.18337 loss)
I0413 19:20:40.369957 21842 sgd_solver.cpp:138] Iteration 64800, lr = 1e-05
I0413 19:25:02.447860 21842 solver.cpp:243] Iteration 64900, loss = 2.21275
I0413 19:25:02.448004 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.41119 (* 1 = 2.41119 loss)
I0413 19:25:03.853236 21842 sgd_solver.cpp:138] Iteration 64900, lr = 1e-05
I0413 19:29:31.203593 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_65000.caffemodel
I0413 19:29:32.340806 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_65000.solverstate
I0413 19:29:32.707357 21842 solver.cpp:433] Iteration 65000, Testing net (#0)
I0413 19:29:32.707442 21842 net.cpp:693] Ignoring source layer mbox_loss
I0413 19:29:58.406461 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.517625
I0413 19:30:00.341589 21842 solver.cpp:243] Iteration 65000, loss = 2.21129
I0413 19:30:00.341642 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07907 (* 1 = 2.07907 loss)
I0413 19:30:00.341691 21842 sgd_solver.cpp:138] Iteration 65000, lr = 1e-05
I0413 19:34:24.943565 21842 solver.cpp:243] Iteration 65100, loss = 2.28164
I0413 19:34:24.944288 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04527 (* 1 = 2.04527 loss)
I0413 19:34:25.652894 21842 sgd_solver.cpp:138] Iteration 65100, lr = 1e-05
I0413 19:38:46.589211 21842 solver.cpp:243] Iteration 65200, loss = 2.25616
I0413 19:38:46.589421 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13772 (* 1 = 2.13772 loss)
I0413 19:38:46.589469 21842 sgd_solver.cpp:138] Iteration 65200, lr = 1e-05
I0413 19:43:16.648928 21842 solver.cpp:243] Iteration 65300, loss = 2.19834
I0413 19:43:16.649111 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.79443 (* 1 = 1.79443 loss)
I0413 19:43:18.092667 21842 sgd_solver.cpp:138] Iteration 65300, lr = 1e-05
I0413 19:47:45.311610 21842 solver.cpp:243] Iteration 65400, loss = 2.27723
I0413 19:47:45.311743 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55081 (* 1 = 2.55081 loss)
I0413 19:47:45.961156 21842 sgd_solver.cpp:138] Iteration 65400, lr = 1e-05
I0413 19:52:10.581874 21842 solver.cpp:243] Iteration 65500, loss = 2.25647
I0413 19:52:10.583539 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50538 (* 1 = 2.50538 loss)
I0413 19:52:12.016630 21842 sgd_solver.cpp:138] Iteration 65500, lr = 1e-05
I0413 19:56:32.011612 21842 solver.cpp:243] Iteration 65600, loss = 2.20944
I0413 19:56:32.011762 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12157 (* 1 = 2.12157 loss)
I0413 19:56:32.734472 21842 sgd_solver.cpp:138] Iteration 65600, lr = 1e-05
I0413 20:00:56.015911 21842 solver.cpp:243] Iteration 65700, loss = 2.26986
I0413 20:00:56.016058 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26901 (* 1 = 2.26901 loss)
I0413 20:00:56.743829 21842 sgd_solver.cpp:138] Iteration 65700, lr = 1e-05
I0413 20:05:27.939810 21842 solver.cpp:243] Iteration 65800, loss = 2.19391
I0413 20:05:27.939967 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.75815 (* 1 = 1.75815 loss)
I0413 20:05:27.940021 21842 sgd_solver.cpp:138] Iteration 65800, lr = 1e-05
I0413 20:09:50.231182 21842 solver.cpp:243] Iteration 65900, loss = 2.24953
I0413 20:09:50.231362 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.03739 (* 1 = 3.03739 loss)
I0413 20:09:50.947402 21842 sgd_solver.cpp:138] Iteration 65900, lr = 1e-05
I0413 20:14:17.989140 21842 solver.cpp:243] Iteration 66000, loss = 2.23711
I0413 20:14:17.989280 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.3354 (* 1 = 2.3354 loss)
I0413 20:14:17.989315 21842 sgd_solver.cpp:138] Iteration 66000, lr = 1e-05
I0413 20:18:46.983057 21842 solver.cpp:243] Iteration 66100, loss = 2.20121
I0413 20:18:46.983229 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55922 (* 1 = 2.55922 loss)
I0413 20:18:47.775043 21842 sgd_solver.cpp:138] Iteration 66100, lr = 1e-05
I0413 20:23:12.537709 21842 solver.cpp:243] Iteration 66200, loss = 2.23739
I0413 20:23:12.537868 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.8463 (* 1 = 1.8463 loss)
I0413 20:23:12.537919 21842 sgd_solver.cpp:138] Iteration 66200, lr = 1e-05
I0413 20:27:34.074798 21842 solver.cpp:243] Iteration 66300, loss = 2.29831
I0413 20:27:34.074980 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2683 (* 1 = 2.2683 loss)
I0413 20:27:34.075078 21842 sgd_solver.cpp:138] Iteration 66300, lr = 1e-05
I0413 20:31:59.396926 21842 solver.cpp:243] Iteration 66400, loss = 2.19698
I0413 20:31:59.397102 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34294 (* 1 = 2.34294 loss)
I0413 20:32:00.902918 21842 sgd_solver.cpp:138] Iteration 66400, lr = 1e-05
I0413 20:36:27.372154 21842 solver.cpp:243] Iteration 66500, loss = 2.24905
I0413 20:36:27.372329 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.58496 (* 1 = 2.58496 loss)
I0413 20:36:27.372376 21842 sgd_solver.cpp:138] Iteration 66500, lr = 1e-05
I0413 20:40:49.600664 21842 solver.cpp:243] Iteration 66600, loss = 2.28265
I0413 20:40:49.600817 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91205 (* 1 = 1.91205 loss)
I0413 20:40:50.419103 21842 sgd_solver.cpp:138] Iteration 66600, lr = 1e-05
I0413 20:45:12.424762 21842 solver.cpp:243] Iteration 66700, loss = 2.24236
I0413 20:45:12.424892 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07032 (* 1 = 2.07032 loss)
I0413 20:45:12.424924 21842 sgd_solver.cpp:138] Iteration 66700, lr = 1e-05
I0413 20:49:32.600548 21842 solver.cpp:243] Iteration 66800, loss = 2.24581
I0413 20:49:32.600674 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.9101 (* 1 = 1.9101 loss)
I0413 20:49:34.111595 21842 sgd_solver.cpp:138] Iteration 66800, lr = 1e-05
I0413 20:54:05.360700 21842 solver.cpp:243] Iteration 66900, loss = 2.19996
I0413 20:54:05.360828 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.05619 (* 1 = 2.05619 loss)
I0413 20:54:05.360870 21842 sgd_solver.cpp:138] Iteration 66900, lr = 1e-05
I0413 20:58:26.421389 21842 solver.cpp:243] Iteration 67000, loss = 2.21734
I0413 20:58:26.421517 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98006 (* 1 = 1.98006 loss)
I0413 20:58:26.421573 21842 sgd_solver.cpp:138] Iteration 67000, lr = 1e-05
I0413 21:02:51.542934 21842 solver.cpp:243] Iteration 67100, loss = 2.24086
I0413 21:02:51.544320 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59561 (* 1 = 2.59561 loss)
I0413 21:02:52.239565 21842 sgd_solver.cpp:138] Iteration 67100, lr = 1e-05
I0413 21:07:19.175858 21842 solver.cpp:243] Iteration 67200, loss = 2.24582
I0413 21:07:19.176044 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.8168 (* 1 = 1.8168 loss)
I0413 21:07:19.930079 21842 sgd_solver.cpp:138] Iteration 67200, lr = 1e-05
I0413 21:11:39.589537 21842 solver.cpp:243] Iteration 67300, loss = 2.26323
I0413 21:11:39.589701 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.01572 (* 1 = 2.01572 loss)
I0413 21:11:40.304090 21842 sgd_solver.cpp:138] Iteration 67300, lr = 1e-05
I0413 21:16:06.453999 21842 solver.cpp:243] Iteration 67400, loss = 2.24277
I0413 21:16:06.454164 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.77668 (* 1 = 1.77668 loss)
I0413 21:16:07.955610 21842 sgd_solver.cpp:138] Iteration 67400, lr = 1e-05
I0413 21:20:32.771119 21842 solver.cpp:243] Iteration 67500, loss = 2.17359
I0413 21:20:32.771256 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08511 (* 1 = 2.08511 loss)
I0413 21:20:32.771291 21842 sgd_solver.cpp:138] Iteration 67500, lr = 1e-05
I0413 21:25:00.344578 21842 solver.cpp:243] Iteration 67600, loss = 2.24052
I0413 21:25:00.344743 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17242 (* 1 = 2.17242 loss)
I0413 21:25:00.344781 21842 sgd_solver.cpp:138] Iteration 67600, lr = 1e-05
I0413 21:29:21.162202 21842 solver.cpp:243] Iteration 67700, loss = 2.26435
I0413 21:29:21.162398 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24899 (* 1 = 2.24899 loss)
I0413 21:29:22.645896 21842 sgd_solver.cpp:138] Iteration 67700, lr = 1e-05
I0413 21:33:49.188659 21842 solver.cpp:243] Iteration 67800, loss = 2.15729
I0413 21:33:49.188823 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26758 (* 1 = 2.26758 loss)
I0413 21:33:49.188941 21842 sgd_solver.cpp:138] Iteration 67800, lr = 1e-05
I0413 21:38:14.674121 21842 solver.cpp:243] Iteration 67900, loss = 2.25796
I0413 21:38:14.674257 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.68632 (* 1 = 1.68632 loss)
I0413 21:38:14.674300 21842 sgd_solver.cpp:138] Iteration 67900, lr = 1e-05
I0413 21:42:42.999908 21842 solver.cpp:243] Iteration 68000, loss = 2.25939
I0413 21:42:43.000054 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.93386 (* 1 = 1.93386 loss)
I0413 21:42:43.740732 21842 sgd_solver.cpp:138] Iteration 68000, lr = 1e-05
I0413 21:47:05.555004 21842 solver.cpp:243] Iteration 68100, loss = 2.21466
I0413 21:47:05.555186 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.69827 (* 1 = 2.69827 loss)
I0413 21:47:06.218822 21842 sgd_solver.cpp:138] Iteration 68100, lr = 1e-05
I0413 21:51:34.892765 21842 solver.cpp:243] Iteration 68200, loss = 2.24343
I0413 21:51:34.893024 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09952 (* 1 = 2.09952 loss)
I0413 21:51:34.893071 21842 sgd_solver.cpp:138] Iteration 68200, lr = 1e-05
I0413 21:56:02.011975 21842 solver.cpp:243] Iteration 68300, loss = 2.2022
I0413 21:56:02.012114 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57082 (* 1 = 2.57082 loss)
I0413 21:56:02.012148 21842 sgd_solver.cpp:138] Iteration 68300, lr = 1e-05
I0413 22:00:23.826223 21842 solver.cpp:243] Iteration 68400, loss = 2.24887
I0413 22:00:23.826421 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15677 (* 1 = 2.15677 loss)
I0413 22:00:25.316692 21842 sgd_solver.cpp:138] Iteration 68400, lr = 1e-05
I0413 22:04:53.057389 21842 solver.cpp:243] Iteration 68500, loss = 2.29552
I0413 22:04:53.057520 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23164 (* 1 = 2.23164 loss)
I0413 22:04:53.057557 21842 sgd_solver.cpp:138] Iteration 68500, lr = 1e-05
I0413 22:09:21.139111 21842 solver.cpp:243] Iteration 68600, loss = 2.23463
I0413 22:09:21.139240 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12509 (* 1 = 2.12509 loss)
I0413 22:09:22.014714 21842 sgd_solver.cpp:138] Iteration 68600, lr = 1e-05
I0413 22:13:47.266757 21842 solver.cpp:243] Iteration 68700, loss = 2.2684
I0413 22:13:47.266947 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23728 (* 1 = 2.23728 loss)
I0413 22:13:47.932575 21842 sgd_solver.cpp:138] Iteration 68700, lr = 1e-05
I0413 22:18:12.581245 21842 solver.cpp:243] Iteration 68800, loss = 2.17989
I0413 22:18:12.581380 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04321 (* 1 = 2.04321 loss)
I0413 22:18:12.581411 21842 sgd_solver.cpp:138] Iteration 68800, lr = 1e-05
I0413 22:22:40.164273 21842 solver.cpp:243] Iteration 68900, loss = 2.18369
I0413 22:22:40.167481 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.61944 (* 1 = 1.61944 loss)
I0413 22:22:41.616716 21842 sgd_solver.cpp:138] Iteration 68900, lr = 1e-05
I0413 22:27:08.059178 21842 solver.cpp:243] Iteration 69000, loss = 2.23611
I0413 22:27:08.059365 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.97169 (* 1 = 1.97169 loss)
I0413 22:27:08.798455 21842 sgd_solver.cpp:138] Iteration 69000, lr = 1e-05
I0413 22:31:37.795977 21842 solver.cpp:243] Iteration 69100, loss = 2.31371
I0413 22:31:37.796145 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96385 (* 1 = 1.96385 loss)
I0413 22:31:38.585360 21842 sgd_solver.cpp:138] Iteration 69100, lr = 1e-05
I0413 22:36:04.385751 21842 solver.cpp:243] Iteration 69200, loss = 2.15094
I0413 22:36:04.385881 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.29484 (* 1 = 2.29484 loss)
I0413 22:36:05.160979 21842 sgd_solver.cpp:138] Iteration 69200, lr = 1e-05
I0413 22:40:36.059033 21842 solver.cpp:243] Iteration 69300, loss = 2.23072
I0413 22:40:36.059201 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06499 (* 1 = 2.06499 loss)
I0413 22:40:36.722079 21842 sgd_solver.cpp:138] Iteration 69300, lr = 1e-05
I0413 22:45:04.528091 21842 solver.cpp:243] Iteration 69400, loss = 2.24503
I0413 22:45:04.528213 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.16158 (* 1 = 2.16158 loss)
I0413 22:45:05.966804 21842 sgd_solver.cpp:138] Iteration 69400, lr = 1e-05
I0413 22:49:29.701891 21842 solver.cpp:243] Iteration 69500, loss = 2.2585
I0413 22:49:29.702042 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10675 (* 1 = 2.10675 loss)
I0413 22:49:29.702085 21842 sgd_solver.cpp:138] Iteration 69500, lr = 1e-05
I0413 22:53:52.853070 21842 solver.cpp:243] Iteration 69600, loss = 2.25102
I0413 22:53:52.853217 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.93978 (* 1 = 1.93978 loss)
I0413 22:53:52.853271 21842 sgd_solver.cpp:138] Iteration 69600, lr = 1e-05
I0413 22:58:19.069761 21842 solver.cpp:243] Iteration 69700, loss = 2.19189
I0413 22:58:19.069955 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.21602 (* 1 = 2.21602 loss)
I0413 22:58:20.518831 21842 sgd_solver.cpp:138] Iteration 69700, lr = 1e-05
I0413 23:02:39.131991 21842 solver.cpp:243] Iteration 69800, loss = 2.26254
I0413 23:02:39.132212 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.21976 (* 1 = 2.21976 loss)
I0413 23:02:39.132257 21842 sgd_solver.cpp:138] Iteration 69800, lr = 1e-05
I0413 23:06:59.939888 21842 solver.cpp:243] Iteration 69900, loss = 2.22329
I0413 23:06:59.940047 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.95474 (* 1 = 1.95474 loss)
I0413 23:06:59.940088 21842 sgd_solver.cpp:138] Iteration 69900, lr = 1e-05
I0413 23:11:22.748566 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_70000.caffemodel
I0413 23:11:23.998817 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_70000.solverstate
I0413 23:11:24.509860 21842 solver.cpp:433] Iteration 70000, Testing net (#0)
I0413 23:11:24.509943 21842 net.cpp:693] Ignoring source layer mbox_loss
I0413 23:11:49.183842 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.525231
I0413 23:11:50.497370 21842 solver.cpp:243] Iteration 70000, loss = 2.23544
I0413 23:11:50.497418 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0909 (* 1 = 2.0909 loss)
I0413 23:11:52.016080 21842 sgd_solver.cpp:138] Iteration 70000, lr = 1e-05
I0413 23:16:11.546648 21842 solver.cpp:243] Iteration 70100, loss = 2.20428
I0413 23:16:11.546804 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0356 (* 1 = 2.0356 loss)
I0413 23:16:12.166170 21842 sgd_solver.cpp:138] Iteration 70100, lr = 1e-05
I0413 23:20:32.923149 21842 solver.cpp:243] Iteration 70200, loss = 2.26712
I0413 23:20:32.923394 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23211 (* 1 = 2.23211 loss)
I0413 23:20:33.853118 21842 sgd_solver.cpp:138] Iteration 70200, lr = 1e-05
I0413 23:24:59.314479 21842 solver.cpp:243] Iteration 70300, loss = 2.17077
I0413 23:24:59.314615 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.76391 (* 1 = 1.76391 loss)
I0413 23:25:00.754309 21842 sgd_solver.cpp:138] Iteration 70300, lr = 1e-05
I0413 23:29:23.197373 21842 solver.cpp:243] Iteration 70400, loss = 2.26026
I0413 23:29:23.197576 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96932 (* 1 = 1.96932 loss)
I0413 23:29:24.659436 21842 sgd_solver.cpp:138] Iteration 70400, lr = 1e-05
I0413 23:33:52.593298 21842 solver.cpp:243] Iteration 70500, loss = 2.31208
I0413 23:33:52.593457 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06815 (* 1 = 2.06815 loss)
I0413 23:33:54.087734 21842 sgd_solver.cpp:138] Iteration 70500, lr = 1e-05
I0413 23:38:16.961921 21842 solver.cpp:243] Iteration 70600, loss = 2.23791
I0413 23:38:16.962059 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.61633 (* 1 = 2.61633 loss)
I0413 23:38:16.962102 21842 sgd_solver.cpp:138] Iteration 70600, lr = 1e-05
I0413 23:42:42.779942 21842 solver.cpp:243] Iteration 70700, loss = 2.27499
I0413 23:42:42.780133 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.19107 (* 1 = 2.19107 loss)
I0413 23:42:43.603679 21842 sgd_solver.cpp:138] Iteration 70700, lr = 1e-05
I0413 23:47:13.298935 21842 solver.cpp:243] Iteration 70800, loss = 2.24405
I0413 23:47:13.299072 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.07105 (* 1 = 2.07105 loss)
I0413 23:47:13.299110 21842 sgd_solver.cpp:138] Iteration 70800, lr = 1e-05
I0413 23:51:34.810997 21842 solver.cpp:243] Iteration 70900, loss = 2.29463
I0413 23:51:34.811208 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09769 (* 1 = 2.09769 loss)
I0413 23:51:36.299111 21842 sgd_solver.cpp:138] Iteration 70900, lr = 1e-05
I0413 23:56:01.102742 21842 solver.cpp:243] Iteration 71000, loss = 2.25631
I0413 23:56:01.103057 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.20603 (* 1 = 2.20603 loss)
I0413 23:56:01.103106 21842 sgd_solver.cpp:138] Iteration 71000, lr = 1e-05
I0414 00:00:29.595639 21842 solver.cpp:243] Iteration 71100, loss = 2.1891
I0414 00:00:29.595809 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2771 (* 1 = 2.2771 loss)
I0414 00:00:30.330176 21842 sgd_solver.cpp:138] Iteration 71100, lr = 1e-05
I0414 00:04:50.369093 21842 solver.cpp:243] Iteration 71200, loss = 2.26922
I0414 00:04:50.369216 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37355 (* 1 = 2.37355 loss)
I0414 00:04:50.369249 21842 sgd_solver.cpp:138] Iteration 71200, lr = 1e-05
I0414 00:09:15.653735 21842 solver.cpp:243] Iteration 71300, loss = 2.25332
I0414 00:09:15.653972 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25727 (* 1 = 2.25727 loss)
I0414 00:09:15.654048 21842 sgd_solver.cpp:138] Iteration 71300, lr = 1e-05
I0414 00:13:46.276795 21842 solver.cpp:243] Iteration 71400, loss = 2.19406
I0414 00:13:46.276933 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.90688 (* 1 = 1.90688 loss)
I0414 00:13:47.083176 21842 sgd_solver.cpp:138] Iteration 71400, lr = 1e-05
I0414 00:18:10.349036 21842 solver.cpp:243] Iteration 71500, loss = 2.22876
I0414 00:18:10.349236 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.68383 (* 1 = 1.68383 loss)
I0414 00:18:11.237370 21842 sgd_solver.cpp:138] Iteration 71500, lr = 1e-05
I0414 00:22:40.369161 21842 solver.cpp:243] Iteration 71600, loss = 2.2538
I0414 00:22:40.369377 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09029 (* 1 = 2.09029 loss)
I0414 00:22:41.107393 21842 sgd_solver.cpp:138] Iteration 71600, lr = 1e-05
I0414 00:27:04.813274 21842 solver.cpp:243] Iteration 71700, loss = 2.21816
I0414 00:27:04.813459 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.20759 (* 1 = 2.20759 loss)
I0414 00:27:04.813496 21842 sgd_solver.cpp:138] Iteration 71700, lr = 1e-05
I0414 00:31:28.285923 21842 solver.cpp:243] Iteration 71800, loss = 2.28674
I0414 00:31:28.286067 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37415 (* 1 = 2.37415 loss)
I0414 00:31:29.059922 21842 sgd_solver.cpp:138] Iteration 71800, lr = 1e-05
I0414 00:35:57.035862 21842 solver.cpp:243] Iteration 71900, loss = 2.25215
I0414 00:35:57.036005 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93632 (* 1 = 2.93632 loss)
I0414 00:35:58.516132 21842 sgd_solver.cpp:138] Iteration 71900, lr = 1e-05
I0414 00:40:24.383661 21842 solver.cpp:243] Iteration 72000, loss = 2.20886
I0414 00:40:24.383846 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17863 (* 1 = 2.17863 loss)
I0414 00:40:24.383957 21842 sgd_solver.cpp:138] Iteration 72000, lr = 1e-05
I0414 00:44:46.505009 21842 solver.cpp:243] Iteration 72100, loss = 2.2823
I0414 00:44:46.505153 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15943 (* 1 = 2.15943 loss)
I0414 00:44:46.505189 21842 sgd_solver.cpp:138] Iteration 72100, lr = 1e-05
I0414 00:49:18.672113 21842 solver.cpp:243] Iteration 72200, loss = 2.19058
I0414 00:49:18.672230 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.80033 (* 1 = 1.80033 loss)
I0414 00:49:18.672272 21842 sgd_solver.cpp:138] Iteration 72200, lr = 1e-05
I0414 00:53:45.187973 21842 solver.cpp:243] Iteration 72300, loss = 2.26788
I0414 00:53:45.188123 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03833 (* 1 = 2.03833 loss)
I0414 00:53:46.597209 21842 sgd_solver.cpp:138] Iteration 72300, lr = 1e-05
I0414 00:58:08.393090 21842 solver.cpp:243] Iteration 72400, loss = 2.25323
I0414 00:58:08.393254 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11685 (* 1 = 2.11685 loss)
I0414 00:58:09.142779 21842 sgd_solver.cpp:138] Iteration 72400, lr = 1e-05
I0414 01:02:39.375532 21842 solver.cpp:243] Iteration 72500, loss = 2.20258
I0414 01:02:39.375670 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.18356 (* 1 = 2.18356 loss)
I0414 01:02:39.375727 21842 sgd_solver.cpp:138] Iteration 72500, lr = 1e-05
I0414 01:07:05.407704 21842 solver.cpp:243] Iteration 72600, loss = 2.20381
I0414 01:07:05.407887 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.81539 (* 1 = 2.81539 loss)
I0414 01:07:06.846753 21842 sgd_solver.cpp:138] Iteration 72600, lr = 1e-05
I0414 01:11:31.636574 21842 solver.cpp:243] Iteration 72700, loss = 2.20557
I0414 01:11:31.636744 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10693 (* 1 = 2.10693 loss)
I0414 01:11:33.987514 21842 sgd_solver.cpp:138] Iteration 72700, lr = 1e-05
I0414 01:15:54.908263 21842 solver.cpp:243] Iteration 72800, loss = 2.16238
I0414 01:15:54.908390 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27167 (* 1 = 2.27167 loss)
I0414 01:15:56.407099 21842 sgd_solver.cpp:138] Iteration 72800, lr = 1e-05
I0414 01:20:23.636196 21842 solver.cpp:243] Iteration 72900, loss = 2.25198
I0414 01:20:23.636353 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.02323 (* 1 = 2.02323 loss)
I0414 01:20:23.636471 21842 sgd_solver.cpp:138] Iteration 72900, lr = 1e-05
I0414 01:24:55.200842 21842 solver.cpp:243] Iteration 73000, loss = 2.21425
I0414 01:24:55.201007 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.95007 (* 1 = 1.95007 loss)
I0414 01:24:55.201056 21842 sgd_solver.cpp:138] Iteration 73000, lr = 1e-05
I0414 01:29:18.784683 21842 solver.cpp:243] Iteration 73100, loss = 2.23633
I0414 01:29:18.784857 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04157 (* 1 = 2.04157 loss)
I0414 01:29:19.513856 21842 sgd_solver.cpp:138] Iteration 73100, lr = 1e-05
I0414 01:33:42.612035 21842 solver.cpp:243] Iteration 73200, loss = 2.29057
I0414 01:33:42.612196 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.35215 (* 1 = 3.35215 loss)
I0414 01:33:43.345542 21842 sgd_solver.cpp:138] Iteration 73200, lr = 1e-05
I0414 01:38:11.242740 21842 solver.cpp:243] Iteration 73300, loss = 2.21383
I0414 01:38:11.242893 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36759 (* 1 = 2.36759 loss)
I0414 01:38:12.682090 21842 sgd_solver.cpp:138] Iteration 73300, lr = 1e-05
I0414 01:42:35.065513 21842 solver.cpp:243] Iteration 73400, loss = 2.23596
I0414 01:42:35.065644 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.90146 (* 1 = 1.90146 loss)
I0414 01:42:35.065685 21842 sgd_solver.cpp:138] Iteration 73400, lr = 1e-05
I0414 01:47:03.576722 21842 solver.cpp:243] Iteration 73500, loss = 2.27116
I0414 01:47:03.576877 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.63688 (* 1 = 2.63688 loss)
I0414 01:47:03.576931 21842 sgd_solver.cpp:138] Iteration 73500, lr = 1e-05
I0414 01:51:28.324805 21842 solver.cpp:243] Iteration 73600, loss = 2.21348
I0414 01:51:28.324960 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.39352 (* 1 = 2.39352 loss)
I0414 01:51:29.198318 21842 sgd_solver.cpp:138] Iteration 73600, lr = 1e-05
I0414 01:55:54.640467 21842 solver.cpp:243] Iteration 73700, loss = 2.20799
I0414 01:55:54.640607 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43159 (* 1 = 2.43159 loss)
I0414 01:55:54.640653 21842 sgd_solver.cpp:138] Iteration 73700, lr = 1e-05
I0414 02:00:19.531641 21842 solver.cpp:243] Iteration 73800, loss = 2.2121
I0414 02:00:19.531778 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51586 (* 1 = 2.51586 loss)
I0414 02:00:20.981360 21842 sgd_solver.cpp:138] Iteration 73800, lr = 1e-05
I0414 02:04:45.778373 21842 solver.cpp:243] Iteration 73900, loss = 2.17118
I0414 02:04:45.778512 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.20374 (* 1 = 2.20374 loss)
I0414 02:04:47.264086 21842 sgd_solver.cpp:138] Iteration 73900, lr = 1e-05
I0414 02:09:09.292487 21842 solver.cpp:243] Iteration 74000, loss = 2.23912
I0414 02:09:09.292666 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73592 (* 1 = 2.73592 loss)
I0414 02:09:10.749110 21842 sgd_solver.cpp:138] Iteration 74000, lr = 1e-05
I0414 02:13:32.948777 21842 solver.cpp:243] Iteration 74100, loss = 2.27525
I0414 02:13:32.948976 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57919 (* 1 = 2.57919 loss)
I0414 02:13:34.460747 21842 sgd_solver.cpp:138] Iteration 74100, lr = 1e-05
I0414 02:17:54.628134 21842 solver.cpp:243] Iteration 74200, loss = 2.18299
I0414 02:17:54.628270 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26093 (* 1 = 2.26093 loss)
I0414 02:17:56.086396 21842 sgd_solver.cpp:138] Iteration 74200, lr = 1e-05
I0414 02:22:15.265197 21842 solver.cpp:243] Iteration 74300, loss = 2.25539
I0414 02:22:15.265369 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.82001 (* 1 = 1.82001 loss)
I0414 02:22:15.869237 21842 sgd_solver.cpp:138] Iteration 74300, lr = 1e-05
I0414 02:26:45.525370 21842 solver.cpp:243] Iteration 74400, loss = 2.21479
I0414 02:26:45.525506 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.5926 (* 1 = 2.5926 loss)
I0414 02:26:46.999330 21842 sgd_solver.cpp:138] Iteration 74400, lr = 1e-05
I0414 02:31:07.650461 21842 solver.cpp:243] Iteration 74500, loss = 2.21089
I0414 02:31:07.650614 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23424 (* 1 = 2.23424 loss)
I0414 02:31:07.650712 21842 sgd_solver.cpp:138] Iteration 74500, lr = 1e-05
I0414 02:35:25.581332 21842 solver.cpp:243] Iteration 74600, loss = 2.24739
I0414 02:35:25.581459 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26474 (* 1 = 2.26474 loss)
I0414 02:35:25.581493 21842 sgd_solver.cpp:138] Iteration 74600, lr = 1e-05
I0414 02:39:54.654109 21842 solver.cpp:243] Iteration 74700, loss = 2.2099
I0414 02:39:54.654285 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.55435 (* 1 = 3.55435 loss)
I0414 02:39:56.104907 21842 sgd_solver.cpp:138] Iteration 74700, lr = 1e-05
I0414 02:44:17.185392 21842 solver.cpp:243] Iteration 74800, loss = 2.23459
I0414 02:44:17.185557 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.18584 (* 1 = 2.18584 loss)
I0414 02:44:18.606479 21842 sgd_solver.cpp:138] Iteration 74800, lr = 1e-05
I0414 02:48:44.324482 21842 solver.cpp:243] Iteration 74900, loss = 2.22976
I0414 02:48:44.324635 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32171 (* 1 = 2.32171 loss)
I0414 02:48:45.135329 21842 sgd_solver.cpp:138] Iteration 74900, lr = 1e-05
I0414 02:53:12.852834 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_75000.caffemodel
I0414 02:53:14.109140 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_75000.solverstate
I0414 02:53:14.622895 21842 solver.cpp:433] Iteration 75000, Testing net (#0)
I0414 02:53:14.622968 21842 net.cpp:693] Ignoring source layer mbox_loss
I0414 02:53:40.485913 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.510552
I0414 02:53:41.661226 21842 solver.cpp:243] Iteration 75000, loss = 2.20271
I0414 02:53:41.661281 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59022 (* 1 = 2.59022 loss)
I0414 02:53:43.090059 21842 sgd_solver.cpp:138] Iteration 75000, lr = 1e-05
I0414 02:58:04.809168 21842 solver.cpp:243] Iteration 75100, loss = 2.23279
I0414 02:58:04.809304 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.24403 (* 1 = 2.24403 loss)
I0414 02:58:04.809337 21842 sgd_solver.cpp:138] Iteration 75100, lr = 1e-05
I0414 03:02:30.342223 21842 solver.cpp:243] Iteration 75200, loss = 2.22869
I0414 03:02:30.342357 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91418 (* 1 = 1.91418 loss)
I0414 03:02:31.782871 21842 sgd_solver.cpp:138] Iteration 75200, lr = 1e-05
I0414 03:06:53.111202 21842 solver.cpp:243] Iteration 75300, loss = 2.17593
I0414 03:06:53.111377 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.5479 (* 1 = 1.5479 loss)
I0414 03:06:53.111477 21842 sgd_solver.cpp:138] Iteration 75300, lr = 1e-05
I0414 03:11:16.254997 21842 solver.cpp:243] Iteration 75400, loss = 2.26167
I0414 03:11:16.255208 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.82916 (* 1 = 2.82916 loss)
I0414 03:11:16.926728 21842 sgd_solver.cpp:138] Iteration 75400, lr = 1e-05
I0414 03:15:43.806035 21842 solver.cpp:243] Iteration 75500, loss = 2.21655
I0414 03:15:43.806169 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32845 (* 1 = 2.32845 loss)
I0414 03:15:44.486093 21842 sgd_solver.cpp:138] Iteration 75500, lr = 1e-05
I0414 03:20:07.542084 21842 solver.cpp:243] Iteration 75600, loss = 2.18549
I0414 03:20:07.542215 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.20052 (* 1 = 2.20052 loss)
I0414 03:20:07.542258 21842 sgd_solver.cpp:138] Iteration 75600, lr = 1e-05
I0414 03:24:38.031515 21842 solver.cpp:243] Iteration 75700, loss = 2.24751
I0414 03:24:38.031707 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98109 (* 1 = 1.98109 loss)
I0414 03:24:38.031798 21842 sgd_solver.cpp:138] Iteration 75700, lr = 1e-05
I0414 03:29:04.683231 21842 solver.cpp:243] Iteration 75800, loss = 2.14962
I0414 03:29:04.683367 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.38156 (* 1 = 2.38156 loss)
I0414 03:29:04.683413 21842 sgd_solver.cpp:138] Iteration 75800, lr = 1e-05
I0414 03:33:29.725399 21842 solver.cpp:243] Iteration 75900, loss = 2.24996
I0414 03:33:29.725569 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.52863 (* 1 = 2.52863 loss)
I0414 03:33:30.381700 21842 sgd_solver.cpp:138] Iteration 75900, lr = 1e-05
I0414 03:37:59.053241 21842 solver.cpp:243] Iteration 76000, loss = 2.16686
I0414 03:37:59.053406 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.92095 (* 1 = 1.92095 loss)
I0414 03:37:59.053450 21842 sgd_solver.cpp:138] Iteration 76000, lr = 1e-05
I0414 03:42:25.284880 21842 solver.cpp:243] Iteration 76100, loss = 2.2235
I0414 03:42:25.285018 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28588 (* 1 = 2.28588 loss)
I0414 03:42:26.037192 21842 sgd_solver.cpp:138] Iteration 76100, lr = 1e-05
I0414 03:46:52.147565 21842 solver.cpp:243] Iteration 76200, loss = 2.22447
I0414 03:46:52.147711 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.75005 (* 1 = 1.75005 loss)
I0414 03:46:53.599239 21842 sgd_solver.cpp:138] Iteration 76200, lr = 1e-05
I0414 03:51:13.100670 21842 solver.cpp:243] Iteration 76300, loss = 2.27198
I0414 03:51:13.100859 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37968 (* 1 = 2.37968 loss)
I0414 03:51:13.782820 21842 sgd_solver.cpp:138] Iteration 76300, lr = 1e-05
I0414 03:55:43.264008 21842 solver.cpp:243] Iteration 76400, loss = 2.18249
I0414 03:55:43.264135 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49061 (* 1 = 2.49061 loss)
I0414 03:55:43.264191 21842 sgd_solver.cpp:138] Iteration 76400, lr = 1e-05
I0414 04:00:02.646397 21842 solver.cpp:243] Iteration 76500, loss = 2.22392
I0414 04:00:02.646522 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26551 (* 1 = 2.26551 loss)
I0414 04:00:02.646554 21842 sgd_solver.cpp:138] Iteration 76500, lr = 1e-05
I0414 04:04:25.814208 21842 solver.cpp:243] Iteration 76600, loss = 2.26937
I0414 04:04:25.814370 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12975 (* 1 = 2.12975 loss)
I0414 04:04:26.592296 21842 sgd_solver.cpp:138] Iteration 76600, lr = 1e-05
I0414 04:08:44.585749 21842 solver.cpp:243] Iteration 76700, loss = 2.21606
I0414 04:08:44.585963 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.19357 (* 1 = 2.19357 loss)
I0414 04:08:46.013968 21842 sgd_solver.cpp:138] Iteration 76700, lr = 1e-05
I0414 04:13:13.414005 21842 solver.cpp:243] Iteration 76800, loss = 2.25508
I0414 04:13:13.414176 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.33767 (* 1 = 2.33767 loss)
I0414 04:13:14.182957 21842 sgd_solver.cpp:138] Iteration 76800, lr = 1e-05
I0414 04:17:44.837947 21842 solver.cpp:243] Iteration 76900, loss = 2.15619
I0414 04:17:44.838091 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96867 (* 1 = 1.96867 loss)
I0414 04:17:45.530232 21842 sgd_solver.cpp:138] Iteration 76900, lr = 1e-05
I0414 04:22:07.145354 21842 solver.cpp:243] Iteration 77000, loss = 2.23547
I0414 04:22:07.145514 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.81888 (* 1 = 1.81888 loss)
I0414 04:22:07.145558 21842 sgd_solver.cpp:138] Iteration 77000, lr = 1e-05
I0414 04:26:33.003803 21842 solver.cpp:243] Iteration 77100, loss = 2.18218
I0414 04:26:33.003964 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.48145 (* 1 = 2.48145 loss)
I0414 04:26:33.004000 21842 sgd_solver.cpp:138] Iteration 77100, lr = 1e-05
I0414 04:30:58.459436 21842 solver.cpp:243] Iteration 77200, loss = 2.2213
I0414 04:30:58.459575 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91242 (* 1 = 1.91242 loss)
I0414 04:30:58.459619 21842 sgd_solver.cpp:138] Iteration 77200, lr = 1e-05
I0414 04:35:20.357484 21842 solver.cpp:243] Iteration 77300, loss = 2.23246
I0414 04:35:20.357647 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.52354 (* 1 = 2.52354 loss)
I0414 04:35:20.357691 21842 sgd_solver.cpp:138] Iteration 77300, lr = 1e-05
I0414 04:39:46.704231 21842 solver.cpp:243] Iteration 77400, loss = 2.23998
I0414 04:39:46.704383 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08325 (* 1 = 2.08325 loss)
I0414 04:39:46.704427 21842 sgd_solver.cpp:138] Iteration 77400, lr = 1e-05
I0414 04:44:17.499858 21842 solver.cpp:243] Iteration 77500, loss = 2.19429
I0414 04:44:17.499994 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91276 (* 1 = 1.91276 loss)
I0414 04:44:17.500037 21842 sgd_solver.cpp:138] Iteration 77500, lr = 1e-05
I0414 04:48:43.178537 21842 solver.cpp:243] Iteration 77600, loss = 2.19846
I0414 04:48:43.178723 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.99442 (* 1 = 1.99442 loss)
I0414 04:48:44.068365 21842 sgd_solver.cpp:138] Iteration 77600, lr = 1e-05
I0414 04:53:05.675712 21842 solver.cpp:243] Iteration 77700, loss = 2.2141
I0414 04:53:05.675904 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.16384 (* 1 = 2.16384 loss)
I0414 04:53:05.675966 21842 sgd_solver.cpp:138] Iteration 77700, lr = 1e-05
I0414 04:57:28.204468 21842 solver.cpp:243] Iteration 77800, loss = 2.13166
I0414 04:57:28.204633 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49742 (* 1 = 2.49742 loss)
I0414 04:57:29.681674 21842 sgd_solver.cpp:138] Iteration 77800, lr = 1e-05
I0414 05:01:57.647346 21842 solver.cpp:243] Iteration 77900, loss = 2.26038
I0414 05:01:57.647505 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0428 (* 1 = 2.0428 loss)
I0414 05:01:57.647600 21842 sgd_solver.cpp:138] Iteration 77900, lr = 1e-05
I0414 05:06:22.117795 21842 solver.cpp:243] Iteration 78000, loss = 2.22145
I0414 05:06:22.117944 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.69029 (* 1 = 1.69029 loss)
I0414 05:06:22.117977 21842 sgd_solver.cpp:138] Iteration 78000, lr = 1e-05
I0414 05:10:46.220516 21842 solver.cpp:243] Iteration 78100, loss = 2.20104
I0414 05:10:46.220695 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32542 (* 1 = 2.32542 loss)
I0414 05:10:47.700011 21842 sgd_solver.cpp:138] Iteration 78100, lr = 1e-05
I0414 05:15:10.359086 21842 solver.cpp:243] Iteration 78200, loss = 2.22854
I0414 05:15:10.359248 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.1703 (* 1 = 3.1703 loss)
I0414 05:15:10.978075 21842 sgd_solver.cpp:138] Iteration 78200, lr = 1e-05
I0414 05:19:38.943684 21842 solver.cpp:243] Iteration 78300, loss = 2.18128
I0414 05:19:38.943842 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93421 (* 1 = 2.93421 loss)
I0414 05:19:38.943950 21842 sgd_solver.cpp:138] Iteration 78300, lr = 1e-05
I0414 05:24:02.217727 21842 solver.cpp:243] Iteration 78400, loss = 2.26334
I0414 05:24:02.217859 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35746 (* 1 = 2.35746 loss)
I0414 05:24:02.990968 21842 sgd_solver.cpp:138] Iteration 78400, lr = 1e-05
I0414 05:28:21.935185 21842 solver.cpp:243] Iteration 78500, loss = 2.26941
I0414 05:28:21.935302 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.73236 (* 1 = 2.73236 loss)
I0414 05:28:21.935334 21842 sgd_solver.cpp:138] Iteration 78500, lr = 1e-05
I0414 05:32:53.059327 21842 solver.cpp:243] Iteration 78600, loss = 2.17479
I0414 05:32:53.059505 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.62097 (* 1 = 1.62097 loss)
I0414 05:32:53.698001 21842 sgd_solver.cpp:138] Iteration 78600, lr = 1e-05
I0414 05:37:21.140424 21842 solver.cpp:243] Iteration 78700, loss = 2.2056
I0414 05:37:21.140586 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28017 (* 1 = 2.28017 loss)
I0414 05:37:21.140630 21842 sgd_solver.cpp:138] Iteration 78700, lr = 1e-05
I0414 05:41:45.572435 21842 solver.cpp:243] Iteration 78800, loss = 2.25485
I0414 05:41:45.572630 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.69771 (* 1 = 1.69771 loss)
I0414 05:41:47.093696 21842 sgd_solver.cpp:138] Iteration 78800, lr = 1e-05
I0414 05:46:14.933831 21842 solver.cpp:243] Iteration 78900, loss = 2.13869
I0414 05:46:14.933962 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.79274 (* 1 = 1.79274 loss)
I0414 05:46:14.933995 21842 sgd_solver.cpp:138] Iteration 78900, lr = 1e-05
I0414 05:50:35.152632 21842 solver.cpp:243] Iteration 79000, loss = 2.2481
I0414 05:50:35.152845 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51242 (* 1 = 2.51242 loss)
I0414 05:50:36.569427 21842 sgd_solver.cpp:138] Iteration 79000, lr = 1e-05
I0414 05:55:02.638466 21842 solver.cpp:243] Iteration 79100, loss = 2.29098
I0414 05:55:02.638607 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17166 (* 1 = 2.17166 loss)
I0414 05:55:04.131822 21842 sgd_solver.cpp:138] Iteration 79100, lr = 1e-05
I0414 05:59:25.386224 21842 solver.cpp:243] Iteration 79200, loss = 2.17452
I0414 05:59:25.386373 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17693 (* 1 = 2.17693 loss)
I0414 05:59:26.156785 21842 sgd_solver.cpp:138] Iteration 79200, lr = 1e-05
I0414 06:03:47.261982 21842 solver.cpp:243] Iteration 79300, loss = 2.24185
I0414 06:03:47.262224 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.98787 (* 1 = 1.98787 loss)
I0414 06:03:47.262303 21842 sgd_solver.cpp:138] Iteration 79300, lr = 1e-05
I0414 06:08:17.109558 21842 solver.cpp:243] Iteration 79400, loss = 2.20085
I0414 06:08:17.109730 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13179 (* 1 = 2.13179 loss)
I0414 06:08:17.763890 21842 sgd_solver.cpp:138] Iteration 79400, lr = 1e-05
I0414 06:12:41.947384 21842 solver.cpp:243] Iteration 79500, loss = 2.23739
I0414 06:12:41.947517 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27017 (* 1 = 2.27017 loss)
I0414 06:12:41.947551 21842 sgd_solver.cpp:138] Iteration 79500, lr = 1e-05
I0414 06:17:01.257802 21842 solver.cpp:243] Iteration 79600, loss = 2.19443
I0414 06:17:01.257925 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.86306 (* 1 = 1.86306 loss)
I0414 06:17:01.257956 21842 sgd_solver.cpp:138] Iteration 79600, lr = 1e-05
I0414 06:21:27.942768 21842 solver.cpp:243] Iteration 79700, loss = 2.16395
I0414 06:21:27.942993 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53251 (* 1 = 2.53251 loss)
I0414 06:21:29.422669 21842 sgd_solver.cpp:138] Iteration 79700, lr = 1e-05
I0414 06:25:48.304015 21842 solver.cpp:243] Iteration 79800, loss = 2.23534
I0414 06:25:48.304194 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.31069 (* 1 = 2.31069 loss)
I0414 06:25:48.304229 21842 sgd_solver.cpp:138] Iteration 79800, lr = 1e-05
I0414 06:30:08.561027 21842 solver.cpp:243] Iteration 79900, loss = 2.22267
I0414 06:30:08.561161 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2987 (* 1 = 2.2987 loss)
I0414 06:30:10.025574 21842 sgd_solver.cpp:138] Iteration 79900, lr = 1e-05
I0414 06:34:36.991423 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_80000.caffemodel
I0414 06:34:37.655256 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_80000.solverstate
I0414 06:34:38.168104 21842 solver.cpp:433] Iteration 80000, Testing net (#0)
I0414 06:34:38.168237 21842 net.cpp:693] Ignoring source layer mbox_loss
I0414 06:35:02.735860 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.522101
I0414 06:35:04.907418 21842 solver.cpp:243] Iteration 80000, loss = 2.21615
I0414 06:35:04.907464 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96428 (* 1 = 1.96428 loss)
I0414 06:35:04.907498 21842 sgd_solver.cpp:138] Iteration 80000, lr = 1e-05
I0414 06:39:28.588431 21842 solver.cpp:243] Iteration 80100, loss = 2.24464
I0414 06:39:28.588608 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.61829 (* 1 = 2.61829 loss)
I0414 06:39:30.063877 21842 sgd_solver.cpp:138] Iteration 80100, lr = 1e-05
I0414 06:43:53.553259 21842 solver.cpp:243] Iteration 80200, loss = 2.25796
I0414 06:43:53.553413 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.93222 (* 1 = 2.93222 loss)
I0414 06:43:53.553448 21842 sgd_solver.cpp:138] Iteration 80200, lr = 1e-05
I0414 06:48:26.128625 21842 solver.cpp:243] Iteration 80300, loss = 2.15587
I0414 06:48:26.128763 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.00034 (* 1 = 2.00034 loss)
I0414 06:48:26.128808 21842 sgd_solver.cpp:138] Iteration 80300, lr = 1e-05
I0414 06:52:42.992012 21842 solver.cpp:243] Iteration 80400, loss = 2.27594
I0414 06:52:42.992163 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06315 (* 1 = 2.06315 loss)
I0414 06:52:43.657526 21842 sgd_solver.cpp:138] Iteration 80400, lr = 1e-05
I0414 06:57:06.814885 21842 solver.cpp:243] Iteration 80500, loss = 2.17344
I0414 06:57:06.815089 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.88605 (* 1 = 1.88605 loss)
I0414 06:57:08.269497 21842 sgd_solver.cpp:138] Iteration 80500, lr = 1e-05
I0414 07:01:31.855247 21842 solver.cpp:243] Iteration 80600, loss = 2.19624
I0414 07:01:31.855379 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.6986 (* 1 = 1.6986 loss)
I0414 07:01:31.855422 21842 sgd_solver.cpp:138] Iteration 80600, lr = 1e-05
I0414 07:05:54.027348 21842 solver.cpp:243] Iteration 80700, loss = 2.2263
I0414 07:05:54.027492 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.08724 (* 1 = 2.08724 loss)
I0414 07:05:54.707199 21842 sgd_solver.cpp:138] Iteration 80700, lr = 1e-05
I0414 07:10:21.876466 21842 solver.cpp:243] Iteration 80800, loss = 2.18283
I0414 07:10:21.876665 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06602 (* 1 = 2.06602 loss)
I0414 07:10:22.675949 21842 sgd_solver.cpp:138] Iteration 80800, lr = 1e-05
I0414 07:14:46.816851 21842 solver.cpp:243] Iteration 80900, loss = 2.20673
I0414 07:14:46.817035 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17169 (* 1 = 2.17169 loss)
I0414 07:14:48.362725 21842 sgd_solver.cpp:138] Iteration 80900, lr = 1e-05
I0414 07:19:16.474474 21842 solver.cpp:243] Iteration 81000, loss = 2.21458
I0414 07:19:16.474637 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.75621 (* 1 = 2.75621 loss)
I0414 07:19:16.474670 21842 sgd_solver.cpp:138] Iteration 81000, lr = 1e-05
I0414 07:23:45.433668 21842 solver.cpp:243] Iteration 81100, loss = 2.16121
I0414 07:23:45.433835 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34947 (* 1 = 2.34947 loss)
I0414 07:23:45.433943 21842 sgd_solver.cpp:138] Iteration 81100, lr = 1e-05
I0414 07:28:11.190290 21842 solver.cpp:243] Iteration 81200, loss = 2.2264
I0414 07:28:11.190425 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10914 (* 1 = 2.10914 loss)
I0414 07:28:12.691262 21842 sgd_solver.cpp:138] Iteration 81200, lr = 1e-05
I0414 07:32:39.513000 21842 solver.cpp:243] Iteration 81300, loss = 2.16575
I0414 07:32:39.513137 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32826 (* 1 = 2.32826 loss)
I0414 07:32:39.513195 21842 sgd_solver.cpp:138] Iteration 81300, lr = 1e-05
I0414 07:37:03.111889 21842 solver.cpp:243] Iteration 81400, loss = 2.14378
I0414 07:37:03.112092 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.84129 (* 1 = 1.84129 loss)
I0414 07:37:05.111716 21842 sgd_solver.cpp:138] Iteration 81400, lr = 1e-05
I0414 07:41:24.099037 21842 solver.cpp:243] Iteration 81500, loss = 2.23444
I0414 07:41:24.100894 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.94533 (* 1 = 1.94533 loss)
I0414 07:41:25.566656 21842 sgd_solver.cpp:138] Iteration 81500, lr = 1e-05
I0414 07:45:53.971266 21842 solver.cpp:243] Iteration 81600, loss = 2.22275
I0414 07:45:53.971447 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.67458 (* 1 = 1.67458 loss)
I0414 07:45:53.971542 21842 sgd_solver.cpp:138] Iteration 81600, lr = 1e-05
I0414 07:50:16.510380 21842 solver.cpp:243] Iteration 81700, loss = 2.16983
I0414 07:50:16.510493 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.36286 (* 1 = 2.36286 loss)
I0414 07:50:17.953037 21842 sgd_solver.cpp:138] Iteration 81700, lr = 1e-05
I0414 07:54:43.843684 21842 solver.cpp:243] Iteration 81800, loss = 2.22038
I0414 07:54:43.843822 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.58292 (* 1 = 2.58292 loss)
I0414 07:54:43.843873 21842 sgd_solver.cpp:138] Iteration 81800, lr = 1e-05
I0414 07:59:13.679534 21842 solver.cpp:243] Iteration 81900, loss = 2.18054
I0414 07:59:13.679697 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22385 (* 1 = 2.22385 loss)
I0414 07:59:13.679733 21842 sgd_solver.cpp:138] Iteration 81900, lr = 1e-05
I0414 08:03:32.695576 21842 solver.cpp:243] Iteration 82000, loss = 2.24062
I0414 08:03:32.695700 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.02343 (* 1 = 2.02343 loss)
I0414 08:03:33.417284 21842 sgd_solver.cpp:138] Iteration 82000, lr = 1e-05
I0414 08:07:53.395378 21842 solver.cpp:243] Iteration 82100, loss = 2.20371
I0414 08:07:53.395517 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12241 (* 1 = 2.12241 loss)
I0414 08:07:53.395560 21842 sgd_solver.cpp:138] Iteration 82100, lr = 1e-05
I0414 08:12:22.481169 21842 solver.cpp:243] Iteration 82200, loss = 2.19586
I0414 08:12:22.481353 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.92479 (* 1 = 1.92479 loss)
I0414 08:12:23.230209 21842 sgd_solver.cpp:138] Iteration 82200, lr = 1e-05
I0414 08:16:44.378634 21842 solver.cpp:243] Iteration 82300, loss = 2.22021
I0414 08:16:44.378792 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.53871 (* 1 = 2.53871 loss)
I0414 08:16:45.123239 21842 sgd_solver.cpp:138] Iteration 82300, lr = 1e-05
I0414 08:21:07.463434 21842 solver.cpp:243] Iteration 82400, loss = 2.21178
I0414 08:21:07.463558 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.88718 (* 1 = 1.88718 loss)
I0414 08:21:07.463590 21842 sgd_solver.cpp:138] Iteration 82400, lr = 1e-05
I0414 08:25:33.143143 21842 solver.cpp:243] Iteration 82500, loss = 2.20196
I0414 08:25:33.143306 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91803 (* 1 = 1.91803 loss)
I0414 08:25:34.602103 21842 sgd_solver.cpp:138] Iteration 82500, lr = 1e-05
I0414 08:29:58.873659 21842 solver.cpp:243] Iteration 82600, loss = 2.2734
I0414 08:29:58.873782 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.29631 (* 1 = 2.29631 loss)
I0414 08:29:58.873827 21842 sgd_solver.cpp:138] Iteration 82600, lr = 1e-05
I0414 08:34:30.253382 21842 solver.cpp:243] Iteration 82700, loss = 2.23587
I0414 08:34:30.253509 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.65539 (* 1 = 2.65539 loss)
I0414 08:34:30.253541 21842 sgd_solver.cpp:138] Iteration 82700, lr = 1e-05
I0414 08:38:50.496414 21842 solver.cpp:243] Iteration 82800, loss = 2.18702
I0414 08:38:50.496595 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43317 (* 1 = 2.43317 loss)
I0414 08:38:50.496654 21842 sgd_solver.cpp:138] Iteration 82800, lr = 1e-05
I0414 08:43:19.611640 21842 solver.cpp:243] Iteration 82900, loss = 2.25178
I0414 08:43:19.611810 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.8515 (* 1 = 1.8515 loss)
I0414 08:43:20.404587 21842 sgd_solver.cpp:138] Iteration 82900, lr = 1e-05
I0414 08:47:49.020174 21842 solver.cpp:243] Iteration 83000, loss = 2.1769
I0414 08:47:49.020380 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34914 (* 1 = 2.34914 loss)
I0414 08:47:49.020432 21842 sgd_solver.cpp:138] Iteration 83000, lr = 1e-05
I0414 08:52:08.944118 21842 solver.cpp:243] Iteration 83100, loss = 2.25672
I0414 08:52:08.944278 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.83129 (* 1 = 2.83129 loss)
I0414 08:52:08.944319 21842 sgd_solver.cpp:138] Iteration 83100, lr = 1e-05
I0414 08:56:30.314921 21842 solver.cpp:243] Iteration 83200, loss = 2.15163
I0414 08:56:30.315083 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.6575 (* 1 = 2.6575 loss)
I0414 08:56:31.026612 21842 sgd_solver.cpp:138] Iteration 83200, lr = 1e-05
I0414 09:01:00.108726 21842 solver.cpp:243] Iteration 83300, loss = 2.21668
I0414 09:01:00.108866 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.92204 (* 1 = 1.92204 loss)
I0414 09:01:00.108909 21842 sgd_solver.cpp:138] Iteration 83300, lr = 1e-05
I0414 09:05:26.617426 21842 solver.cpp:243] Iteration 83400, loss = 2.19272
I0414 09:05:26.617589 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.90199 (* 1 = 1.90199 loss)
I0414 09:05:27.366371 21842 sgd_solver.cpp:138] Iteration 83400, lr = 1e-05
I0414 09:09:50.747622 21842 solver.cpp:243] Iteration 83500, loss = 2.18839
I0414 09:09:50.747752 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17949 (* 1 = 2.17949 loss)
I0414 09:09:50.747783 21842 sgd_solver.cpp:138] Iteration 83500, lr = 1e-05
I0414 09:14:24.096192 21842 solver.cpp:243] Iteration 83600, loss = 2.16393
I0414 09:14:24.096348 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.89402 (* 1 = 1.89402 loss)
I0414 09:14:24.752959 21842 sgd_solver.cpp:138] Iteration 83600, lr = 1e-05
I0414 09:18:50.946013 21842 solver.cpp:243] Iteration 83700, loss = 2.24001
I0414 09:18:50.946182 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.80681 (* 1 = 2.80681 loss)
I0414 09:18:50.946236 21842 sgd_solver.cpp:138] Iteration 83700, lr = 1e-05
I0414 09:23:18.052937 21842 solver.cpp:243] Iteration 83800, loss = 2.17863
I0414 09:23:18.053100 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96739 (* 1 = 1.96739 loss)
I0414 09:23:18.734117 21842 sgd_solver.cpp:138] Iteration 83800, lr = 1e-05
I0414 09:27:42.536345 21842 solver.cpp:243] Iteration 83900, loss = 2.16032
I0414 09:27:42.536463 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32695 (* 1 = 2.32695 loss)
I0414 09:27:42.536494 21842 sgd_solver.cpp:138] Iteration 83900, lr = 1e-05
I0414 09:32:09.692618 21842 solver.cpp:243] Iteration 84000, loss = 2.22106
I0414 09:32:09.692790 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.59061 (* 1 = 2.59061 loss)
I0414 09:32:09.692930 21842 sgd_solver.cpp:138] Iteration 84000, lr = 1e-05
I0414 09:36:33.640283 21842 solver.cpp:243] Iteration 84100, loss = 2.22557
I0414 09:36:33.640427 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.99213 (* 1 = 1.99213 loss)
I0414 09:36:33.640465 21842 sgd_solver.cpp:138] Iteration 84100, lr = 1e-05
I0414 09:40:56.800745 21842 solver.cpp:243] Iteration 84200, loss = 2.2401
I0414 09:40:56.800910 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.95554 (* 1 = 1.95554 loss)
I0414 09:40:57.513247 21842 sgd_solver.cpp:138] Iteration 84200, lr = 1e-05
I0414 09:45:22.615353 21842 solver.cpp:243] Iteration 84300, loss = 2.28005
I0414 09:45:22.615510 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43337 (* 1 = 2.43337 loss)
I0414 09:45:23.233098 21842 sgd_solver.cpp:138] Iteration 84300, lr = 1e-05
I0414 09:49:52.507268 21842 solver.cpp:243] Iteration 84400, loss = 2.16918
I0414 09:49:52.507401 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.32787 (* 1 = 2.32787 loss)
I0414 09:49:53.953125 21842 sgd_solver.cpp:138] Iteration 84400, lr = 1e-05
I0414 09:54:16.582121 21842 solver.cpp:243] Iteration 84500, loss = 2.22246
I0414 09:54:16.582307 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25047 (* 1 = 2.25047 loss)
I0414 09:54:16.582355 21842 sgd_solver.cpp:138] Iteration 84500, lr = 1e-05
I0414 09:58:44.276819 21842 solver.cpp:243] Iteration 84600, loss = 2.23514
I0414 09:58:44.277048 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.02268 (* 1 = 2.02268 loss)
I0414 09:58:44.277086 21842 sgd_solver.cpp:138] Iteration 84600, lr = 1e-05
I0414 10:03:10.242053 21842 solver.cpp:243] Iteration 84700, loss = 2.19824
I0414 10:03:10.242185 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27264 (* 1 = 2.27264 loss)
I0414 10:03:10.242233 21842 sgd_solver.cpp:138] Iteration 84700, lr = 1e-05
I0414 10:07:32.391641 21842 solver.cpp:243] Iteration 84800, loss = 2.22068
I0414 10:07:32.391808 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.84552 (* 1 = 1.84552 loss)
I0414 10:07:33.825939 21842 sgd_solver.cpp:138] Iteration 84800, lr = 1e-05
I0414 10:11:58.492810 21842 solver.cpp:243] Iteration 84900, loss = 2.20481
I0414 10:11:58.492955 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17967 (* 1 = 2.17967 loss)
I0414 10:11:59.166432 21842 sgd_solver.cpp:138] Iteration 84900, lr = 1e-05
I0414 10:16:21.931514 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_85000.caffemodel
I0414 10:16:23.168774 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_85000.solverstate
I0414 10:16:23.539217 21842 solver.cpp:433] Iteration 85000, Testing net (#0)
I0414 10:16:23.539300 21842 net.cpp:693] Ignoring source layer mbox_loss
I0414 10:16:49.223213 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.515521
I0414 10:16:51.592872 21842 solver.cpp:243] Iteration 85000, loss = 2.10978
I0414 10:16:51.592931 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.97237 (* 1 = 1.97237 loss)
I0414 10:16:51.592969 21842 sgd_solver.cpp:138] Iteration 85000, lr = 1e-05
I0414 10:21:19.474160 21842 solver.cpp:243] Iteration 85100, loss = 2.28749
I0414 10:21:19.475848 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03848 (* 1 = 2.03848 loss)
I0414 10:21:19.475888 21842 sgd_solver.cpp:138] Iteration 85100, lr = 1e-05
I0414 10:25:44.489114 21842 solver.cpp:243] Iteration 85200, loss = 2.23541
I0414 10:25:44.489243 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27114 (* 1 = 2.27114 loss)
I0414 10:25:44.489285 21842 sgd_solver.cpp:138] Iteration 85200, lr = 1e-05
I0414 10:30:02.776445 21842 solver.cpp:243] Iteration 85300, loss = 2.19077
I0414 10:30:02.776645 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.19641 (* 1 = 2.19641 loss)
I0414 10:30:03.383083 21842 sgd_solver.cpp:138] Iteration 85300, lr = 1e-05
I0414 10:34:33.457638 21842 solver.cpp:243] Iteration 85400, loss = 2.22805
I0414 10:34:33.457784 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.81439 (* 1 = 1.81439 loss)
I0414 10:34:33.457826 21842 sgd_solver.cpp:138] Iteration 85400, lr = 1e-05
I0414 10:38:59.128154 21842 solver.cpp:243] Iteration 85500, loss = 2.18646
I0414 10:38:59.128366 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.90913 (* 1 = 1.90913 loss)
I0414 10:38:59.941364 21842 sgd_solver.cpp:138] Iteration 85500, lr = 1e-05
I0414 10:43:21.879425 21842 solver.cpp:243] Iteration 85600, loss = 2.21819
I0414 10:43:21.879637 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15036 (* 1 = 2.15036 loss)
I0414 10:43:22.740020 21842 sgd_solver.cpp:138] Iteration 85600, lr = 1e-05
I0414 10:47:44.626899 21842 solver.cpp:243] Iteration 85700, loss = 2.21213
I0414 10:47:44.627084 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57492 (* 1 = 2.57492 loss)
I0414 10:47:44.627192 21842 sgd_solver.cpp:138] Iteration 85700, lr = 1e-05
I0414 10:52:09.623508 21842 solver.cpp:243] Iteration 85800, loss = 2.17352
I0414 10:52:09.623739 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.88021 (* 1 = 1.88021 loss)
I0414 10:52:09.623816 21842 sgd_solver.cpp:138] Iteration 85800, lr = 1e-05
I0414 10:56:36.373036 21842 solver.cpp:243] Iteration 85900, loss = 2.2066
I0414 10:56:36.373247 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22761 (* 1 = 2.22761 loss)
I0414 10:56:36.373283 21842 sgd_solver.cpp:138] Iteration 85900, lr = 1e-05
I0414 11:00:56.548782 21842 solver.cpp:243] Iteration 86000, loss = 2.23436
I0414 11:00:56.548950 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.95334 (* 1 = 1.95334 loss)
I0414 11:00:57.234987 21842 sgd_solver.cpp:138] Iteration 86000, lr = 1e-05
I0414 11:05:23.893839 21842 solver.cpp:243] Iteration 86100, loss = 2.13803
I0414 11:05:23.894032 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.29363 (* 1 = 2.29363 loss)
I0414 11:05:24.719458 21842 sgd_solver.cpp:138] Iteration 86100, lr = 1e-05
I0414 11:09:50.415359 21842 solver.cpp:243] Iteration 86200, loss = 2.23813
I0414 11:09:50.415500 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.26614 (* 1 = 2.26614 loss)
I0414 11:09:50.415542 21842 sgd_solver.cpp:138] Iteration 86200, lr = 1e-05
I0414 11:14:13.727016 21842 solver.cpp:243] Iteration 86300, loss = 2.23352
I0414 11:14:13.727149 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17826 (* 1 = 2.17826 loss)
I0414 11:14:15.202220 21842 sgd_solver.cpp:138] Iteration 86300, lr = 1e-05
I0414 11:18:37.720304 21842 solver.cpp:243] Iteration 86400, loss = 2.16939
I0414 11:18:37.720494 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.42124 (* 1 = 2.42124 loss)
I0414 11:18:37.720554 21842 sgd_solver.cpp:138] Iteration 86400, lr = 1e-05
I0414 11:23:04.626718 21842 solver.cpp:243] Iteration 86500, loss = 2.26009
I0414 11:23:04.626850 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.55265 (* 1 = 2.55265 loss)
I0414 11:23:04.626883 21842 sgd_solver.cpp:138] Iteration 86500, lr = 1e-05
I0414 11:27:32.838297 21842 solver.cpp:243] Iteration 86600, loss = 2.18254
I0414 11:27:32.838436 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.81329 (* 1 = 1.81329 loss)
I0414 11:27:32.838469 21842 sgd_solver.cpp:138] Iteration 86600, lr = 1e-05
I0414 11:31:57.854344 21842 solver.cpp:243] Iteration 86700, loss = 2.16636
I0414 11:31:57.854476 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35296 (* 1 = 2.35296 loss)
I0414 11:31:57.854511 21842 sgd_solver.cpp:138] Iteration 86700, lr = 1e-05
I0414 11:36:16.694232 21842 solver.cpp:243] Iteration 86800, loss = 2.23649
I0414 11:36:16.694372 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.95858 (* 1 = 1.95858 loss)
I0414 11:36:17.522897 21842 sgd_solver.cpp:138] Iteration 86800, lr = 1e-05
I0414 11:40:44.509959 21842 solver.cpp:243] Iteration 86900, loss = 2.1343
I0414 11:40:44.510130 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.05611 (* 1 = 2.05611 loss)
I0414 11:40:44.510241 21842 sgd_solver.cpp:138] Iteration 86900, lr = 1e-05
I0414 11:45:06.391139 21842 solver.cpp:243] Iteration 87000, loss = 2.25156
I0414 11:45:06.391281 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.05362 (* 1 = 2.05362 loss)
I0414 11:45:07.231264 21842 sgd_solver.cpp:138] Iteration 87000, lr = 1e-05
I0414 11:49:32.018147 21842 solver.cpp:243] Iteration 87100, loss = 2.19109
I0414 11:49:32.018285 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11125 (* 1 = 2.11125 loss)
I0414 11:49:32.018329 21842 sgd_solver.cpp:138] Iteration 87100, lr = 1e-05
I0414 11:54:01.727190 21842 solver.cpp:243] Iteration 87200, loss = 2.20384
I0414 11:54:01.727397 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13979 (* 1 = 2.13979 loss)
I0414 11:54:01.727435 21842 sgd_solver.cpp:138] Iteration 87200, lr = 1e-05
I0414 11:58:21.679517 21842 solver.cpp:243] Iteration 87300, loss = 2.20774
I0414 11:58:21.679692 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.51157 (* 1 = 2.51157 loss)
I0414 11:58:23.373556 21842 sgd_solver.cpp:138] Iteration 87300, lr = 1e-05
I0414 12:02:44.205101 21842 solver.cpp:243] Iteration 87400, loss = 2.20961
I0414 12:02:44.205289 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.73504 (* 1 = 1.73504 loss)
I0414 12:02:44.951759 21842 sgd_solver.cpp:138] Iteration 87400, lr = 1e-05
I0414 12:07:11.812363 21842 solver.cpp:243] Iteration 87500, loss = 2.17558
I0414 12:07:11.812527 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37282 (* 1 = 2.37282 loss)
I0414 12:07:12.597023 21842 sgd_solver.cpp:138] Iteration 87500, lr = 1e-05
I0414 12:11:34.240301 21842 solver.cpp:243] Iteration 87600, loss = 2.24011
I0414 12:11:34.240460 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.2108 (* 1 = 2.2108 loss)
I0414 12:11:34.240509 21842 sgd_solver.cpp:138] Iteration 87600, lr = 1e-05
I0414 12:15:54.087877 21842 solver.cpp:243] Iteration 87700, loss = 2.23261
I0414 12:15:54.088042 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.38084 (* 1 = 2.38084 loss)
I0414 12:15:54.088156 21842 sgd_solver.cpp:138] Iteration 87700, lr = 1e-05
I0414 12:20:18.429507 21842 solver.cpp:243] Iteration 87800, loss = 2.20341
I0414 12:20:18.429651 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.28767 (* 1 = 2.28767 loss)
I0414 12:20:18.429708 21842 sgd_solver.cpp:138] Iteration 87800, lr = 1e-05
I0414 12:24:45.269726 21842 solver.cpp:243] Iteration 87900, loss = 2.20837
I0414 12:24:45.269915 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03342 (* 1 = 2.03342 loss)
I0414 12:24:45.949559 21842 sgd_solver.cpp:138] Iteration 87900, lr = 1e-05
I0414 12:29:11.081919 21842 solver.cpp:243] Iteration 88000, loss = 2.16343
I0414 12:29:11.082046 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91899 (* 1 = 1.91899 loss)
I0414 12:29:11.082100 21842 sgd_solver.cpp:138] Iteration 88000, lr = 1e-05
I0414 12:33:30.387666 21842 solver.cpp:243] Iteration 88100, loss = 2.23047
I0414 12:33:30.387809 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.37786 (* 1 = 2.37786 loss)
I0414 12:33:31.866076 21842 sgd_solver.cpp:138] Iteration 88100, lr = 1e-05
I0414 12:37:56.617619 21842 solver.cpp:243] Iteration 88200, loss = 2.18654
I0414 12:37:56.617749 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.68753 (* 1 = 1.68753 loss)
I0414 12:37:56.617785 21842 sgd_solver.cpp:138] Iteration 88200, lr = 1e-05
I0414 12:42:22.782305 21842 solver.cpp:243] Iteration 88300, loss = 2.17025
I0414 12:42:22.782547 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.44544 (* 1 = 2.44544 loss)
I0414 12:42:23.431591 21842 sgd_solver.cpp:138] Iteration 88300, lr = 1e-05
I0414 12:46:44.237251 21842 solver.cpp:243] Iteration 88400, loss = 2.19383
I0414 12:46:44.238499 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.25898 (* 1 = 2.25898 loss)
I0414 12:46:44.897552 21842 sgd_solver.cpp:138] Iteration 88400, lr = 1e-05
I0414 12:51:05.928205 21842 solver.cpp:243] Iteration 88500, loss = 2.16416
I0414 12:51:05.928349 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.97446 (* 1 = 1.97446 loss)
I0414 12:51:06.554287 21842 sgd_solver.cpp:138] Iteration 88500, lr = 1e-05
I0414 12:55:26.357813 21842 solver.cpp:243] Iteration 88600, loss = 2.1573
I0414 12:55:26.357997 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.99658 (* 1 = 1.99658 loss)
I0414 12:55:27.047237 21842 sgd_solver.cpp:138] Iteration 88600, lr = 1e-05
I0414 12:59:46.387121 21842 solver.cpp:243] Iteration 88700, loss = 2.24522
I0414 12:59:46.387447 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.4046 (* 1 = 2.4046 loss)
I0414 12:59:47.108249 21842 sgd_solver.cpp:138] Iteration 88700, lr = 1e-05
I0414 13:04:04.244933 21842 solver.cpp:243] Iteration 88800, loss = 2.22116
I0414 13:04:04.245177 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.38072 (* 1 = 2.38072 loss)
I0414 13:04:05.683607 21842 sgd_solver.cpp:138] Iteration 88800, lr = 1e-05
I0414 13:08:24.616133 21842 solver.cpp:243] Iteration 88900, loss = 2.18986
I0414 13:08:24.616309 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.21957 (* 1 = 2.21957 loss)
I0414 13:08:26.058320 21842 sgd_solver.cpp:138] Iteration 88900, lr = 1e-05
I0414 13:12:49.723098 21842 solver.cpp:243] Iteration 89000, loss = 2.22204
I0414 13:12:49.723259 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.398 (* 1 = 2.398 loss)
I0414 13:12:49.723341 21842 sgd_solver.cpp:138] Iteration 89000, lr = 1e-05
I0414 13:17:16.752931 21842 solver.cpp:243] Iteration 89100, loss = 2.1604
I0414 13:17:16.753131 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.97938 (* 1 = 1.97938 loss)
I0414 13:17:16.753231 21842 sgd_solver.cpp:138] Iteration 89100, lr = 1e-05
I0414 13:21:41.145086 21842 solver.cpp:243] Iteration 89200, loss = 2.15679
I0414 13:21:41.145311 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.11054 (* 1 = 2.11054 loss)
I0414 13:21:41.971905 21842 sgd_solver.cpp:138] Iteration 89200, lr = 1e-05
I0414 13:26:10.725045 21842 solver.cpp:243] Iteration 89300, loss = 2.23293
I0414 13:26:10.725169 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.50464 (* 1 = 2.50464 loss)
I0414 13:26:11.546952 21842 sgd_solver.cpp:138] Iteration 89300, lr = 1e-05
I0414 13:30:41.166410 21842 solver.cpp:243] Iteration 89400, loss = 2.17
I0414 13:30:41.166895 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.92409 (* 1 = 2.92409 loss)
I0414 13:30:41.166944 21842 sgd_solver.cpp:138] Iteration 89400, lr = 1e-05
I0414 13:35:01.263063 21842 solver.cpp:243] Iteration 89500, loss = 2.21991
I0414 13:35:01.263221 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23518 (* 1 = 2.23518 loss)
I0414 13:35:02.036607 21842 sgd_solver.cpp:138] Iteration 89500, lr = 1e-05
I0414 13:39:24.874197 21842 solver.cpp:243] Iteration 89600, loss = 2.24371
I0414 13:39:24.874378 21842 solver.cpp:259]     Train net output #0: mbox_loss = 3.19259 (* 1 = 3.19259 loss)
I0414 13:39:24.874483 21842 sgd_solver.cpp:138] Iteration 89600, lr = 1e-05
I0414 13:43:52.325467 21842 solver.cpp:243] Iteration 89700, loss = 2.21945
I0414 13:43:52.325610 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12688 (* 1 = 2.12688 loss)
I0414 13:43:53.074302 21842 sgd_solver.cpp:138] Iteration 89700, lr = 1e-05
I0414 13:48:12.572242 21842 solver.cpp:243] Iteration 89800, loss = 2.20429
I0414 13:48:12.572372 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17472 (* 1 = 2.17472 loss)
I0414 13:48:13.255376 21842 sgd_solver.cpp:138] Iteration 89800, lr = 1e-05
I0414 13:52:38.412436 21842 solver.cpp:243] Iteration 89900, loss = 2.2237
I0414 13:52:38.413918 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.76697 (* 1 = 1.76697 loss)
I0414 13:52:39.906584 21842 sgd_solver.cpp:138] Iteration 89900, lr = 1e-05
I0414 13:57:09.121583 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_90000.caffemodel
I0414 13:57:09.782347 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_90000.solverstate
I0414 13:57:10.149267 21842 solver.cpp:433] Iteration 90000, Testing net (#0)
I0414 13:57:10.149341 21842 net.cpp:693] Ignoring source layer mbox_loss
I0414 13:57:34.816133 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.524847
I0414 13:57:36.883775 21842 solver.cpp:243] Iteration 90000, loss = 2.14432
I0414 13:57:36.883826 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.19736 (* 1 = 2.19736 loss)
I0414 13:57:36.883857 21842 sgd_solver.cpp:138] Iteration 90000, lr = 1e-05
I0414 14:02:02.291404 21842 solver.cpp:243] Iteration 90100, loss = 2.22434
I0414 14:02:02.291548 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23606 (* 1 = 2.23606 loss)
I0414 14:02:02.291599 21842 sgd_solver.cpp:138] Iteration 90100, lr = 1e-05
I0414 14:06:30.706104 21842 solver.cpp:243] Iteration 90200, loss = 2.21822
I0414 14:06:30.706281 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.84985 (* 1 = 1.84985 loss)
I0414 14:06:32.205596 21842 sgd_solver.cpp:138] Iteration 90200, lr = 1e-05
I0414 14:10:56.185886 21842 solver.cpp:243] Iteration 90300, loss = 2.17524
I0414 14:10:56.186094 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.97283 (* 1 = 2.97283 loss)
I0414 14:10:58.153291 21842 sgd_solver.cpp:138] Iteration 90300, lr = 1e-05
I0414 14:15:20.251227 21842 solver.cpp:243] Iteration 90400, loss = 2.21827
I0414 14:15:20.251397 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.27789 (* 1 = 2.27789 loss)
I0414 14:15:20.862489 21842 sgd_solver.cpp:138] Iteration 90400, lr = 1e-05
I0414 14:19:52.893851 21842 solver.cpp:243] Iteration 90500, loss = 2.13279
I0414 14:19:52.894016 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.1547 (* 1 = 2.1547 loss)
I0414 14:19:54.376237 21842 sgd_solver.cpp:138] Iteration 90500, lr = 1e-05
I0414 14:24:18.985149 21842 solver.cpp:243] Iteration 90600, loss = 2.26978
I0414 14:24:18.985337 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23101 (* 1 = 2.23101 loss)
I0414 14:24:18.985473 21842 sgd_solver.cpp:138] Iteration 90600, lr = 1e-05
I0414 14:28:41.353345 21842 solver.cpp:243] Iteration 90700, loss = 2.20547
I0414 14:28:41.353485 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.13675 (* 1 = 2.13675 loss)
I0414 14:28:41.353534 21842 sgd_solver.cpp:138] Iteration 90700, lr = 1e-05
I0414 14:33:11.398795 21842 solver.cpp:243] Iteration 90800, loss = 2.15697
I0414 14:33:11.398943 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34345 (* 1 = 2.34345 loss)
I0414 14:33:12.004895 21842 sgd_solver.cpp:138] Iteration 90800, lr = 1e-05
I0414 14:37:33.425679 21842 solver.cpp:243] Iteration 90900, loss = 2.23856
I0414 14:37:33.425828 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.92807 (* 1 = 2.92807 loss)
I0414 14:37:34.847333 21842 sgd_solver.cpp:138] Iteration 90900, lr = 1e-05
I0414 14:41:58.930819 21842 solver.cpp:243] Iteration 91000, loss = 2.18473
I0414 14:41:58.931002 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.96036 (* 1 = 1.96036 loss)
I0414 14:41:59.542485 21842 sgd_solver.cpp:138] Iteration 91000, lr = 1e-05
I0414 14:46:25.229079 21842 solver.cpp:243] Iteration 91100, loss = 2.10725
I0414 14:46:25.229243 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.05955 (* 1 = 2.05955 loss)
I0414 14:46:26.023252 21842 sgd_solver.cpp:138] Iteration 91100, lr = 1e-05
I0414 14:50:48.171020 21842 solver.cpp:243] Iteration 91200, loss = 2.2063
I0414 14:50:48.171193 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.15778 (* 1 = 2.15778 loss)
I0414 14:50:48.171303 21842 sgd_solver.cpp:138] Iteration 91200, lr = 1e-05
I0414 14:55:15.492360 21842 solver.cpp:243] Iteration 91300, loss = 2.19149
I0414 14:55:15.492558 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17959 (* 1 = 2.17959 loss)
I0414 14:55:16.265300 21842 sgd_solver.cpp:138] Iteration 91300, lr = 1e-05
I0414 14:59:43.261484 21842 solver.cpp:243] Iteration 91400, loss = 2.1356
I0414 14:59:43.261638 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91421 (* 1 = 1.91421 loss)
I0414 14:59:43.261687 21842 sgd_solver.cpp:138] Iteration 91400, lr = 1e-05
I0414 15:04:07.099578 21842 solver.cpp:243] Iteration 91500, loss = 2.24109
I0414 15:04:07.102244 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.23638 (* 1 = 2.23638 loss)
I0414 15:04:07.804335 21842 sgd_solver.cpp:138] Iteration 91500, lr = 1e-05
I0414 15:08:39.596895 21842 solver.cpp:243] Iteration 91600, loss = 2.14432
I0414 15:08:39.597724 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.01335 (* 1 = 2.01335 loss)
I0414 15:08:39.597771 21842 sgd_solver.cpp:138] Iteration 91600, lr = 1e-05
I0414 15:12:57.120517 21842 solver.cpp:243] Iteration 91700, loss = 2.21499
I0414 15:12:57.120662 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.30454 (* 1 = 2.30454 loss)
I0414 15:12:57.967790 21842 sgd_solver.cpp:138] Iteration 91700, lr = 1e-05
I0414 15:17:15.276652 21842 solver.cpp:243] Iteration 91800, loss = 2.26582
I0414 15:17:15.276823 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17227 (* 1 = 2.17227 loss)
I0414 15:17:15.936981 21842 sgd_solver.cpp:138] Iteration 91800, lr = 1e-05
I0414 15:21:37.001958 21842 solver.cpp:243] Iteration 91900, loss = 2.19543
I0414 15:21:37.002112 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.09439 (* 1 = 2.09439 loss)
I0414 15:21:37.002147 21842 sgd_solver.cpp:138] Iteration 91900, lr = 1e-05
I0414 15:25:57.859143 21842 solver.cpp:243] Iteration 92000, loss = 2.25028
I0414 15:25:57.859417 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.58902 (* 1 = 2.58902 loss)
I0414 15:25:58.485050 21842 sgd_solver.cpp:138] Iteration 92000, lr = 1e-05
I0414 15:30:22.156093 21842 solver.cpp:243] Iteration 92100, loss = 2.25564
I0414 15:30:22.156268 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.00692 (* 1 = 2.00692 loss)
I0414 15:30:23.594929 21842 sgd_solver.cpp:138] Iteration 92100, lr = 1e-05
I0414 15:34:48.566237 21842 solver.cpp:243] Iteration 92200, loss = 2.17049
I0414 15:34:48.566375 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.0914 (* 1 = 2.0914 loss)
I0414 15:34:49.261783 21842 sgd_solver.cpp:138] Iteration 92200, lr = 1e-05
I0414 15:39:14.020227 21842 solver.cpp:243] Iteration 92300, loss = 2.19748
I0414 15:39:14.020434 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.17305 (* 1 = 2.17305 loss)
I0414 15:39:14.631148 21842 sgd_solver.cpp:138] Iteration 92300, lr = 1e-05
I0414 15:43:40.474347 21842 solver.cpp:243] Iteration 92400, loss = 2.25573
I0414 15:43:40.474563 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12197 (* 1 = 2.12197 loss)
I0414 15:43:41.129758 21842 sgd_solver.cpp:138] Iteration 92400, lr = 1e-05
I0414 15:48:06.028247 21842 solver.cpp:243] Iteration 92500, loss = 2.18677
I0414 15:48:06.028380 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.34651 (* 1 = 2.34651 loss)
I0414 15:48:06.028414 21842 sgd_solver.cpp:138] Iteration 92500, lr = 1e-05
I0414 15:52:29.554100 21842 solver.cpp:243] Iteration 92600, loss = 2.21112
I0414 15:52:29.554255 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35885 (* 1 = 2.35885 loss)
I0414 15:52:31.030295 21842 sgd_solver.cpp:138] Iteration 92600, lr = 1e-05
I0414 15:56:59.941717 21842 solver.cpp:243] Iteration 92700, loss = 2.19747
I0414 15:56:59.941897 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.83074 (* 1 = 2.83074 loss)
I0414 15:56:59.941998 21842 sgd_solver.cpp:138] Iteration 92700, lr = 1e-05
I0414 16:01:19.826814 21842 solver.cpp:243] Iteration 92800, loss = 2.18665
I0414 16:01:19.826987 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.43408 (* 1 = 2.43408 loss)
I0414 16:01:20.629251 21842 sgd_solver.cpp:138] Iteration 92800, lr = 1e-05
I0414 16:05:46.902367 21842 solver.cpp:243] Iteration 92900, loss = 2.18105
I0414 16:05:46.902498 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.01135 (* 1 = 2.01135 loss)
I0414 16:05:46.902540 21842 sgd_solver.cpp:138] Iteration 92900, lr = 1e-05
I0414 16:10:14.452849 21842 solver.cpp:243] Iteration 93000, loss = 2.25513
I0414 16:10:14.452996 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.35413 (* 1 = 2.35413 loss)
I0414 16:10:14.453048 21842 sgd_solver.cpp:138] Iteration 93000, lr = 1e-05
I0414 16:14:36.937072 21842 solver.cpp:243] Iteration 93100, loss = 2.23315
I0414 16:14:36.937219 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.88682 (* 1 = 2.88682 loss)
I0414 16:14:38.376444 21842 sgd_solver.cpp:138] Iteration 93100, lr = 1e-05
I0414 16:18:59.966647 21842 solver.cpp:243] Iteration 93200, loss = 2.19865
I0414 16:18:59.966780 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.76401 (* 1 = 1.76401 loss)
I0414 16:18:59.966830 21842 sgd_solver.cpp:138] Iteration 93200, lr = 1e-05
I0414 16:23:26.374191 21842 solver.cpp:243] Iteration 93300, loss = 2.14335
I0414 16:23:26.374351 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04876 (* 1 = 2.04876 loss)
I0414 16:23:26.374384 21842 sgd_solver.cpp:138] Iteration 93300, lr = 1e-05
I0414 16:27:48.565815 21842 solver.cpp:243] Iteration 93400, loss = 2.17845
I0414 16:27:48.566020 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.04676 (* 1 = 2.04676 loss)
I0414 16:27:48.566135 21842 sgd_solver.cpp:138] Iteration 93400, lr = 1e-05
I0414 16:32:13.703742 21842 solver.cpp:243] Iteration 93500, loss = 2.2106
I0414 16:32:13.703954 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.00648 (* 1 = 2.00648 loss)
I0414 16:32:13.703992 21842 sgd_solver.cpp:138] Iteration 93500, lr = 1e-05
I0414 16:36:40.206703 21842 solver.cpp:243] Iteration 93600, loss = 2.07959
I0414 16:36:40.206840 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03893 (* 1 = 2.03893 loss)
I0414 16:36:40.983342 21842 sgd_solver.cpp:138] Iteration 93600, lr = 1e-05
I0414 16:41:08.145220 21842 solver.cpp:243] Iteration 93700, loss = 2.22892
I0414 16:41:08.145390 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.90728 (* 1 = 1.90728 loss)
I0414 16:41:09.623942 21842 sgd_solver.cpp:138] Iteration 93700, lr = 1e-05
I0414 16:45:40.952270 21842 solver.cpp:243] Iteration 93800, loss = 2.20814
I0414 16:45:40.952461 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.22407 (* 1 = 2.22407 loss)
I0414 16:45:40.952515 21842 sgd_solver.cpp:138] Iteration 93800, lr = 1e-05
I0414 16:50:01.214356 21842 solver.cpp:243] Iteration 93900, loss = 2.18478
I0414 16:50:01.214493 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.48834 (* 1 = 2.48834 loss)
I0414 16:50:01.214526 21842 sgd_solver.cpp:138] Iteration 93900, lr = 1e-05
I0414 16:54:27.370245 21842 solver.cpp:243] Iteration 94000, loss = 2.22373
I0414 16:54:27.370421 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.71892 (* 1 = 2.71892 loss)
I0414 16:54:27.370540 21842 sgd_solver.cpp:138] Iteration 94000, lr = 1e-05
I0414 16:58:58.306568 21842 solver.cpp:243] Iteration 94100, loss = 2.14416
I0414 16:58:58.306773 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.68135 (* 1 = 1.68135 loss)
I0414 16:58:58.306838 21842 sgd_solver.cpp:138] Iteration 94100, lr = 1e-05
I0414 17:03:21.106699 21842 solver.cpp:243] Iteration 94200, loss = 2.27201
I0414 17:03:21.106861 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06596 (* 1 = 2.06596 loss)
I0414 17:03:21.106901 21842 sgd_solver.cpp:138] Iteration 94200, lr = 1e-05
I0414 17:07:44.917909 21842 solver.cpp:243] Iteration 94300, loss = 2.20136
I0414 17:07:44.918085 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.85795 (* 1 = 1.85795 loss)
I0414 17:07:45.538578 21842 sgd_solver.cpp:138] Iteration 94300, lr = 1e-05
I0414 17:12:16.369415 21842 solver.cpp:243] Iteration 94400, loss = 2.16042
I0414 17:12:16.369608 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.988 (* 1 = 1.988 loss)
I0414 17:12:16.369681 21842 sgd_solver.cpp:138] Iteration 94400, lr = 1e-05
I0414 17:16:36.170119 21842 solver.cpp:243] Iteration 94500, loss = 2.15394
I0414 17:16:36.170356 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.78047 (* 1 = 1.78047 loss)
I0414 17:16:37.609350 21842 sgd_solver.cpp:138] Iteration 94500, lr = 1e-05
I0414 17:21:02.682235 21842 solver.cpp:243] Iteration 94600, loss = 2.1992
I0414 17:21:02.682368 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.49381 (* 1 = 2.49381 loss)
I0414 17:21:02.682420 21842 sgd_solver.cpp:138] Iteration 94600, lr = 1e-05
I0414 17:25:32.455299 21842 solver.cpp:243] Iteration 94700, loss = 2.20665
I0414 17:25:32.455444 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.12219 (* 1 = 2.12219 loss)
I0414 17:25:33.903384 21842 sgd_solver.cpp:138] Iteration 94700, lr = 1e-05
I0414 17:29:58.280803 21842 solver.cpp:243] Iteration 94800, loss = 2.16533
I0414 17:29:58.280930 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.10157 (* 1 = 2.10157 loss)
I0414 17:29:58.280979 21842 sgd_solver.cpp:138] Iteration 94800, lr = 1e-05
I0414 17:34:22.667690 21842 solver.cpp:243] Iteration 94900, loss = 2.21223
I0414 17:34:22.667845 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.03953 (* 1 = 2.03953 loss)
I0414 17:34:22.667901 21842 sgd_solver.cpp:138] Iteration 94900, lr = 1e-05
I0414 17:38:43.441874 21842 solver.cpp:593] Snapshotting to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_95000.caffemodel
I0414 17:38:44.584663 21842 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/text/text_polygon_precise_fix_order_384x384/VGG_text_text_polygon_precise_fix_order_384x384_iter_95000.solverstate
I0414 17:38:44.951443 21842 solver.cpp:433] Iteration 95000, Testing net (#0)
I0414 17:38:44.951529 21842 net.cpp:693] Ignoring source layer mbox_loss
I0414 17:39:10.552796 21842 solver.cpp:543]     Test net output #0: detection_eval = 0.51261
I0414 17:39:12.066550 21842 solver.cpp:243] Iteration 95000, loss = 2.17664
I0414 17:39:12.066602 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.40178 (* 1 = 2.40178 loss)
I0414 17:39:12.848151 21842 sgd_solver.cpp:138] Iteration 95000, lr = 1e-05
I0414 17:43:32.129806 21842 solver.cpp:243] Iteration 95100, loss = 2.25602
I0414 17:43:32.129956 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.57551 (* 1 = 2.57551 loss)
I0414 17:43:32.839224 21842 sgd_solver.cpp:138] Iteration 95100, lr = 1e-05
I0414 17:47:57.906675 21842 solver.cpp:243] Iteration 95200, loss = 2.18978
I0414 17:47:57.906823 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.66821 (* 1 = 1.66821 loss)
I0414 17:47:58.533565 21842 sgd_solver.cpp:138] Iteration 95200, lr = 1e-05
I0414 17:52:16.836047 21842 solver.cpp:243] Iteration 95300, loss = 2.16127
I0414 17:52:16.836185 21842 solver.cpp:259]     Train net output #0: mbox_loss = 1.91484 (* 1 = 1.91484 loss)
I0414 17:52:17.597571 21842 sgd_solver.cpp:138] Iteration 95300, lr = 1e-05
I0414 17:56:46.626410 21842 solver.cpp:243] Iteration 95400, loss = 2.17566
I0414 17:56:46.626587 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.06954 (* 1 = 2.06954 loss)
I0414 17:56:46.626704 21842 sgd_solver.cpp:138] Iteration 95400, lr = 1e-05
I0414 18:01:13.412250 21842 solver.cpp:243] Iteration 95500, loss = 2.13543
I0414 18:01:13.412405 21842 solver.cpp:259]     Train net output #0: mbox_loss = 2.3858 (* 1 = 2.3858 loss)
I0414 18:01:14.172857 21842 sgd_solver.cpp:138] Iteration 95500, lr = 1e-05
